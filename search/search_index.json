{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"@gadugi/agentic-test Documentation","text":"<p>Complete documentation for the Gadugi multi-agent testing framework.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation and Quick Start - Set up the framework and run your first test</li> <li>Writing Your First Test - YAML scenario structure and agent types</li> </ul>"},{"location":"#guides","title":"Guides","text":"<ul> <li>Screenshot Diffing and Visual Regression - Configure screenshot capture and image comparison</li> <li>ResourceOptimizer Configuration - Tune concurrency and resource limits</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>Architecture - Layered architecture, all modules, BaseAgent pattern, and data flow</li> <li>API Reference - Programmatic API (<code>lib.ts</code>) and exported types</li> <li>CLI Reference - <code>gadugi-test</code> command-line options</li> <li>YAML Scenario Schema - All scenario fields, agent types, and action names</li> </ul>"},{"location":"#e2e-test-suite","title":"E2E Test Suite","text":"<ul> <li>E2E Tests Overview - End-to-end scenarios that validate the framework itself</li> <li>E2E Quick Reference - Common commands and scenario summary</li> <li>Testing Approach - Agent-driven self-testing vs. traditional approaches</li> </ul>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Troubleshooting Guide - Common issues and solutions</li> </ul>"},{"location":"#internal","title":"Internal","text":"<ul> <li>Quality Audit 2026-02 - Historical audit report; all issues resolved</li> </ul>"},{"location":"API_REFERENCE/","title":"API Reference","text":"<p>Complete API documentation for the Gadugi Agentic Test framework. This reference covers all classes, methods, configuration options, and integration patterns.</p>"},{"location":"API_REFERENCE/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Core Classes</li> <li>Agent APIs</li> <li>Configuration Objects</li> <li>Test Models</li> <li>Utility Functions</li> <li>Integration APIs</li> <li>Event System</li> <li>Error Handling</li> <li>Base Classes</li> </ol>"},{"location":"API_REFERENCE/#core-classes","title":"Core Classes","text":""},{"location":"API_REFERENCE/#testorchestrator","title":"TestOrchestrator","text":"<p>The main orchestrator class that coordinates all testing activities across multiple agents.</p> <pre><code>class TestOrchestrator extends EventEmitter\n</code></pre>"},{"location":"API_REFERENCE/#constructor","title":"Constructor","text":"<pre><code>constructor(config: TestConfig)\n</code></pre> <p>Parameters: - <code>config: TestConfig</code> - Global configuration object</p> <p>Example: <pre><code>import { TestOrchestrator } from '@gadugi/agentic-test';\n\nconst orchestrator = new TestOrchestrator({\n  execution: {\n    maxParallel: 3,\n    maxRetries: 2,\n    continueOnFailure: true\n  },\n  cli: {\n    timeout: 30000,\n    workingDirectory: process.cwd()\n  },\n  ui: {\n    executablePath: '/path/to/app.exe',\n    headless: false\n  },\n  github: {\n    repository: 'owner/repo',\n    createIssues: true\n  }\n});\n</code></pre></p>"},{"location":"API_REFERENCE/#methods","title":"Methods","text":""},{"location":"API_REFERENCE/#runsuite-string-scenariofiles-string-promisetestsession","title":"<code>run(suite?: string, scenarioFiles?: string[]): Promise&lt;TestSession&gt;</code>","text":"<p>Execute a complete testing session.</p> <p>Parameters: - <code>suite?: string</code> - Test suite name (default: 'smoke') - <code>scenarioFiles?: string[]</code> - Specific scenario files to run</p> <p>Returns: <code>Promise&lt;TestSession&gt;</code> - Complete session results</p> <p>Example: <pre><code>// Run smoke tests\nconst session = await orchestrator.run('smoke');\n\n// Run specific files\nconst session = await orchestrator.run('full', [\n  './tests/login.yaml',\n  './tests/dashboard.yaml'\n]);\n\n// Run all scenarios in directory\nconst session = await orchestrator.run('regression');\n</code></pre></p>"},{"location":"API_REFERENCE/#abort-void","title":"<code>abort(): void</code>","text":"<p>Abort the current test session.</p> <p>Example: <pre><code>// Set up abort on timeout\nsetTimeout(() =&gt; {\n  orchestrator.abort();\n}, 300000); // 5 minutes\n\nconst session = await orchestrator.run();\n</code></pre></p>"},{"location":"API_REFERENCE/#getsession-testsession-null","title":"<code>getSession(): TestSession | null</code>","text":"<p>Get the current test session.</p> <p>Returns: <code>TestSession | null</code> - Current session or null if none active</p>"},{"location":"API_REFERENCE/#getresults-testresult","title":"<code>getResults(): TestResult[]</code>","text":"<p>Get all test results from the current session.</p> <p>Returns: <code>TestResult[]</code> - Array of test results</p>"},{"location":"API_REFERENCE/#getfailures-testfailure","title":"<code>getFailures(): TestFailure[]</code>","text":"<p>Get all test failures from the current session.</p> <p>Returns: <code>TestFailure[]</code> - Array of test failures</p> <p>Note: <code>reportFailures()</code> is a fully-implemented private method called internally during <code>run()</code>. It iterates over all failures, invokes <code>IssueReporter.execute()</code> for each, and collects the created issue numbers onto the session. You do not call it directly.</p>"},{"location":"API_REFERENCE/#events","title":"Events","text":"<pre><code>interface OrchestratorEvents {\n  'session:start': (session: TestSession) =&gt; void;\n  'session:end': (session: TestSession) =&gt; void;\n  'scenario:start': (scenario: TestScenario) =&gt; void;\n  'scenario:end': (scenario: TestScenario, result: TestResult) =&gt; void;\n  'phase:start': (phase: string) =&gt; void;\n  'phase:end': (phase: string) =&gt; void;\n  'error': (error: Error) =&gt; void;\n}\n</code></pre> <p>Example: <pre><code>orchestrator.on('scenario:start', (scenario) =&gt; {\n  console.log(`Starting: ${scenario.name}`);\n});\n\norchestrator.on('scenario:end', (scenario, result) =&gt; {\n  console.log(`Completed: ${scenario.name} - ${result.status}`);\n});\n</code></pre></p>"},{"location":"API_REFERENCE/#agent-apis","title":"Agent APIs","text":""},{"location":"API_REFERENCE/#electronuiagent","title":"ElectronUIAgent","text":"<p>Intelligent Electron application testing agent using Playwright.</p> <pre><code>class ElectronUIAgent extends EventEmitter implements IAgent\n</code></pre>"},{"location":"API_REFERENCE/#constructor_1","title":"Constructor","text":"<pre><code>constructor(config: ElectronUIAgentConfig)\n</code></pre>"},{"location":"API_REFERENCE/#core-methods","title":"Core Methods","text":""},{"location":"API_REFERENCE/#initialize-promisevoid","title":"<code>initialize(): Promise&lt;void&gt;</code>","text":"<p>Initialize the agent and validate configuration.</p> <p>Example: <pre><code>const agent = new ElectronUIAgent({\n  executablePath: '/path/to/app.exe',\n  defaultTimeout: 10000\n});\n\nawait agent.initialize();\n</code></pre></p>"},{"location":"API_REFERENCE/#launch-promisevoid","title":"<code>launch(): Promise&lt;void&gt;</code>","text":"<p>Launch the Electron application.</p> <p>Example: <pre><code>await agent.launch();\n</code></pre></p>"},{"location":"API_REFERENCE/#close-promisevoid","title":"<code>close(): Promise&lt;void&gt;</code>","text":"<p>Close the Electron application.</p>"},{"location":"API_REFERENCE/#cleanup-promisevoid","title":"<code>cleanup(): Promise&lt;void&gt;</code>","text":"<p>Clean up all resources and export final data.</p>"},{"location":"API_REFERENCE/#ui-interaction-methods","title":"UI Interaction Methods","text":""},{"location":"API_REFERENCE/#clicktabtabname-string-promisevoid","title":"<code>clickTab(tabName: string): Promise&lt;void&gt;</code>","text":"<p>Navigate to a specific tab using intelligent selector strategies.</p> <p>Parameters: - <code>tabName: string</code> - Display name of the tab</p> <p>Example: <pre><code>await agent.clickTab('Settings');\nawait agent.clickTab('Build Configuration');\n</code></pre></p>"},{"location":"API_REFERENCE/#fillinputselector-string-value-string-promisevoid","title":"<code>fillInput(selector: string, value: string): Promise&lt;void&gt;</code>","text":"<p>Fill an input field with validation.</p> <p>Parameters: - <code>selector: string</code> - CSS selector or data-testid - <code>value: string</code> - Value to fill</p> <p>Example: <pre><code>await agent.fillInput('[data-testid=\"username\"]', 'testuser');\nawait agent.fillInput('#email', 'test@example.com');\n</code></pre></p>"},{"location":"API_REFERENCE/#clickbuttonselector-string-promisevoid","title":"<code>clickButton(selector: string): Promise&lt;void&gt;</code>","text":"<p>Click a button or clickable element.</p> <p>Parameters: - <code>selector: string</code> - CSS selector for the element</p> <p>Example: <pre><code>await agent.clickButton('[data-testid=\"submit-btn\"]');\nawait agent.clickButton('button:has-text(\"Save\")');\n</code></pre></p>"},{"location":"API_REFERENCE/#waitforelementselector-string-options-waitoptions-promiselocator","title":"<code>waitForElement(selector: string, options?: WaitOptions): Promise&lt;Locator&gt;</code>","text":"<p>Wait for an element to appear or reach a specific state.</p> <p>Parameters: - <code>selector: string</code> - CSS selector - <code>options?: WaitOptions</code> - Wait configuration</p> <pre><code>interface WaitOptions {\n  state?: 'attached' | 'detached' | 'visible' | 'hidden';\n  timeout?: number;\n}\n</code></pre> <p>Example: <pre><code>// Wait for element to be visible\nconst element = await agent.waitForElement('[data-testid=\"success-message\"]');\n\n// Wait for element to be hidden\nawait agent.waitForElement('[data-testid=\"loading\"]', {\n  state: 'hidden',\n  timeout: 30000\n});\n</code></pre></p>"},{"location":"API_REFERENCE/#getelementtextselector-string-promisestring","title":"<code>getElementText(selector: string): Promise&lt;string&gt;</code>","text":"<p>Get text content from an element.</p> <p>Example: <pre><code>const errorMessage = await agent.getElementText('[data-testid=\"error\"]');\nconst title = await agent.getElementText('h1');\n</code></pre></p>"},{"location":"API_REFERENCE/#state-capture-methods","title":"State Capture Methods","text":""},{"location":"API_REFERENCE/#screenshotname-string-promisescreenshotmetadata","title":"<code>screenshot(name: string): Promise&lt;ScreenshotMetadata&gt;</code>","text":"<p>Take a screenshot with metadata.</p> <p>Returns: <code>ScreenshotMetadata</code> - Screenshot information</p> <pre><code>interface ScreenshotMetadata {\n  fileName: string;\n  filePath: string;\n  timestamp: Date;\n  scenarioId?: string;\n  description?: string;\n  fileSize: number;\n  dimensions: { width: number; height: number };\n}\n</code></pre> <p>Example: <pre><code>const screenshot = await agent.screenshot('login_success');\nconsole.log(`Screenshot saved: ${screenshot.filePath}`);\n</code></pre></p>"},{"location":"API_REFERENCE/#capturestate-promiseappstate","title":"<code>captureState(): Promise&lt;AppState&gt;</code>","text":"<p>Capture comprehensive application state.</p> <p>Returns: <code>AppState</code> - Complete application state</p> <pre><code>interface AppState {\n  timestamp: Date;\n  interface: 'GUI' | 'CLI' | 'API';\n  screenshotPath?: string;\n  url?: string;\n  title?: string;\n  processInfo?: ProcessInfo;\n  performance?: PerformanceMetrics;\n  networkState?: NetworkState;\n  customData?: Record&lt;string, any&gt;;\n}\n</code></pre> <p>Example: <pre><code>const state = await agent.captureState();\nconsole.log(`Current URL: ${state.url}`);\nconsole.log(`Memory usage: ${state.performance?.memoryUsage}MB`);\n</code></pre></p>"},{"location":"API_REFERENCE/#test-execution","title":"Test Execution","text":""},{"location":"API_REFERENCE/#executescenario-testscenario-promisetestresult","title":"<code>execute(scenario: TestScenario): Promise&lt;TestResult&gt;</code>","text":"<p>Execute a complete test scenario.</p> <p>Example: <pre><code>const scenario = {\n  id: 'login-test',\n  name: 'User Login Flow',\n  steps: [\n    { action: 'launch_electron', target: '', timeout: 20000 },\n    { action: 'fill', target: '[data-testid=\"username\"]', value: 'testuser' },\n    { action: 'fill', target: '[data-testid=\"password\"]', value: 'password' },\n    { action: 'click', target: '[data-testid=\"login-btn\"]' },\n    { action: 'wait_for_element', target: '[data-testid=\"dashboard\"]' }\n  ]\n};\n\nconst result = await agent.execute(scenario);\n</code></pre></p>"},{"location":"API_REFERENCE/#executestepstep-teststep-stepindex-number-promisestepresult","title":"<code>executeStep(step: TestStep, stepIndex: number): Promise&lt;StepResult&gt;</code>","text":"<p>Execute a single test step.</p> <p>Example: <pre><code>const step = {\n  action: 'click',\n  target: '[data-testid=\"save-btn\"]',\n  timeout: 5000\n};\n\nconst result = await agent.executeStep(step, 0);\n</code></pre></p>"},{"location":"API_REFERENCE/#configuration-interface","title":"Configuration Interface","text":"<pre><code>interface ElectronUIAgentConfig {\n  executablePath: string;\n  args?: string[];\n  cwd?: string;\n  env?: Record&lt;string, string&gt;;\n  launchTimeout?: number;\n  defaultTimeout?: number;\n  headless?: boolean;\n  recordVideo?: boolean;\n  videoDir?: string;\n  slowMo?: number;\n\n  screenshotConfig?: {\n    mode: 'off' | 'on' | 'only-on-failure';\n    directory: string;\n    fullPage: boolean;\n  };\n\n  websocketConfig?: {\n    url: string;\n    events: string[];\n    reconnectAttempts: number;\n    reconnectDelay: number;\n  };\n\n  performanceConfig?: {\n    enabled: boolean;\n    sampleInterval: number;\n    collectLogs: boolean;\n  };\n  // Note: cpuUsage in performance samples is measured via the `pidusage` library,\n  // which provides real per-process CPU percentages. It is not always 0.\n\n  recoveryConfig?: {\n    maxRetries: number;\n    retryDelay: number;\n    restartOnFailure: boolean;\n  };\n}\n</code></pre>"},{"location":"API_REFERENCE/#cliagent","title":"CLIAgent","text":"<p>Command-line interface testing and validation agent.</p> <pre><code>class CLIAgent implements IAgent\n</code></pre>"},{"location":"API_REFERENCE/#constructor_2","title":"Constructor","text":"<pre><code>constructor(config: CLIConfig)\n</code></pre>"},{"location":"API_REFERENCE/#methods_1","title":"Methods","text":""},{"location":"API_REFERENCE/#executescenario-testscenario-promisetestresult_1","title":"<code>execute(scenario: TestScenario): Promise&lt;TestResult&gt;</code>","text":"<p>Execute CLI-based test scenarios.</p>"},{"location":"API_REFERENCE/#runcommandcommand-string-options-commandoptions-promisecommandresult","title":"<code>runCommand(command: string, options?: CommandOptions): Promise&lt;CommandResult&gt;</code>","text":"<p>Execute a single command with monitoring.</p> <pre><code>interface CommandOptions {\n  timeout?: number;\n  workingDirectory?: string;\n  environmentVars?: Record&lt;string, string&gt;;\n  input?: string;\n  expectExitCode?: number;\n}\n\ninterface CommandResult {\n  exitCode: number;\n  stdout: string;\n  stderr: string;\n  duration: number;\n  timedOut: boolean;\n}\n</code></pre> <p>Example: <pre><code>const result = await cliAgent.runCommand('npm test', {\n  timeout: 60000,\n  workingDirectory: './my-project',\n  expectExitCode: 0\n});\n\nconsole.log(`Exit code: ${result.exitCode}`);\nconsole.log(`Output: ${result.stdout}`);\n</code></pre></p>"},{"location":"API_REFERENCE/#startinteractivesessioncommand-string-promiseinteractivesession","title":"<code>startInteractiveSession(command: string): Promise&lt;InteractiveSession&gt;</code>","text":"<p>Start an interactive CLI session.</p> <pre><code>interface InteractiveSession {\n  send(input: string): Promise&lt;void&gt;;\n  expect(pattern: string | RegExp, timeout?: number): Promise&lt;string&gt;;\n  close(): Promise&lt;void&gt;;\n}\n</code></pre> <p>Example: <pre><code>const session = await cliAgent.startInteractiveSession('npm run dev');\nawait session.expect('Server running on port 3000');\nawait session.send('q'); // Quit\nawait session.close();\n</code></pre></p>"},{"location":"API_REFERENCE/#issuereporter","title":"IssueReporter","text":"<p>Automated GitHub issue creation and management agent. <code>IssueReporter</code> fully implements the <code>IAgent</code> interface, including a concrete <code>execute()</code> method that processes a scenario and reports any failures as GitHub issues.</p> <pre><code>class IssueReporter implements IAgent\n</code></pre>"},{"location":"API_REFERENCE/#methods_2","title":"Methods","text":""},{"location":"API_REFERENCE/#executescenario-orchestratorscenario-promise-issuenumber-number-url-string-null","title":"<code>execute(scenario: OrchestratorScenario): Promise&lt;{ issueNumber: number; url: string } | null&gt;</code>","text":"<p>Execute the reporter against a scenario. Creates a GitHub issue for the failure described in the scenario and returns the issue number and URL, or <code>null</code> if issue creation was skipped (e.g., duplicate detected).</p> <p>Example: <pre><code>const reporter = new IssueReporter({ repository: 'owner/repo', createIssues: true });\nawait reporter.initialize();\nconst result = await reporter.execute(scenario);\nif (result) {\n  console.log(`Issue #${result.issueNumber}: ${result.url}`);\n}\n</code></pre></p>"},{"location":"API_REFERENCE/#reportfailurefailure-testfailure-promisenumber-null","title":"<code>reportFailure(failure: TestFailure): Promise&lt;number | null&gt;</code>","text":"<p>Create a GitHub issue for a test failure.</p> <p>Returns: Issue number or null if creation failed</p> <p>Example: <pre><code>const issueNumber = await issueReporter.reportFailure({\n  scenarioId: 'login-test',\n  timestamp: new Date(),\n  message: 'Login button not responding',\n  category: 'ui',\n  logs: ['Error: Timeout waiting for element']\n});\n\nconsole.log(`Created issue #${issueNumber}`);\n</code></pre></p>"},{"location":"API_REFERENCE/#checkforduplicatesfailure-testfailure-promisenumber-null","title":"<code>checkForDuplicates(failure: TestFailure): Promise&lt;number | null&gt;</code>","text":"<p>Check if a similar issue already exists.</p> <p>Returns: Existing issue number or null</p>"},{"location":"API_REFERENCE/#priorityagent","title":"PriorityAgent","text":"<p>Intelligent failure prioritization and classification agent.</p> <pre><code>class PriorityAgent implements IAgent\n</code></pre>"},{"location":"API_REFERENCE/#methods_3","title":"Methods","text":""},{"location":"API_REFERENCE/#analyzepriorityfailure-testfailure-promisepriorityanalysis","title":"<code>analyzePriority(failure: TestFailure): Promise&lt;PriorityAnalysis&gt;</code>","text":"<p>Analyze failure priority using AI and historical data.</p> <pre><code>interface PriorityAnalysis {\n  priority: Priority;\n  impactScore: number;\n  reasoning: string;\n  confidence: number;\n  factors: PriorityFactor[];\n}\n\nenum Priority {\n  CRITICAL = 'critical',\n  HIGH = 'high',\n  MEDIUM = 'medium',\n  LOW = 'low'\n}\n</code></pre> <p>Example: <pre><code>const analysis = await priorityAgent.analyzePriority(failure);\nconsole.log(`Priority: ${analysis.priority} (score: ${analysis.impactScore})`);\nconsole.log(`Reasoning: ${analysis.reasoning}`);\n</code></pre></p>"},{"location":"API_REFERENCE/#generatepriorityreportfailures-testfailure-results-testresult-promisepriorityreport","title":"<code>generatePriorityReport(failures: TestFailure[], results: TestResult[]): Promise&lt;PriorityReport&gt;</code>","text":"<p>Generate comprehensive priority analysis report.</p>"},{"location":"API_REFERENCE/#configuration-objects","title":"Configuration Objects","text":""},{"location":"API_REFERENCE/#testconfig","title":"TestConfig","text":"<p>Global configuration for the test orchestrator.</p> <pre><code>interface TestConfig {\n  execution?: ExecutionConfig;\n  cli?: CLIConfig;\n  ui?: UIConfig;\n  github?: GitHubConfig;\n  priority?: PriorityConfig;\n}\n</code></pre>"},{"location":"API_REFERENCE/#executionconfig","title":"ExecutionConfig","text":"<pre><code>interface ExecutionConfig {\n  maxParallel?: number;          // Default: 3\n  maxRetries?: number;           // Default: 2\n  continueOnFailure?: boolean;   // Default: true\n  suites?: Record&lt;string, string[]&gt;;\n}\n</code></pre>"},{"location":"API_REFERENCE/#cliconfig","title":"CLIConfig","text":"<pre><code>interface CLIConfig {\n  timeout?: number;              // Default: 30000\n  workingDirectory?: string;     // Default: process.cwd()\n  environmentVars?: Record&lt;string, string&gt;;\n  shell?: string;                // Default: system shell\n}\n</code></pre>"},{"location":"API_REFERENCE/#uiconfig","title":"UIConfig","text":"<pre><code>interface UIConfig {\n  executablePath?: string;\n  browser?: 'chromium' | 'firefox' | 'webkit';\n  headless?: boolean;\n  viewport?: { width: number; height: number };\n  timeout?: number;\n}\n</code></pre>"},{"location":"API_REFERENCE/#githubconfig","title":"GitHubConfig","text":"<pre><code>interface GitHubConfig {\n  repository?: string;           // Format: 'owner/repo'\n  token?: string;\n  createIssues?: boolean;        // Default: false\n  labels?: string[];\n  assignees?: string[];\n  issueTemplate?: string;\n}\n</code></pre>"},{"location":"API_REFERENCE/#test-models","title":"Test Models","text":""},{"location":"API_REFERENCE/#testscenario","title":"TestScenario","text":"<pre><code>interface TestScenario {\n  id: string;\n  name: string;\n  description?: string;\n  version?: string;\n  tags?: string[];\n  interface?: TestInterface;\n  steps: TestStep[];\n  cleanup?: TestStep[];\n  retryOnFailure?: boolean;\n  timeout?: number;\n}\n\nenum TestInterface {\n  GUI = 'gui',\n  CLI = 'cli',\n  API = 'api',\n  MIXED = 'mixed'\n}\n</code></pre>"},{"location":"API_REFERENCE/#teststep","title":"TestStep","text":"<pre><code>interface TestStep {\n  name?: string;\n  action: string;\n  target: string;\n  value?: string;\n  timeout?: number;\n  retries?: number;\n  continueOnFailure?: boolean;\n  condition?: StepCondition;\n}\n\ninterface StepCondition {\n  when?: 'always' | 'previous_step_passed' | 'previous_step_failed';\n  unless?: string;\n}\n</code></pre>"},{"location":"API_REFERENCE/#testresult","title":"TestResult","text":"<pre><code>interface TestResult {\n  scenarioId: string;\n  status: TestStatus;\n  duration: number;\n  startTime?: Date;\n  endTime?: Date;\n  error?: TestError;\n  logs?: string[];\n  screenshots?: string[];\n  performanceSamples?: PerformanceSample[];\n  websocketEvents?: WebSocketEvent[];\n  stateSnapshots?: StateSnapshot[];\n  retryCount?: number;\n}\n\nenum TestStatus {\n  PASSED = 'passed',\n  FAILED = 'failed',\n  SKIPPED = 'skipped',\n  ERROR = 'error'\n}\n</code></pre>"},{"location":"API_REFERENCE/#testerror","title":"TestError","text":"<pre><code>interface TestError {\n  type: string;\n  message: string;\n  stackTrace?: string;\n  timestamp?: Date;\n  context?: Record&lt;string, any&gt;;\n}\n</code></pre>"},{"location":"API_REFERENCE/#testsession","title":"TestSession","text":"<pre><code>interface TestSession {\n  id: string;\n  startTime: Date;\n  endTime: Date | null;\n  scenariosExecuted: string[];\n  results: TestResult[];\n  failures: TestFailure[];\n  issuesCreated: number[];\n  metrics: SessionMetrics;\n}\n\ninterface SessionMetrics {\n  totalScenarios: number;\n  passed: number;\n  failed: number;\n  skipped: number;\n  duration: number;\n}\n</code></pre>"},{"location":"API_REFERENCE/#utility-functions","title":"Utility Functions","text":""},{"location":"API_REFERENCE/#factory-functions","title":"Factory Functions","text":"<pre><code>// Create agent instances\nexport function createElectronUIAgent(config: ElectronUIAgentConfig): ElectronUIAgent;\nexport function createCLIAgent(config: CLIConfig): CLIAgent;\nexport function createTestOrchestrator(config: TestConfig): TestOrchestrator;\n\n// Quick start utilities\nexport async function quickStart(scenarioPath: string): Promise&lt;TestSession&gt;;\nexport async function quickStartMultiple(scenarioPaths: string[]): Promise&lt;TestSession&gt;;\n</code></pre> <p>Examples: <pre><code>// Quick single test\nawait quickStart('./tests/smoke-test.yaml');\n\n// Quick multiple tests\nawait quickStartMultiple([\n  './tests/login.yaml',\n  './tests/dashboard.yaml'\n]);\n\n// Manual agent creation\nconst uiAgent = createElectronUIAgent({\n  executablePath: '/path/to/app.exe',\n  headless: false\n});\n</code></pre></p>"},{"location":"API_REFERENCE/#configuration-helpers","title":"Configuration Helpers","text":"<pre><code>export function loadConfig(path?: string): TestConfig;\nexport function validateEnvironment(): EnvironmentCheck;\nexport function mergeConfigs(base: TestConfig, override: Partial&lt;TestConfig&gt;): TestConfig;\n\ninterface EnvironmentCheck {\n  valid: boolean;\n  missing: string[];\n  warnings: string[];\n}\n</code></pre> <p>Examples: <pre><code>// Load configuration\nconst config = loadConfig('./gadugi.config.js');\n\n// Environment validation\nconst envCheck = validateEnvironment();\nif (!envCheck.valid) {\n  console.error('Missing environment variables:', envCheck.missing);\n}\n\n// Merge configurations\nconst mergedConfig = mergeConfigs(baseConfig, {\n  execution: { maxParallel: 5 }\n});\n</code></pre></p>"},{"location":"API_REFERENCE/#scenario-loading","title":"Scenario Loading","text":"<pre><code>export class ScenarioLoader {\n  static async loadFromFile(path: string): Promise&lt;TestScenario&gt;;\n  static async loadFromDirectory(directory: string): Promise&lt;TestScenario[]&gt;;\n  static async loadFromPattern(pattern: string): Promise&lt;TestScenario[]&gt;;\n  static validate(scenario: TestScenario): ValidationResult;\n}\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings: string[];\n}\n</code></pre> <p>Examples: <pre><code>// Load single scenario\nconst scenario = await ScenarioLoader.loadFromFile('./tests/login.yaml');\n\n// Load all scenarios from directory\nconst scenarios = await ScenarioLoader.loadFromDirectory('./tests/');\n\n// Load with glob pattern\nconst smokeTests = await ScenarioLoader.loadFromPattern('./tests/**/*smoke*.yaml');\n\n// Validate scenario\nconst validation = ScenarioLoader.validate(scenario);\nif (!validation.valid) {\n  console.error('Validation errors:', validation.errors);\n}\n</code></pre></p>"},{"location":"API_REFERENCE/#screenshot-management","title":"Screenshot Management","text":"<pre><code>export class ScreenshotManager {\n  async capturePageScreenshot(page: Page, options?: ScreenshotOptions): Promise&lt;ScreenshotMetadata&gt;;\n  async compareScreenshots(baseline: string, actual: string, options?: CompareOptions): Promise&lt;ComparisonResult&gt;;\n  async createDiff(baseline: string, actual: string, output: string, options?: DiffOptions): Promise&lt;string&gt;;\n  async batchCompareScreenshots(comparisons: BatchComparison[]): Promise&lt;ComparisonResult[]&gt;;\n}\n\ninterface ScreenshotOptions {\n  scenarioId?: string;\n  description?: string;\n  fullPage?: boolean;\n}\n\ninterface CompareOptions {\n  algorithm?: 'pixel-by-pixel' | 'perceptual' | 'structural';\n  threshold?: number;\n  includeAA?: boolean;\n  createDiffImage?: boolean;\n  colorOptions?: ColorOptions;\n}\n\ninterface ComparisonResult {\n  matches: boolean;\n  similarityPercentage: number;\n  differencePercentage: number;\n  diffImagePath?: string;\n  metadata: ComparisonMetadata;\n}\n</code></pre> <p>Examples: <pre><code>const screenshotManager = createScreenshotManager({\n  baseDir: './screenshots',\n  strategy: 'by-scenario'\n});\n\n// Compare screenshots\nconst comparison = await screenshotManager.compareScreenshots(\n  './baseline/login.png',\n  './actual/login.png',\n  {\n    algorithm: 'perceptual',\n    threshold: 0.05,\n    createDiffImage: true\n  }\n);\n\nconsole.log(`Match: ${comparison.matches} (${comparison.similarityPercentage}%)`);\n</code></pre></p>"},{"location":"API_REFERENCE/#integration-apis","title":"Integration APIs","text":""},{"location":"API_REFERENCE/#github-integration","title":"GitHub Integration","text":"<pre><code>export class GitHubIntegration {\n  constructor(config: GitHubConfig);\n\n  async createIssue(title: string, body: string, options?: IssueOptions): Promise&lt;number&gt;;\n  async updateIssue(issueNumber: number, updates: IssueUpdate): Promise&lt;void&gt;;\n  async closeIssue(issueNumber: number, reason?: string): Promise&lt;void&gt;;\n  async searchIssues(query: string): Promise&lt;GitHubIssue[]&gt;;\n  async uploadArtifact(filePath: string, description?: string): Promise&lt;string&gt;;\n}\n\ninterface IssueOptions {\n  labels?: string[];\n  assignees?: string[];\n  milestone?: number;\n}\n</code></pre>"},{"location":"API_REFERENCE/#websocket-integration","title":"WebSocket Integration","text":"<pre><code>export class WebSocketAgent implements IAgent {\n  constructor(config: WebSocketConfig);\n\n  async connect(): Promise&lt;void&gt;;\n  async disconnect(): Promise&lt;void&gt;;\n  async send(event: string, data: any): Promise&lt;void&gt;;\n  async waitForEvent(event: string, timeout?: number): Promise&lt;any&gt;;\n  async listenForEvents(events: string[], handler: EventHandler): Promise&lt;void&gt;;\n}\n\ninterface WebSocketConfig {\n  url: string;\n  protocols?: string[];\n  reconnect?: boolean;\n  reconnectAttempts?: number;\n  reconnectDelay?: number;\n}\n\ntype EventHandler = (event: string, data: any) =&gt; void;\n</code></pre>"},{"location":"API_REFERENCE/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>export class CIIntegration {\n  static detectEnvironment(): CIEnvironment;\n  static generateArtifacts(session: TestSession, outputDir: string): Promise&lt;void&gt;;\n  static publishResults(session: TestSession, config: PublishConfig): Promise&lt;void&gt;;\n}\n\ninterface CIEnvironment {\n  provider: 'github-actions' | 'jenkins' | 'azure-devops' | 'gitlab-ci' | 'unknown';\n  buildNumber?: string;\n  commitSha?: string;\n  branch?: string;\n  pullRequestNumber?: string;\n}\n</code></pre>"},{"location":"API_REFERENCE/#event-system","title":"Event System","text":"<p>All major components emit events for monitoring and integration.</p>"},{"location":"API_REFERENCE/#orchestrator-events","title":"Orchestrator Events","text":"<pre><code>orchestrator.on('session:start', (session: TestSession) =&gt; {\n  console.log(`Session ${session.id} started`);\n});\n\norchestrator.on('scenario:start', (scenario: TestScenario) =&gt; {\n  console.log(`Starting ${scenario.name}`);\n});\n\norchestrator.on('scenario:end', (scenario: TestScenario, result: TestResult) =&gt; {\n  console.log(`${scenario.name}: ${result.status} (${result.duration}ms)`);\n});\n\norchestrator.on('phase:start', (phase: string) =&gt; {\n  console.log(`Phase started: ${phase}`);\n});\n\norchestrator.on('error', (error: Error) =&gt; {\n  console.error('Orchestrator error:', error);\n});\n</code></pre>"},{"location":"API_REFERENCE/#agent-events","title":"Agent Events","text":"<pre><code>// ElectronUIAgent events\nuiAgent.on('initialized', () =&gt; console.log('UI Agent ready'));\nuiAgent.on('launched', () =&gt; console.log('Application launched'));\nuiAgent.on('screenshot', (path: string) =&gt; console.log(`Screenshot: ${path}`));\nuiAgent.on('websocket_connected', () =&gt; console.log('WebSocket connected'));\nuiAgent.on('websocket_event', (event: WebSocketEvent) =&gt; {\n  console.log(`WebSocket: ${event.type}`, event.data);\n});\n\n// CLIAgent events\ncliAgent.on('command_start', (command: string) =&gt; console.log(`Running: ${command}`));\ncliAgent.on('command_end', (command: string, result: CommandResult) =&gt; {\n  console.log(`Completed: ${command} (exit: ${result.exitCode})`);\n});\n</code></pre>"},{"location":"API_REFERENCE/#error-handling","title":"Error Handling","text":""},{"location":"API_REFERENCE/#error-types","title":"Error Types","text":"<pre><code>// Base error classes\nexport class GadugiError extends Error {\n  public readonly code: string;\n  public readonly context?: Record&lt;string, any&gt;;\n}\n\nexport class ConfigurationError extends GadugiError {\n  constructor(message: string, context?: Record&lt;string, any&gt;);\n}\n\nexport class ExecutionError extends GadugiError {\n  constructor(message: string, context?: Record&lt;string, any&gt;);\n}\n\nexport class TimeoutError extends GadugiError {\n  constructor(operation: string, timeout: number);\n}\n\nexport class ValidationError extends GadugiError {\n  constructor(message: string, errors: string[]);\n}\n</code></pre>"},{"location":"API_REFERENCE/#error-handling-patterns","title":"Error Handling Patterns","text":"<pre><code>// Graceful error handling with retry\ntry {\n  const result = await agent.execute(scenario);\n} catch (error) {\n  if (error instanceof TimeoutError) {\n    console.log('Operation timed out, retrying...');\n    // Retry logic\n  } else if (error instanceof ValidationError) {\n    console.error('Validation failed:', error.errors);\n    // Handle validation errors\n  } else {\n    console.error('Unexpected error:', error);\n    throw error;\n  }\n}\n\n// Global error handling\nprocess.on('unhandledRejection', (reason, promise) =&gt; {\n  console.error('Unhandled rejection at:', promise, 'reason:', reason);\n});\n</code></pre>"},{"location":"API_REFERENCE/#recovery-strategies","title":"Recovery Strategies","text":"<pre><code>// Configure automatic recovery\nconst agent = new ElectronUIAgent({\n  executablePath: '/path/to/app.exe',\n  recoveryConfig: {\n    maxRetries: 3,\n    retryDelay: 2000,\n    restartOnFailure: true\n  }\n});\n\n// Manual recovery\nasync function withRetry&lt;T&gt;(operation: () =&gt; Promise&lt;T&gt;, maxRetries: number = 3): Promise&lt;T&gt; {\n  let lastError: Error;\n\n  for (let attempt = 1; attempt &lt;= maxRetries; attempt++) {\n    try {\n      return await operation();\n    } catch (error) {\n      lastError = error as Error;\n      if (attempt === maxRetries) break;\n\n      const delay = Math.pow(2, attempt) * 1000; // Exponential backoff\n      await new Promise(resolve =&gt; setTimeout(resolve, delay));\n    }\n  }\n\n  throw lastError!;\n}\n</code></pre>"},{"location":"API_REFERENCE/#advanced-usage-examples","title":"Advanced Usage Examples","text":""},{"location":"API_REFERENCE/#custom-agent-creation","title":"Custom Agent Creation","text":"<pre><code>import { IAgent, AgentType, TestScenario, TestResult } from '@gadugi/agentic-test';\n\nclass CustomDatabaseAgent implements IAgent {\n  public readonly name = 'CustomDatabaseAgent';\n  public readonly type = AgentType.API;\n\n  async initialize(): Promise&lt;void&gt; {\n    // Initialize database connection\n  }\n\n  async execute(scenario: TestScenario): Promise&lt;TestResult&gt; {\n    // Execute database-specific test scenarios\n    return {\n      scenarioId: scenario.id,\n      status: TestStatus.PASSED,\n      duration: 1000\n    };\n  }\n\n  async cleanup(): Promise&lt;void&gt; {\n    // Close database connections\n  }\n}\n\n// Register custom agent\nconst orchestrator = new TestOrchestrator(config);\norchestrator.registerAgent(new CustomDatabaseAgent());\n</code></pre>"},{"location":"API_REFERENCE/#advanced-scenario-composition","title":"Advanced Scenario Composition","text":"<pre><code>// Programmatic scenario creation\nconst dynamicScenario: TestScenario = {\n  id: 'dynamic-test',\n  name: 'Dynamic User Test',\n  steps: [\n    {\n      action: 'launch_electron',\n      target: ''\n    },\n    ...users.map(user =&gt; ({\n      action: 'test_user_flow',\n      target: user.id,\n      value: JSON.stringify(user)\n    }))\n  ]\n};\n\n// Scenario composition\nfunction createLoginScenario(username: string, password: string): TestScenario {\n  return {\n    id: `login-${username}`,\n    name: `Login Test for ${username}`,\n    steps: [\n      { action: 'launch_electron', target: '' },\n      { action: 'fill', target: '[data-testid=\"username\"]', value: username },\n      { action: 'fill', target: '[data-testid=\"password\"]', value: password },\n      { action: 'click', target: '[data-testid=\"login-btn\"]' },\n      { action: 'wait_for_element', target: '[data-testid=\"dashboard\"]' }\n    ]\n  };\n}\n</code></pre>"},{"location":"API_REFERENCE/#plugin-system","title":"Plugin System","text":"<pre><code>// Plugin interface\ninterface GadugiPlugin {\n  name: string;\n  version: string;\n  install(orchestrator: TestOrchestrator): Promise&lt;void&gt;;\n  uninstall(orchestrator: TestOrchestrator): Promise&lt;void&gt;;\n}\n\n// Example plugin\nclass ReportingPlugin implements GadugiPlugin {\n  name = 'ReportingPlugin';\n  version = '1.0.0';\n\n  async install(orchestrator: TestOrchestrator): Promise&lt;void&gt; {\n    orchestrator.on('session:end', this.generateReport);\n  }\n\n  async uninstall(orchestrator: TestOrchestrator): Promise&lt;void&gt; {\n    orchestrator.off('session:end', this.generateReport);\n  }\n\n  private generateReport = (session: TestSession) =&gt; {\n    // Generate custom reports\n  };\n}\n\n// Use plugin\nconst plugin = new ReportingPlugin();\nawait plugin.install(orchestrator);\n</code></pre>"},{"location":"API_REFERENCE/#base-classes","title":"Base Classes","text":""},{"location":"API_REFERENCE/#baseagent","title":"BaseAgent","text":"<p>Abstract base class that all test-executing agents extend. Implements the <code>IAgent</code> interface using the template-method pattern, providing a shared <code>execute()</code> loop and requiring subclasses to implement <code>executeStep()</code> and <code>buildResult()</code>.</p> <pre><code>import { EventEmitter } from 'events';\nimport { IAgent, AgentType } from '@gadugi/agentic-test';\n\nabstract class BaseAgent extends EventEmitter implements IAgent {\n  abstract readonly name: string;\n  abstract readonly type: AgentType;\n\n  abstract initialize(): Promise&lt;void&gt;;\n  abstract cleanup(): Promise&lt;void&gt;;\n  abstract executeStep(step: any, index: number): Promise&lt;StepResult&gt;;\n  protected abstract buildResult(ctx: ExecutionContext): unknown;\n\n  // Shared concrete implementation - runs all steps in order\n  async execute(scenario: OrchestratorScenario): Promise&lt;unknown&gt;;\n\n  // Optional lifecycle hooks\n  protected applyEnvironment(scenario: OrchestratorScenario): void;\n  protected onBeforeExecute(scenario: OrchestratorScenario): void;\n  protected async onAfterExecute(scenario: OrchestratorScenario, status: TestStatus): Promise&lt;void&gt;;\n}\n</code></pre> <p>Example - creating a custom agent: <pre><code>import { BaseAgent, AgentType, ExecutionContext, StepResult, OrchestratorScenario } from '@gadugi/agentic-test';\n\nclass CustomAgent extends BaseAgent {\n  readonly name = 'CustomAgent';\n  readonly type = AgentType.CLI;\n\n  async initialize(): Promise&lt;void&gt; {\n    this.isInitialized = true;\n  }\n\n  async cleanup(): Promise&lt;void&gt; {}\n\n  async executeStep(step: any, index: number): Promise&lt;StepResult&gt; {\n    return { status: 'passed', duration: 0, stepIndex: index };\n  }\n\n  protected buildResult(ctx: ExecutionContext) {\n    return { ...ctx };\n  }\n}\n</code></pre></p>"},{"location":"API_REFERENCE/#shared-utility-apis","title":"Shared Utility APIs","text":""},{"location":"API_REFERENCE/#generateidprefix-string-string","title":"<code>generateId(prefix?: string): string</code>","text":"<p>Located in <code>src/utils/ids.ts</code>. Generates a unique identifier using a timestamp and random segment, optionally prefixed.</p> <pre><code>import { generateId } from '@gadugi/agentic-test';\n\ngenerateId();          // \"1714000000000_k3j8f9d2x\"\ngenerateId('conn');    // \"conn_1714000000000_k3j8f9d2x\"\ngenerateId('tui');     // \"tui_1714000000000_k3j8f9d2x\"\n</code></pre>"},{"location":"API_REFERENCE/#sanitizeconfigwithenvconfig-envfield","title":"<code>sanitizeConfigWithEnv(config, envField)</code>","text":"<p>Located in <code>src/utils/agentUtils.ts</code>. Returns a safe copy of an agent config object where environment variable values are replaced by their key names (preventing secrets from appearing in logs).</p> <pre><code>import { sanitizeConfigWithEnv } from '@gadugi/agentic-test';\n\nconst safeConfig = sanitizeConfigWithEnv(this.config, 'environment');\n// { ...config, environment: ['API_KEY', 'DB_PASSWORD'] }  // values removed, keys retained\n\nconst safeElectronConfig = sanitizeConfigWithEnv(this.config, 'env');\n// { ...config, env: ['NODE_ENV', 'DISPLAY'] }\n</code></pre>"},{"location":"API_REFERENCE/#validatedirectorydirpath-string-promisevoid","title":"<code>validateDirectory(dirPath: string): Promise&lt;void&gt;</code>","text":"<p>Located in <code>src/utils/fileUtils.ts</code>. Verifies that <code>dirPath</code> exists and is a directory. Throws if the path does not exist or is not a directory.</p> <pre><code>import { validateDirectory } from '@gadugi/agentic-test';\n\nawait validateDirectory('./screenshots');\n// Throws: Error: Path \"./missing\" does not exist or is not a directory\n</code></pre> <p>This API reference provides comprehensive documentation for all public interfaces in the Gadugi Agentic Test framework. For additional examples and advanced usage patterns, see the examples directory and scenario samples.</p> <p>For questions or clarifications about any API, please open an issue on GitHub.</p>"},{"location":"ARCHITECTURE/","title":"Architecture \u2014 @gadugi/agentic-test","text":"<p>Type: Explanation (Diataxis) Updated: 2026-02-22</p>"},{"location":"ARCHITECTURE/#contents","title":"Contents","text":"<ul> <li>Overview</li> <li>Directory Structure</li> <li>Agent Layer</li> <li>Core Layer</li> <li>Runners</li> <li>Orchestrator</li> <li>Utils</li> <li>Models</li> <li>Programmatic API</li> <li>CLI</li> <li>BaseAgent Pattern</li> <li>Module Philosophy</li> <li>Data Flow</li> </ul>"},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p><code>@gadugi/agentic-test</code> is a layered, multi-agent testing framework for Electron and TUI applications. Each layer has a single responsibility and depends only on layers below it.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  CLI  (src/cli.ts + src/cli/)           \u2502  Entry point, Commander commands\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Programmatic API  (src/lib.ts)         \u2502  Signal-handler-free runTests()\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Orchestrator  (src/orchestrator/)      \u2502  Scenario routing, session, results\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Agents  (src/agents/)                  \u2502  9 specialised test executors\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Runners  (src/runners/)                \u2502  UI test runners (Electron/Playwright)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Core  (src/core/)                      \u2502  PTY, processes, waiting, resources\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Utils  (src/utils/)                    \u2502  Logging, config, retry, screenshots\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Models  (src/models/)                  \u2502  Data types shared across all layers\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#directory-structure","title":"Directory Structure","text":"<pre><code>src/\n\u251c\u2500\u2500 index.ts                   # Full public API re-export\n\u251c\u2500\u2500 lib.ts                     # Programmatic API (no process side-effects)\n\u251c\u2500\u2500 lib/\n\u2502   \u251c\u2500\u2500 ConfigurationLoader.ts # Default config factory + file loading\n\u2502   \u251c\u2500\u2500 ScenarioLoader.ts      # YAML scenario discovery + suite filtering\n\u2502   \u2514\u2500\u2500 ResultsHandler.ts      # Result persistence + display + dry-run\n\u251c\u2500\u2500 cli.ts                     # CLI entry point (Commander)\n\u251c\u2500\u2500 cli-path-utils.ts          # Path traversal guard for CLI flags\n\u251c\u2500\u2500 cli/\n\u2502   \u251c\u2500\u2500 output.ts              # Shared print helpers (logSuccess, logError\u2026)\n\u2502   \u2514\u2500\u2500 commands/\n\u2502       \u251c\u2500\u2500 run.ts             # agentic-test run\n\u2502       \u251c\u2500\u2500 watch.ts           # agentic-test watch\n\u2502       \u251c\u2500\u2500 validate.ts        # agentic-test validate\n\u2502       \u251c\u2500\u2500 list.ts            # agentic-test list\n\u2502       \u251c\u2500\u2500 init.ts            # agentic-test init\n\u2502       \u251c\u2500\u2500 init-templates.ts  # Scenario template generator\n\u2502       \u2514\u2500\u2500 help.ts            # agentic-test help\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 index.ts               # IAgent interface, AgentType enum, all exports\n\u2502   \u251c\u2500\u2500 BaseAgent.ts           # Abstract base \u2014 shared execute() loop\n\u2502   \u251c\u2500\u2500 TUIAgent.ts            # Terminal-UI test execution\n\u2502   \u251c\u2500\u2500 CLIAgent.ts            # CLI subprocess testing\n\u2502   \u251c\u2500\u2500 APIAgent.ts            # HTTP/REST API testing\n\u2502   \u251c\u2500\u2500 WebSocketAgent.ts      # WebSocket protocol testing\n\u2502   \u251c\u2500\u2500 ElectronUIAgent.ts     # Electron app UI testing\n\u2502   \u251c\u2500\u2500 ComprehensionAgent.ts  # LLM-powered feature discovery\n\u2502   \u251c\u2500\u2500 IssueReporter.ts       # GitHub issue creation\n\u2502   \u251c\u2500\u2500 PriorityAgent.ts       # Test prioritisation\n\u2502   \u251c\u2500\u2500 SystemAgent.ts         # System resource monitoring\n\u2502   \u251c\u2500\u2500 tui/                   # TUIAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 TUIInputSimulator.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUIMenuNavigator.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUIOutputParser.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUISessionManager.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUIStepDispatcher.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 cli/                   # CLIAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 CLICommandRunner.ts\n\u2502   \u2502   \u251c\u2500\u2500 CLIOutputParser.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 api/                   # APIAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 APIAuthHandler.ts\n\u2502   \u2502   \u251c\u2500\u2500 APIRequestExecutor.ts\n\u2502   \u2502   \u251c\u2500\u2500 APIResponseValidator.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 websocket/             # WebSocketAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 WebSocketConnection.ts\n\u2502   \u2502   \u251c\u2500\u2500 WebSocketEventRecorder.ts\n\u2502   \u2502   \u251c\u2500\u2500 WebSocketMessageHandler.ts\n\u2502   \u2502   \u251c\u2500\u2500 WebSocketStepExecutor.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 electron/              # ElectronUIAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 ElectronLauncher.ts\n\u2502   \u2502   \u251c\u2500\u2500 ElectronPageInteractor.ts\n\u2502   \u2502   \u251c\u2500\u2500 ElectronPerformanceMonitor.ts\n\u2502   \u2502   \u251c\u2500\u2500 ElectronWebSocketMonitor.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 comprehension/         # ComprehensionAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 DocumentationLoader.ts\n\u2502   \u2502   \u251c\u2500\u2500 OutputComprehender.ts\n\u2502   \u2502   \u251c\u2500\u2500 ScenarioComprehender.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 issue/                 # IssueReporter sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 IssueDeduplicator.ts\n\u2502   \u2502   \u251c\u2500\u2500 IssueFormatter.ts\n\u2502   \u2502   \u251c\u2500\u2500 IssueSubmitter.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 priority/              # PriorityAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 PriorityAnalyzer.ts\n\u2502   \u2502   \u251c\u2500\u2500 PriorityPatternExtractor.ts\n\u2502   \u2502   \u251c\u2500\u2500 PriorityQueue.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 system/                # SystemAgent sub-modules\n\u2502   \u2502   \u251c\u2500\u2500 MetricsCollector.ts\n\u2502   \u2502   \u251c\u2500\u2500 DockerMonitor.ts\n\u2502   \u2502   \u251c\u2500\u2500 FileSystemWatcher.ts\n\u2502   \u2502   \u251c\u2500\u2500 SystemAnalyzer.ts\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u2514\u2500\u2500 examples/              # Runnable usage examples per agent\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 PtyTerminal.ts         # PTY process wrapper (node-pty)\n\u2502   \u251c\u2500\u2500 AdaptiveWaiter.ts      # Condition-based waiting + backoff\n\u2502   \u251c\u2500\u2500 ProcessLifecycleManager.ts  # Zombie-process prevention\n\u2502   \u251c\u2500\u2500 ResourceOptimizer.ts   # CPU/memory/concurrency optimisation\n\u2502   \u2514\u2500\u2500 optimizer/             # ResourceOptimizer sub-modules\n\u2502       \u251c\u2500\u2500 ConcurrencyOptimizer.ts\n\u2502       \u251c\u2500\u2500 CpuOptimizer.ts\n\u2502       \u251c\u2500\u2500 MemoryOptimizer.ts\n\u2502       \u251c\u2500\u2500 types.ts\n\u2502       \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 orchestrator/\n\u2502   \u251c\u2500\u2500 TestOrchestrator.ts    # Thin facade: routes + sessions + results\n\u2502   \u251c\u2500\u2500 ScenarioRouter.ts      # Dispatches scenarios to agents (parallel)\n\u2502   \u251c\u2500\u2500 SessionManager.ts      # Session lifecycle and persistence\n\u2502   \u251c\u2500\u2500 ResultAggregator.ts    # Collects results, triggers analysis/reporting\n\u2502   \u251c\u2500\u2500 agentAdapters.ts       # Config shape adapters (UI/TUI/priority)\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 runners/\n\u2502   \u251c\u2500\u2500 SmartUITestRunner.ts      # Playwright-based adaptive UI runner\n\u2502   \u251c\u2500\u2500 ComprehensiveUITestRunner.ts  # Exhaustive UI flow runner\n\u2502   \u251c\u2500\u2500 smart/\n\u2502   \u2502   \u251c\u2500\u2500 SmartElementFinder.ts\n\u2502   \u2502   \u251c\u2500\u2500 SmartInteractionExecutor.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 comprehensive/\n\u2502   \u2502   \u251c\u2500\u2500 UIFlowTester.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 scenarios/\n\u2502   \u2514\u2500\u2500 index.ts               # ScenarioDefinition schema + ScenarioLoader\n\u251c\u2500\u2500 adapters/\n\u2502   \u2514\u2500\u2500 scenarioAdapter.ts     # ScenarioDefinition \u2192 OrchestratorScenario\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 TestModels.ts          # OrchestratorScenario, TestSession, TestResult\n\u2502   \u251c\u2500\u2500 Config.ts              # TestConfig (top-level config shape)\n\u2502   \u251c\u2500\u2500 AppState.ts            # Runtime application state\n\u2502   \u251c\u2500\u2500 TUIModels.ts           # TUI-specific model facade\n\u2502   \u251c\u2500\u2500 tui/\n\u2502   \u2502   \u251c\u2500\u2500 TUIConfig.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUIResults.ts\n\u2502   \u2502   \u251c\u2500\u2500 TUISession.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 logger.ts              # Logger facade\n    \u251c\u2500\u2500 config.ts              # Config utilities facade\n    \u251c\u2500\u2500 fileUtils.ts           # File utilities facade\n    \u251c\u2500\u2500 yamlParser.ts          # YAML parser facade\n    \u251c\u2500\u2500 retry.ts               # Retry facade\n    \u251c\u2500\u2500 async.ts               # delay() and async helpers\n    \u251c\u2500\u2500 comparison.ts          # deepEqual() utility\n    \u251c\u2500\u2500 colors.ts              # Terminal color helpers\n    \u251c\u2500\u2500 ids.ts                 # ID generation\n    \u251c\u2500\u2500 agentUtils.ts          # Shared agent utility functions\n    \u251c\u2500\u2500 index.ts\n    \u251c\u2500\u2500 logging/\n    \u2502   \u251c\u2500\u2500 LogFormatter.ts\n    \u2502   \u251c\u2500\u2500 LogTransport.ts\n    \u2502   \u2514\u2500\u2500 index.ts\n    \u251c\u2500\u2500 config/\n    \u2502   \u251c\u2500\u2500 ConfigLoader.ts\n    \u2502   \u251c\u2500\u2500 ConfigManager.ts\n    \u2502   \u251c\u2500\u2500 ConfigValidator.ts\n    \u2502   \u251c\u2500\u2500 types.ts\n    \u2502   \u2514\u2500\u2500 index.ts\n    \u251c\u2500\u2500 files/\n    \u2502   \u251c\u2500\u2500 FileArchiver.ts\n    \u2502   \u251c\u2500\u2500 FileReader.ts\n    \u2502   \u251c\u2500\u2500 FileSearch.ts\n    \u2502   \u251c\u2500\u2500 FileWriter.ts\n    \u2502   \u251c\u2500\u2500 types.ts\n    \u2502   \u2514\u2500\u2500 index.ts\n    \u251c\u2500\u2500 retry/\n    \u2502   \u251c\u2500\u2500 CircuitBreaker.ts\n    \u2502   \u251c\u2500\u2500 RetryExecutor.ts\n    \u2502   \u251c\u2500\u2500 types.ts\n    \u2502   \u2514\u2500\u2500 index.ts\n    \u251c\u2500\u2500 screenshot/\n    \u2502   \u251c\u2500\u2500 ScreenshotCapture.ts\n    \u2502   \u251c\u2500\u2500 ImageComparator.ts\n    \u2502   \u251c\u2500\u2500 DiffRenderer.ts\n    \u2502   \u251c\u2500\u2500 ScreenshotReporter.ts\n    \u2502   \u251c\u2500\u2500 types.ts\n    \u2502   \u2514\u2500\u2500 index.ts\n    \u2514\u2500\u2500 yaml/\n        \u251c\u2500\u2500 YamlLoader.ts\n        \u251c\u2500\u2500 YamlValidator.ts\n        \u251c\u2500\u2500 YamlVariableSubstitution.ts\n        \u251c\u2500\u2500 types.ts\n        \u2514\u2500\u2500 index.ts\n</code></pre>"},{"location":"ARCHITECTURE/#agent-layer","title":"Agent Layer","text":"<p>All nine agents implement the <code>IAgent&lt;TScenario, TResult&gt;</code> interface and extend <code>BaseAgent</code>. Each agent is responsible for one execution domain.</p> <pre><code>export interface IAgent&lt;TScenario = unknown, TResult = unknown&gt; {\n  name: string;\n  type: string;\n  initialize(): Promise&lt;void&gt;;\n  execute(scenario: TScenario): Promise&lt;TResult&gt;;\n  cleanup(): Promise&lt;void&gt;;\n}\n\nexport enum AgentType {\n  UI          = 'ui',\n  CLI         = 'cli',\n  TUI         = 'tui',\n  API         = 'api',\n  WEBSOCKET   = 'websocket',\n  GITHUB      = 'github',\n  SYSTEM      = 'system',\n  COMPREHENSION = 'comprehension',\n  PRIORITY    = 'priority',\n}\n</code></pre>"},{"location":"ARCHITECTURE/#tuiagent-srcagentstuiagentts","title":"TUIAgent \u2014 <code>src/agents/TUIAgent.ts</code>","text":"<p>Executes test scenarios against terminal-based (TUI) applications via a PTY session. Uses <code>PtyTerminal</code> for PTY management, delegating input simulation, menu navigation, output parsing, and step dispatch to focused sub-modules.</p> <p>Sub-modules: <code>TUIInputSimulator</code>, <code>TUIMenuNavigator</code>, <code>TUIOutputParser</code>, <code>TUISessionManager</code>, <code>TUIStepDispatcher</code>.</p>"},{"location":"ARCHITECTURE/#cliagent-srcagentscliagentts","title":"CLIAgent \u2014 <code>src/agents/CLIAgent.ts</code>","text":"<p>Spawns CLI subprocesses and validates their output and exit codes. Handles streaming stdout/stderr, environment variable injection (into the child process only \u2014 never mutating <code>process.env</code>), and command history.</p> <p>Sub-modules: <code>CLICommandRunner</code>, <code>CLIOutputParser</code>.</p>"},{"location":"ARCHITECTURE/#apiagent-srcagentsapiagentts","title":"APIAgent \u2014 <code>src/agents/APIAgent.ts</code>","text":"<p>Tests HTTP/REST APIs. Supports authentication (Bearer, Basic, API key), request and response interceptors, JSON Schema validation, and performance measurement.</p> <p>Sub-modules: <code>APIAuthHandler</code>, <code>APIRequestExecutor</code>, <code>APIResponseValidator</code>.</p>"},{"location":"ARCHITECTURE/#websocketagent-srcagentswebsocketagentts","title":"WebSocketAgent \u2014 <code>src/agents/WebSocketAgent.ts</code>","text":"<p>Tests WebSocket connections: connection lifecycle, message send/receive, event recording, and reconnection with configurable backoff.</p> <p>Sub-modules: <code>WebSocketConnection</code>, <code>WebSocketEventRecorder</code>, <code>WebSocketMessageHandler</code>, <code>WebSocketStepExecutor</code>.</p>"},{"location":"ARCHITECTURE/#electronuiagent-srcagentselectronuiagentts","title":"ElectronUIAgent \u2014 <code>src/agents/ElectronUIAgent.ts</code>","text":"<p>Drives Electron applications via Playwright. Handles app launch, page interaction, performance sampling, and WebSocket monitoring (delegated to <code>WebSocketAgent</code>).</p> <p>Sub-modules: <code>ElectronLauncher</code>, <code>ElectronPageInteractor</code>, <code>ElectronPerformanceMonitor</code>, <code>ElectronWebSocketMonitor</code>.</p>"},{"location":"ARCHITECTURE/#comprehensionagent-srcagentscomprehensionagentts","title":"ComprehensionAgent \u2014 <code>src/agents/ComprehensionAgent.ts</code>","text":"<p>Uses an LLM (OpenAI-compatible) to discover and understand application features from documentation and runtime output. Converts discoveries into structured <code>FeatureSpec</code> objects.</p> <p>Sub-modules: <code>DocumentationLoader</code>, <code>OutputComprehender</code>, <code>ScenarioComprehender</code>.</p>"},{"location":"ARCHITECTURE/#issuereporter-srcagentsissuereporterts","title":"IssueReporter \u2014 <code>src/agents/IssueReporter.ts</code>","text":"<p>Creates, deduplicates, and updates GitHub issues for test failures. Uses SHA-256 fingerprinting for deduplication. Applies an allowlist (<code>getSafeEnvironment()</code>) when embedding environment data in issue bodies to prevent secret exposure.</p> <p>Sub-modules: <code>IssueDeduplicator</code>, <code>IssueFormatter</code>, <code>IssueSubmitter</code>.</p>"},{"location":"ARCHITECTURE/#priorityagent-srcagentspriorityagentts","title":"PriorityAgent \u2014 <code>src/agents/PriorityAgent.ts</code>","text":"<p>Assigns priority scores to test scenarios based on configurable rules, historical failure patterns, and flaky-test detection. Feeds scores back to the orchestrator's scheduling decisions.</p> <p>Sub-modules: <code>PriorityAnalyzer</code>, <code>PriorityPatternExtractor</code>, <code>PriorityQueue</code>.</p>"},{"location":"ARCHITECTURE/#systemagent-srcagentssystemagentts","title":"SystemAgent \u2014 <code>src/agents/SystemAgent.ts</code>","text":"<p>Monitors system resources (CPU, memory, disk, network) and Docker containers during test runs. Detects resource leaks and performance regressions against stored baselines.</p> <p>Sub-modules: <code>MetricsCollector</code>, <code>DockerMonitor</code>, <code>FileSystemWatcher</code>, <code>SystemAnalyzer</code>.</p>"},{"location":"ARCHITECTURE/#core-layer","title":"Core Layer","text":""},{"location":"ARCHITECTURE/#ptyterminal-srccoreptyterminalts","title":"PtyTerminal \u2014 <code>src/core/PtyTerminal.ts</code>","text":"<p>PTY-based terminal manager wrapping <code>node-pty-prebuilt-multiarch</code>. Maintains an output buffer, emits typed events (<code>data</code>, <code>exit</code>, <code>error</code>, <code>ready</code>, <code>destroyed</code>), and integrates with <code>ProcessLifecycleManager</code> to prevent zombie processes.</p> <pre><code>const terminal = new PtyTerminal({ shell: '/bin/bash', cwd: '/tmp' });\nawait terminal.spawn();\nterminal.write('ls -la\\n');\nterminal.on('data', (chunk) =&gt; process.stdout.write(chunk));\nawait terminal.destroy();\n</code></pre>"},{"location":"ARCHITECTURE/#adaptivewaiter-srccoreadaptivewaiterts","title":"AdaptiveWaiter \u2014 <code>src/core/AdaptiveWaiter.ts</code>","text":"<p>Condition-based waiting with configurable backoff strategies. Replaces hard-coded <code>setTimeout</code> calls throughout the codebase.</p> <pre><code>import { waitForOutput, delay, BackoffStrategy } from './core/AdaptiveWaiter';\n\n// Wait until the terminal buffer contains 'ready'\nawait waitForOutput(terminal, 'ready', { timeout: 10_000 });\n\n// Pause for 500 ms\nawait delay(500);\n</code></pre> <p>Exported strategies: <code>LINEAR</code>, <code>EXPONENTIAL</code>, <code>FIXED</code>.</p>"},{"location":"ARCHITECTURE/#processlifecyclemanager-srccoreprocesslifecyclemanagerts","title":"ProcessLifecycleManager \u2014 <code>src/core/ProcessLifecycleManager.ts</code>","text":"<p>Tracks spawned child processes and ensures they are terminated (with escalating signals) on test completion or process exit. Prevents zombie processes that would accumulate across long test runs.</p>"},{"location":"ARCHITECTURE/#resourceoptimizer-srccoreresourceoptimizerts","title":"ResourceOptimizer \u2014 <code>src/core/ResourceOptimizer.ts</code>","text":"<p>Monitors and adjusts concurrency, CPU usage, and memory pressure during test runs. Provides a resource pool abstraction consumed by <code>ScenarioRouter</code>.</p> <p>Sub-modules: <code>ConcurrencyOptimizer</code>, <code>CpuOptimizer</code>, <code>MemoryOptimizer</code>.</p>"},{"location":"ARCHITECTURE/#runners","title":"Runners","text":"<p>Runners are higher-level test execution strategies built on top of Playwright. They are used by <code>ElectronUIAgent</code> for complex UI interaction flows.</p>"},{"location":"ARCHITECTURE/#smartuitestrunner-srcrunnerssmartuitestrunnerts","title":"SmartUITestRunner \u2014 <code>src/runners/SmartUITestRunner.ts</code>","text":"<p>Adaptive runner that locates UI elements dynamically using multiple selector strategies. Falls back gracefully when preferred selectors are absent.</p> <p>Sub-modules: <code>SmartElementFinder</code>, <code>SmartInteractionExecutor</code>.</p>"},{"location":"ARCHITECTURE/#comprehensiveuitestrunner-srcrunnerscomprehensiveuitestrunnerts","title":"ComprehensiveUITestRunner \u2014 <code>src/runners/ComprehensiveUITestRunner.ts</code>","text":"<p>Exhaustive runner that walks complete UI flows: every control in every view. Used for regression passes, not smoke tests.</p> <p>Sub-modules: <code>UIFlowTester</code>.</p>"},{"location":"ARCHITECTURE/#orchestrator","title":"Orchestrator","text":"<p><code>TestOrchestrator</code> is a thin facade that coordinates three focused sub-systems.</p> <pre><code>graph TD\n    CLI[\"CLI / runTests()\"] --&gt; Orchestrator\n    Orchestrator --&gt; ScenarioRouter\n    Orchestrator --&gt; SessionManager\n    Orchestrator --&gt; ResultAggregator\n\n    ScenarioRouter --&gt; Registry[\"agentRegistry: Partial&amp;lt;Record&amp;lt;TestInterface, IAgent&amp;gt;&amp;gt;\"]\n    Registry --&gt; TUIAgent\n    Registry --&gt; CLIAgent\n    Registry --&gt; ElectronUIAgent\n    Registry --&gt; APIAgent\n\n    ResultAggregator --&gt; PriorityAgent\n    ResultAggregator --&gt; IssueReporter\n</code></pre>"},{"location":"ARCHITECTURE/#scenariorouter-srcorchestratorscenariorouterts","title":"ScenarioRouter \u2014 <code>src/orchestrator/ScenarioRouter.ts</code>","text":"<p>Dispatches scenarios to the correct agent based on the scenario's <code>interface</code> field using an IAgent registry (<code>Partial&lt;Record&lt;TestInterface, IAgent&gt;&gt;</code>).</p> <p>The registry is built by <code>TestOrchestrator</code> in its constructor and passed to <code>ScenarioRouter</code>. This decoupling means:</p> <ul> <li><code>ScenarioRouter</code> has no imports of concrete agent classes</li> <li>Adding support for a new <code>TestInterface</code> value (e.g. <code>WEBSOCKET</code>) only requires   registering an entry in <code>TestOrchestrator</code> \u2014 <code>ScenarioRouter</code> needs no changes</li> <li>All five interface types route correctly: <code>CLI</code>, <code>TUI</code>, <code>API</code> (parallel), <code>GUI</code>   (sequential with initialize/cleanup), and <code>MIXED</code> (per-scenario selection)</li> <li>Unregistered interface types are reported as explicit failures, never silently dropped</li> </ul> <p>Enforces the <code>maxParallel</code> concurrency limit. Aborts remaining scenarios when <code>failFast</code> is set and a scenario fails.</p>"},{"location":"ARCHITECTURE/#sessionmanager-srcorchestratorsessionmanagerts","title":"SessionManager \u2014 <code>src/orchestrator/SessionManager.ts</code>","text":"<p>Creates and persists <code>TestSession</code> records. Accumulates <code>TestResult</code> entries as scenarios complete. Marks the session <code>complete</code> in the finally block of every run.</p>"},{"location":"ARCHITECTURE/#resultaggregator-srcorchestratorresultaggregatorts","title":"ResultAggregator \u2014 <code>src/orchestrator/ResultAggregator.ts</code>","text":"<p>Collects <code>TestResult</code> objects, invokes <code>PriorityAgent.analyze()</code> to score failures, and calls <code>IssueReporter</code> when <code>createIssuesOnFailure</code> is enabled.</p>"},{"location":"ARCHITECTURE/#orchestrator-events","title":"Orchestrator Events","text":"<p><code>TestOrchestrator</code> extends <code>EventEmitter</code> and emits:</p> Event Payload <code>session:start</code> <code>TestSession</code> <code>session:end</code> <code>TestSession</code> <code>scenario:start</code> <code>OrchestratorScenario</code> <code>scenario:end</code> <code>OrchestratorScenario, TestResult</code> <code>phase:start</code> <code>string</code> (phase name) <code>phase:end</code> <code>string</code> (phase name) <code>error</code> <code>Error</code>"},{"location":"ARCHITECTURE/#utils","title":"Utils","text":"<p>All utility modules follow the facade pattern: a top-level file (e.g. <code>logger.ts</code>) re-exports from a focused sub-directory (<code>logging/</code>).</p> Facade Sub-directory Responsibility <code>utils/logger.ts</code> <code>logging/</code> Structured logging, log levels, transports <code>utils/config.ts</code> <code>config/</code> Config loading, validation, management <code>utils/fileUtils.ts</code> <code>files/</code> File read, write, search, archive <code>utils/yamlParser.ts</code> <code>yaml/</code> Safe YAML load (<code>JSON_SCHEMA</code>), variable substitution <code>utils/retry.ts</code> <code>retry/</code> Retry executor, circuit breaker \u2014 <code>screenshot/</code> Capture, compare, diff, report <p>Shared helpers (no sub-directory):</p> <ul> <li><code>utils/async.ts</code> \u2014 <code>delay(ms)</code>: single canonical async sleep</li> <li><code>utils/comparison.ts</code> \u2014 <code>deepEqual(a, b)</code>: single canonical deep equality check</li> <li><code>utils/agentUtils.ts</code> \u2014 agent utility functions shared by <code>BaseAgent</code> sub-classes</li> </ul>"},{"location":"ARCHITECTURE/#models","title":"Models","text":"<pre><code>models/\n\u251c\u2500\u2500 Config.ts        # TestConfig \u2014 top-level configuration shape\n\u251c\u2500\u2500 TestModels.ts    # OrchestratorScenario, TestSession, TestResult,\n\u2502                    # TestStatus, TestFailure, StepResult\n\u251c\u2500\u2500 AppState.ts      # Runtime state for the running application under test\n\u251c\u2500\u2500 TUIModels.ts     # TUI-specific model facade\n\u2514\u2500\u2500 tui/\n    \u251c\u2500\u2500 TUIConfig.ts\n    \u251c\u2500\u2500 TUIResults.ts\n    \u2514\u2500\u2500 TUISession.ts\n</code></pre> <p>Type naming convention:</p> Type Location Purpose <code>ScenarioDefinition</code> <code>src/scenarios/</code> YAML schema type (what users write) <code>OrchestratorScenario</code> <code>src/models/TestModels</code> Internal execution type (post-adapter) <code>TestConfig</code> <code>src/models/Config</code> Full runtime configuration <code>TestSession</code> <code>src/models/TestModels</code> A single test run with all results <code>TestResult</code> <code>src/models/TestModels</code> Result of one scenario execution <p><code>ScenarioDefinition</code> is adapted to <code>OrchestratorScenario</code> by <code>src/adapters/scenarioAdapter.ts</code> before dispatch.</p>"},{"location":"ARCHITECTURE/#programmatic-api","title":"Programmatic API","text":"<p><code>src/lib.ts</code> is the side-effect-free programmatic entry point. It does not install signal handlers, process listeners, or Commander \u2014 those belong exclusively in <code>src/cli.ts</code>.</p> <pre><code>import { runTests, createDefaultConfig } from '@gadugi/agentic-test';\n\n// Minimal: run smoke suite with default config\nconst session = await runTests({ suite: 'smoke' });\nconsole.log(`Passed: ${session.summary.passed}/${session.summary.total}`);\n\n// Full options\nconst session = await runTests({\n  configPath: './config/test-config.yaml',\n  suite: 'regression',\n  scenarioFiles: ['scenarios/login.yaml', 'scenarios/dashboard.yaml'],\n  outputFile: 'results/run.json',\n  dryRun: false,\n});\n</code></pre> <p>For callers that need graceful shutdown (signal handling), call <code>setupGracefulShutdown(orchestrator)</code> explicitly \u2014 it is not called inside <code>runTests()</code>.</p> <p><code>src/lib/</code> sub-modules:</p> Module Responsibility <code>ConfigurationLoader</code> <code>createDefaultConfig()</code>, <code>loadConfiguration(path)</code> <code>ScenarioLoader</code> <code>loadTestScenarios(files)</code>, <code>filterScenariosForSuite()</code>, <code>TEST_SUITES</code> <code>ResultsHandler</code> <code>saveResults()</code>, <code>displayResults()</code>, <code>performDryRun()</code>"},{"location":"ARCHITECTURE/#cli","title":"CLI","text":"<p><code>src/cli.ts</code> is the only Commander entry point. All command logic lives in <code>src/cli/commands/</code>.</p> <pre><code>agentic-test run       # Run test scenarios\nagentic-test watch     # Watch for scenario file changes and re-run\nagentic-test validate  # Validate scenario YAML files\nagentic-test list      # List discovered scenarios\nagentic-test init      # Scaffold a new scenario file\nagentic-test help      # Show help\n</code></pre> <p>Global flags (available on every command):</p> Flag Description <code>--verbose</code> Enable verbose logging <code>--debug</code> Enable debug logging <code>--no-color</code> Disable coloured output <code>--env &lt;file&gt;</code> Load environment variables from file <p><code>run</code> command flags:</p> Flag Default Description <code>-s, --scenario &lt;name&gt;</code> \u2014 Run a specific scenario by name <code>-d, --directory &lt;path&gt;</code> <code>./scenarios</code> Scenarios directory <code>-c, --config &lt;file&gt;</code> auto-detected Configuration file <code>--parallel</code> false Run scenarios in parallel <code>--timeout &lt;ms&gt;</code> <code>300000</code> Global timeout <p>All path flags (<code>--directory</code>, <code>--file</code>, <code>--config</code>, <code>--env</code>) are validated through <code>src/cli-path-utils.ts</code> to prevent path traversal attacks.</p>"},{"location":"ARCHITECTURE/#baseagent-pattern","title":"BaseAgent Pattern","text":"<p><code>BaseAgent</code> (template-method pattern) eliminates the ~200 lines of duplicated <code>execute()</code> boilerplate that previously existed across all five test-executing agents.</p> <pre><code>BaseAgent (abstract)\n\u251c\u2500\u2500 execute()           \u2190 concrete: shared step loop, status tracking, timing\n\u251c\u2500\u2500 executeStep()       \u2190 abstract: each agent dispatches its own actions\n\u251c\u2500\u2500 buildResult()       \u2190 abstract: each agent assembles its own result shape\n\u251c\u2500\u2500 applyEnvironment()  \u2190 optional hook: per-agent env setup\n\u251c\u2500\u2500 onBeforeExecute()   \u2190 optional hook: called before the step loop\n\u2514\u2500\u2500 onAfterExecute()    \u2190 optional hook: cleanup after step loop (finally block)\n</code></pre> <p>Example: implementing a custom agent</p> <pre><code>import { BaseAgent, AgentType, ExecutionContext } from '@gadugi/agentic-test';\nimport { OrchestratorScenario, StepResult, TestStatus } from '@gadugi/agentic-test';\n\nexport class MyDatabaseAgent extends BaseAgent {\n  readonly name = 'database-agent';\n  readonly type = AgentType.CLI;\n\n  async initialize(): Promise&lt;void&gt; {\n    // Connect to DB, run migrations, etc.\n    this.isInitialized = true;\n  }\n\n  async cleanup(): Promise&lt;void&gt; {\n    // Close connections\n  }\n\n  async executeStep(step: any, _index: number): Promise&lt;StepResult&gt; {\n    const result = await this.runQuery(step.params.sql);\n    return {\n      stepId: step.name,\n      status: result.rows.length &gt; 0 ? TestStatus.PASSED : TestStatus.FAILED,\n      duration: result.duration,\n    };\n  }\n\n  protected buildResult(ctx: ExecutionContext) {\n    return { ...ctx, queryCount: this.queries.length };\n  }\n}\n</code></pre> <p><code>BaseAgent</code> guarantees: - <code>execute()</code> throws if <code>initialize()</code> was not called first - The step loop stops at the first <code>FAILED</code> or <code>ERROR</code> step - <code>onAfterExecute()</code> always runs in the <code>finally</code> block (even on error) - <code>ExecutionContext</code> captures timing, status, and step results for <code>buildResult()</code></p>"},{"location":"ARCHITECTURE/#module-philosophy","title":"Module Philosophy","text":""},{"location":"ARCHITECTURE/#300-loc-limit","title":"300 LOC limit","text":"<p>Every source file is kept under ~300 lines. Files that grew beyond this were split into focused sub-modules during the refactor:</p> Original file Original LOC Replaced by <code>TUIAgent.ts</code> 1,311 5 sub-modules in <code>agents/tui/</code> <code>ElectronUIAgent.ts</code> 1,101 4 sub-modules in <code>agents/electron/</code> <code>PriorityAgent.ts</code> 1,129 3 sub-modules in <code>agents/priority/</code> <code>WebSocketAgent.ts</code> 1,094 4 sub-modules in <code>agents/websocket/</code> <code>cli.ts</code> 1,141 7 command modules in <code>cli/commands/</code> <code>TestOrchestrator</code> 887 3 sub-modules in <code>orchestrator/</code>"},{"location":"ARCHITECTURE/#brick-and-stud-pattern","title":"Brick and stud pattern","text":"<p>Each module is a \"brick\" with a clear surface (\"stud\"): an <code>index.ts</code> that exports only the public interface. Internal helpers are not exported. Consumers always import from the directory, never from individual files:</p> <pre><code>// Correct\nimport { TUIInputSimulator } from './agents/tui';\n\n// Incorrect \u2014 bypasses the public surface\nimport { TUIInputSimulator } from './agents/tui/TUIInputSimulator';\n</code></pre>"},{"location":"ARCHITECTURE/#single-responsibility","title":"Single responsibility","text":"<ul> <li>One class or function group per file</li> <li>No two modules share a responsibility</li> <li>Shared utilities (<code>delay</code>, <code>deepEqual</code>) live in one place and are imported   everywhere else</li> </ul>"},{"location":"ARCHITECTURE/#data-flow","title":"Data Flow","text":"<p>How a test scenario travels from YAML file to recorded result:</p> <pre><code>sequenceDiagram\n    participant User\n    participant CLI\n    participant lib.ts\n    participant ScenarioLoader\n    participant Orchestrator\n    participant ScenarioRouter\n    participant Agent\n    participant ResultAggregator\n\n    User-&gt;&gt;CLI: agentic-test run --scenario login\n    CLI-&gt;&gt;lib.ts: runTests({ suite: 'smoke' })\n    lib.ts-&gt;&gt;ScenarioLoader: loadTestScenarios(['scenarios/login.yaml'])\n    ScenarioLoader--&gt;&gt;lib.ts: ScenarioDefinition[]\n    lib.ts-&gt;&gt;Orchestrator: orchestrator.run(suite, files)\n    Orchestrator-&gt;&gt;ScenarioLoader: load + filter for suite\n    Orchestrator-&gt;&gt;ScenarioRouter: route(OrchestratorScenario[])\n    ScenarioRouter-&gt;&gt;Agent: agent.initialize()\n    ScenarioRouter-&gt;&gt;Agent: agent.execute(scenario)\n    Agent--&gt;&gt;ScenarioRouter: TestResult\n    ScenarioRouter-&gt;&gt;ResultAggregator: record(result)\n    ResultAggregator-&gt;&gt;Orchestrator: session complete\n    Orchestrator--&gt;&gt;lib.ts: TestSession\n    lib.ts--&gt;&gt;CLI: TestSession\n    CLI--&gt;&gt;User: summary output + exit code\n</code></pre> <p>Adapter step: <code>ScenarioDefinition</code> (the YAML schema type) is converted to <code>OrchestratorScenario</code> (the internal execution type) by <code>adaptScenarioToComplex()</code> in <code>src/adapters/scenarioAdapter.ts</code> before being passed to <code>ScenarioRouter</code>.</p> <p>Suite filtering: <code>filterScenariosForSuite()</code> from <code>src/lib/ScenarioLoader.ts</code> selects scenarios by tag prefix (<code>smoke:</code>, <code>critical:</code>, <code>auth:</code>) for the <code>smoke</code> suite, or passes all scenarios for <code>full</code> and <code>regression</code> suites. <code>TestOrchestrator</code> imports and delegates to this canonical function; there is no private duplicate.</p> <p>Type naming disambiguation: - <code>TestModels.TestSuite</code> \u2014 a named collection of <code>OrchestratorScenario[]</code> for execution - <code>SuiteFilterConfig</code> (formerly <code>TestSuite</code> in <code>TestOrchestrator</code>) \u2014 pattern-based   suite selector <code>{ name, patterns: string[], tags?: string[] }</code> used to decide which   scenarios belong to a named run; exported as <code>OrchestratorTestSuite</code> from the public API</p> <p>See also:</p> <ul> <li>docs/index.md \u2014 documentation home</li> <li>docs/ResourceOptimizer.md \u2014 ResourceOptimizer deep-dive</li> <li>docs/screenshot-diff-guide.md \u2014 screenshot comparison guide</li> </ul>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project are documented here.</p> <p>Format: Keep a Changelog Versioning: Semantic Versioning</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li><code>docs/ARCHITECTURE.md</code> \u2014 comprehensive architecture reference</li> </ul>"},{"location":"CHANGELOG/#100-2026-02-22","title":"1.0.0 - 2026-02-22","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>Initial release of <code>@gadugi/agentic-test</code>, a TypeScript multi-agent testing   framework for Electron and TUI applications</li> <li>Nine specialised test agents: <code>TUIAgent</code>, <code>CLIAgent</code>, <code>APIAgent</code>,   <code>WebSocketAgent</code>, <code>ElectronUIAgent</code>, <code>ComprehensionAgent</code>, <code>IssueReporter</code>,   <code>PriorityAgent</code>, <code>SystemAgent</code></li> <li><code>BaseAgent</code> abstract base class (template-method pattern) that provides a   shared <code>execute()</code> loop, eliminating ~200 lines of duplicated boilerplate   across all test-executing agents (#117, #118, PR #125)</li> <li><code>TestOrchestrator</code> with <code>ScenarioRouter</code>, <code>SessionManager</code>, and   <code>ResultAggregator</code> sub-modules for parallel scenario dispatch and result   collection (#50, PR #65)</li> <li><code>PtyTerminal</code> (renamed from <code>core/TUIAgent</code>) \u2014 PTY-based terminal manager   wrapping <code>node-pty-prebuilt-multiarch</code> with zombie-process prevention (#14,   #25, PR #73)</li> <li><code>ProcessLifecycleManager</code> \u2014 tracks and terminates spawned child processes on   test completion</li> <li><code>AdaptiveWaiter</code> \u2014 condition-based waiting with configurable backoff   strategies (<code>LINEAR</code>, <code>EXPONENTIAL</code>, <code>FIXED</code>), replacing hard-coded   <code>setTimeout</code> calls</li> <li><code>ResourceOptimizer</code> with <code>ConcurrencyOptimizer</code>, <code>CpuOptimizer</code>, and   <code>MemoryOptimizer</code> sub-modules (#50, PR #65)</li> <li><code>SmartUITestRunner</code> and <code>ComprehensiveUITestRunner</code> with sub-modules for   adaptive and exhaustive Playwright-based UI testing (#52, PR #72)</li> <li><code>src/lib.ts</code> \u2014 programmatic API (<code>runTests()</code>) with no process-level side   effects; signal handlers remain in <code>src/cli.ts</code> only (#26, PR #58)</li> <li><code>src/cli.ts</code> \u2014 single Commander entry point; all command logic extracted to   <code>src/cli/commands/</code> (#44, #26, PRs #58, #64)</li> <li><code>src/cli-path-utils.ts</code> \u2014 path traversal guard for CLI <code>--directory</code>,   <code>--file</code>, <code>--config</code>, and <code>--env</code> flags (#93, PR #94)</li> <li><code>ScenarioDefinition</code> type in <code>src/scenarios/</code> as the canonical YAML-facing   schema; <code>OrchestratorScenario</code> in <code>src/models/</code> as the internal execution   type (#14, #25, PR #73)</li> <li><code>src/adapters/scenarioAdapter.ts</code> \u2014 converts <code>ScenarioDefinition</code> to   <code>OrchestratorScenario</code> with corrected priority mapping (medium\u2192MEDIUM,   low\u2192LOW) (#22)</li> <li><code>src/utils/async.ts</code> with <code>delay()</code> \u2014 single canonical async sleep,   eliminating duplicate implementations across agents (#118)</li> <li><code>src/utils/comparison.ts</code> with <code>deepEqual()</code> \u2014 single canonical deep   equality, eliminating duplicate implementations (#118)</li> <li><code>src/utils/agentUtils.ts</code> \u2014 shared agent utility functions extracted from   agents during BaseAgent consolidation (#117, #118)</li> <li>249 unit tests across the codebase; 145 new tests covering   <code>AdaptiveWaiter</code>, <code>ProcessLifecycleManager</code>, <code>ResourceOptimizer</code>,   <code>PtyTerminal</code>, <code>SystemAgent</code>, <code>ComprehensionAgent</code>, <code>yamlParser</code>, <code>config</code>,   <code>scenarioLoader</code>, <code>scenarioAdapter</code>, and <code>retry</code> (#27, PR #270578e)</li> <li><code>docs/quality-audit-2026-02.md</code> \u2014 full quality audit report (15 issues,   all resolved)</li> <li><code>docs/ResourceOptimizer.md</code> \u2014 ResourceOptimizer reference</li> <li><code>docs/screenshot-diff-guide.md</code> \u2014 screenshot comparison guide</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Split all oversized agent files (894\u20131,325 LOC) into focused sub-modules   under <code>agents/&lt;type&gt;/</code>. Files affected: <code>TUIAgent</code> (1,311 LOC \u2192 5   sub-modules), <code>ElectronUIAgent</code> (1,101 LOC \u2192 4), <code>PriorityAgent</code> (1,129   LOC \u2192 3), <code>WebSocketAgent</code> (1,094 LOC \u2192 4), <code>CLIAgent</code> (939 LOC \u2192 2),   <code>APIAgent</code> (937 LOC \u2192 3), <code>IssueReporter</code> (924 LOC \u2192 3),   <code>ComprehensionAgent</code> (894 LOC \u2192 3) (#47, #48, #51\u2013#53, #62\u2013#69, PRs   #61\u2013#68, #121)</li> <li>Split <code>TestOrchestrator</code> (887 LOC) into <code>ScenarioRouter</code>, <code>SessionManager</code>,   and <code>ResultAggregator</code> (#50, PR #65)</li> <li>Split <code>ResourceOptimizer</code> (817 LOC) into <code>ConcurrencyOptimizer</code>,   <code>CpuOptimizer</code>, and <code>MemoryOptimizer</code> (#50, PR #65)</li> <li>Split <code>cli.ts</code> (1,141 LOC) into seven focused command modules in   <code>src/cli/commands/</code> (#44, PR #64)</li> <li>Split <code>fileUtils.ts</code> (772 LOC) and <code>config.ts</code> (648 LOC) into sub-module   directories (#51, PR #63)</li> <li>Split <code>TUIModels</code>, <code>retry</code>, <code>yamlParser</code>, and <code>logger</code> into sub-module   directories (#53, PR #68)</li> <li>Split <code>SystemAgent</code> and <code>screenshot.ts</code> into sub-module directories (#28,   PR #f3434f1)</li> <li><code>ElectronWebSocketMonitor</code> now delegates to <code>WebSocketAgent</code> instead of   duplicating Socket.IO client logic (#115, PR #123)</li> <li><code>DocumentationLoader</code> extracted from <code>ComprehensionAgent</code>; hardcoded   application regexes removed (#119, PR #121)</li> <li><code>archiveRun</code> renamed to <code>exportManifest</code>; scenario IDs are now deterministic   (no random UUIDs on re-load) (#108, PR #110)</li> <li>Removed dead code: <code>PTYManager.ts</code> was never imported and has been deleted   (#42, PR #58)</li> <li>Removed global <code>uncaughtException</code>/<code>unhandledRejection</code> handlers from   library module (<code>src/lib.ts</code>); handlers belong in CLI entry points only   (#77, PR #92)</li> <li><code>isolatedModules</code> removed from Jest ts-jest config (deprecated flag); test   coverage thresholds raised (#54, PR #74)</li> <li>Reduced <code>any</code> type usages from 175 to 140 in <code>src/</code> (#55, PR #71)</li> <li><code>src/index.ts</code> now exports all agents, orchestrator, and library functions   as the full public API (#29, PR #d911700)</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li><code>reportFailures()</code> in <code>TestOrchestrator</code> now calls <code>IssueReporter.createIssue()</code>   for each failure; previous implementation was a no-op stub (#76, PR #87)</li> <li><code>IssueReporter.execute()</code> now implements the <code>IAgent</code> contract and returns a   real result; previous implementation always threw (#95, PR #101)</li> <li><code>PriorityAgent</code> stub methods replaced with real implementations (#97, PR #103)</li> <li><code>runTests()</code> TypeError and <code>parseYamlScenarios</code> alias bug resolved (#105, PR #113)</li> <li>Watch command now uses <code>TestOrchestrator.runWithScenarios()</code> with pre-loaded   scenarios instead of re-running full discovery (#21, PR #87)</li> <li><code>executeParallel()</code> semaphore now correctly enforces <code>maxParallel</code> concurrency   limit (#23, PR #87)</li> <li><code>setupLogger()</code> now swaps the <code>_activeLogger</code> reference rather than mutating   the existing instance (#24, PR #87)</li> <li>Real CPU monitoring implemented in <code>TUIAgent.collectPerformanceMetrics()</code>   (#41, PR #60)</li> <li>Test isolation for <code>SystemAgent</code> (silences EACCES from chokidar) and   <code>ZombieProcessPrevention</code> (no longer affects system-wide processes) (#39,   #40, PRs #59, #70)</li> <li><code>exec</code> added to child_process mock in <code>TUIAgent.test.ts</code> (#37, PR #57)</li> <li>Octal escape sequences (<code>\\033</code>) replaced with hex (<code>\\x1b</code>) in terminal   integration tests (#38, PR #56)</li> <li><code>dynamic require(zlib)</code> replaced with static import; <code>Function</code> type   replaced with proper signatures (#78, PR #82)</li> <li>Non-alert Electron dialogs now dismissed correctly; dialog events emitted   (#116, PR #122)</li> <li>LLM errors now propagate from <code>ComprehensionAgent</code> instead of returning a   silent \"Unknown Feature\" fallback (#96, PR #100)</li> <li>API key validation added; <code>apiVersion</code> added to default config (#96, PR #100)</li> <li>Test failures caused by module-split merges resolved (PR #ccaaf30)</li> <li>Medium/low quality issues bundled from audit resolved (#109, #120, PRs #114,   #124)</li> <li><code>process.env</code> mutation removed from <code>TUIAgent</code> and <code>CLIAgent</code>; environment   variables are now stored in local config only (#30, PR #d911700)</li> </ul>"},{"location":"CHANGELOG/#security","title":"Security","text":"<ul> <li>YAML deserialization: all <code>yaml.load()</code> calls now use <code>yaml.JSON_SCHEMA</code>,   blocking <code>!!js/function</code> and other code-execution tags (#83, PR #90)</li> <li>Path traversal in YAML <code>processIncludes()</code> blocked (#83, PR #90)</li> <li>Credential exposure: <code>process.env</code> snapshot no longer written to disk   via <code>exportToFile()</code>; <code>getSafeEnvironment()</code> allowlist applied when   embedding environment data in GitHub issue bodies (#84, #19, PRs #91,   #d911700)</li> <li>CLI path traversal: <code>--directory</code>, <code>--file</code>, <code>--config</code>, and <code>--env</code> flags   validated through <code>safeResolvePath()</code> (#93, PR #94)</li> <li>CLI error output sanitised; timeout bounds validated to prevent   integer-overflow denial of service (#85, #86, PR #88)</li> <li>Shell injection in <code>DockerMonitor</code> blocked; public GitHub Gist screenshot   upload removed (#98, PR #104)</li> <li><code>sendControl()</code> injection attack surface closed; config prototype pollution   prevented (#107, PR #111)</li> <li>ReDoS in <code>filterByPatterns()</code> fixed; path traversal in <code>cleanup()</code> blocked   (#106, PR #112)</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to @gadugi/agentic-test","text":"<p>Thank you for contributing to the Gadugi Agentic Test Framework. This guide covers everything you need to get started.</p>"},{"location":"CONTRIBUTING/#contents","title":"Contents","text":"<ul> <li>Quick Start for Contributors</li> <li>Development Setup</li> <li>Project Structure</li> <li>Running Tests</li> <li>Adding a New Agent</li> <li>Code Standards</li> <li>Making a PR</li> <li>Security</li> </ul>"},{"location":"CONTRIBUTING/#quick-start-for-contributors","title":"Quick Start for Contributors","text":"<pre><code>git clone https://github.com/rysweet/gadugi-agentic-test.git\ncd gadugi-agentic-test\nnpm install\nnpm test  # Verify baseline passes\n</code></pre> <p>All 249+ tests should pass before you start work. If any fail, check TROUBLESHOOTING.md before proceeding.</p>"},{"location":"CONTRIBUTING/#development-setup","title":"Development Setup","text":""},{"location":"CONTRIBUTING/#requirements","title":"Requirements","text":"<ul> <li>Node.js 20+ (CI runs on 20.x and 22.x)</li> <li>npm 9+</li> <li>Native build tools \u2014 required for <code>node-pty</code></li> <li>macOS: <code>xcode-select --install</code></li> <li>Ubuntu/Debian: <code>sudo apt-get install -y build-essential</code></li> <li>Windows: <code>npm install --global windows-build-tools</code></li> </ul>"},{"location":"CONTRIBUTING/#environment-variables","title":"Environment Variables","text":"<pre><code># Required for AI-powered agents (ComprehensionAgent, PriorityAgent)\nexport OPENAI_API_KEY=sk-...\n\n# Required only for integration tests that create GitHub issues\nexport GITHUB_TOKEN=ghp_...\n</code></pre> <p>Copy <code>.env.example</code> to <code>.env</code> and fill in values. The <code>.env</code> file is git-ignored; never commit credentials.</p>"},{"location":"CONTRIBUTING/#ide-recommendations","title":"IDE Recommendations","text":"<ul> <li>VS Code with the TypeScript + JavaScript extension</li> <li>Enable strict mode checking: the project uses <code>\"strict\": true</code> in <code>tsconfig.json</code></li> <li>Install the ESLint extension \u2014 linting runs in CI</li> </ul>"},{"location":"CONTRIBUTING/#project-structure","title":"Project Structure","text":"<p>The project follows a split-module architecture where each agent and utility is decomposed into single-responsibility sub-modules. See ARCHITECTURE.md for the full breakdown.</p> <p>High-level layout:</p> <pre><code>src/\n\u251c\u2500\u2500 agents/         # 9 agent implementations, each with a sub-module directory\n\u251c\u2500\u2500 core/           # PtyTerminal, AdaptiveWaiter, ProcessLifecycleManager, ResourceOptimizer\n\u251c\u2500\u2500 orchestrator/   # TestOrchestrator\n\u251c\u2500\u2500 runners/        # SmartUITestRunner, ComprehensiveUITestRunner\n\u251c\u2500\u2500 utils/          # Logging, config, retry, file ops, screenshot \u2014 all split into sub-modules\n\u251c\u2500\u2500 models/         # Shared TypeScript interfaces\n\u251c\u2500\u2500 adapters/       # scenarioAdapter\n\u251c\u2500\u2500 scenarios/      # ScenarioDefinition type and ScenarioLoader\n\u251c\u2500\u2500 cli.ts          # Single CLI entry point (Commander)\n\u251c\u2500\u2500 lib.ts          # Programmatic API (no side effects)\n\u2514\u2500\u2500 index.ts        # Full public API\n</code></pre>"},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># Full suite\nnpm test\n\n# One specific agent\nnpm test -- --testPathPattern=TUIAgent\n\n# With coverage report\nnpm run test:coverage\n\n# Sequential (avoids timing interference between tests)\nnpx jest --runInBand\n</code></pre> <p>Tests live in <code>src/**/__tests__/</code> alongside the source they cover. The Jest config is in <code>jest.config.js</code>.</p>"},{"location":"CONTRIBUTING/#adding-a-new-agent","title":"Adding a New Agent","text":"<p>All agents follow the same decomposed structure. Use <code>WebSocketAgent</code> as a reference \u2014 it has the clearest split.</p>"},{"location":"CONTRIBUTING/#step-1-create-the-sub-module-directory","title":"Step 1: Create the sub-module directory","text":"<pre><code>mkdir src/agents/myagent\n</code></pre>"},{"location":"CONTRIBUTING/#step-2-create-typests","title":"Step 2: Create <code>types.ts</code>","text":"<p>Define the config interface and any agent-specific types:</p> <pre><code>// src/agents/myagent/types.ts\nexport interface MyAgentConfig {\n  targetUrl: string;\n  timeout?: number;\n}\n</code></pre>"},{"location":"CONTRIBUTING/#step-3-implement-focused-sub-modules","title":"Step 3: Implement focused sub-modules","text":"<p>Each file should do exactly one thing and stay under 300 lines:</p> <pre><code>src/agents/myagent/\n\u251c\u2500\u2500 types.ts            # Config interfaces and enums\n\u251c\u2500\u2500 MyAgentConnector.ts # Handles connection setup\n\u251c\u2500\u2500 MyAgentExecutor.ts  # Runs individual steps\n\u251c\u2500\u2500 MyAgentParser.ts    # Parses responses\n\u2514\u2500\u2500 index.ts            # Re-exports everything\n</code></pre>"},{"location":"CONTRIBUTING/#step-4-create-the-thin-facade","title":"Step 4: Create the thin facade","text":"<p>The main agent file extends <code>BaseAgent</code> and delegates to sub-modules:</p> <pre><code>// src/agents/MyAgent.ts\nimport { BaseAgent } from './BaseAgent';\nimport { AgentType, IAgent } from './index';\nimport { MyAgentConfig } from './myagent/types';\nimport { MyAgentConnector } from './myagent/MyAgentConnector';\nimport { MyAgentExecutor } from './myagent/MyAgentExecutor';\nimport { ExecutionContext } from './BaseAgent';\nimport { OrchestratorScenario, StepResult } from '../models/TestModels';\n\nexport class MyAgent extends BaseAgent implements IAgent {\n  readonly name = 'MyAgent';\n  readonly type = AgentType.CUSTOM;\n\n  private connector: MyAgentConnector;\n  private executor: MyAgentExecutor;\n\n  constructor(private config: MyAgentConfig) {\n    super();\n    this.connector = new MyAgentConnector(config);\n    this.executor = new MyAgentExecutor(config);\n  }\n\n  async initialize(): Promise&lt;void&gt; {\n    await this.connector.connect();\n    this.isInitialized = true;\n  }\n\n  async cleanup(): Promise&lt;void&gt; {\n    await this.connector.disconnect();\n  }\n\n  async executeStep(step: any, index: number): Promise&lt;StepResult&gt; {\n    return this.executor.run(step, index);\n  }\n\n  buildResult(scenario: OrchestratorScenario, ctx: ExecutionContext) {\n    return { scenarioId: scenario.id, ...ctx };\n  }\n}\n</code></pre>"},{"location":"CONTRIBUTING/#step-5-export-from-agents-index","title":"Step 5: Export from agents index","text":"<p>Add your agent to <code>src/agents/index.ts</code>:</p> <pre><code>export { MyAgent } from './MyAgent';\nexport type { MyAgentConfig } from './myagent/types';\n</code></pre>"},{"location":"CONTRIBUTING/#step-6-write-tests","title":"Step 6: Write tests","text":"<p>Create <code>src/agents/__tests__/MyAgent.test.ts</code>. The test file for <code>TUIAgent</code> is a good reference for structure.</p>"},{"location":"CONTRIBUTING/#code-standards","title":"Code Standards","text":""},{"location":"CONTRIBUTING/#module-size-limit","title":"Module size limit","text":"<p>300 lines maximum per file. If a module exceeds this, decompose it into sub-modules following the existing pattern (see <code>src/agents/system/</code> or <code>src/utils/screenshot/</code>).</p>"},{"location":"CONTRIBUTING/#single-responsibility-brick-philosophy","title":"Single responsibility (brick philosophy)","text":"<p>Each file does one thing. <code>WebSocketConnection.ts</code> manages the connection. <code>WebSocketMessageHandler.ts</code> handles messages. They do not overlap.</p>"},{"location":"CONTRIBUTING/#zero-stubs","title":"Zero stubs","text":"<p>No placeholder comments, no <code>// TODO: implement</code>, no empty function bodies. If a feature is not ready, do not merge it. If you are writing ahead of implementation (document-driven development), mark it clearly with <code>[PLANNED]</code> and open a tracking issue.</p>"},{"location":"CONTRIBUTING/#tests-required","title":"Tests required","text":"<p>All new code needs tests. No PR merges without test coverage for new public methods. Run <code>npm run test:coverage</code> and confirm your additions are covered.</p>"},{"location":"CONTRIBUTING/#typescript-strict-mode","title":"TypeScript strict mode","text":"<p>The project uses <code>\"strict\": true</code>. No <code>any</code> escapes unless absolutely necessary and explicitly justified in a comment. No <code>@ts-ignore</code> without an explanation.</p>"},{"location":"CONTRIBUTING/#shared-utilities","title":"Shared utilities","text":"<p>Before adding a new utility, check <code>src/utils/</code>. Common patterns are already extracted:</p> <ul> <li>Delays: <code>delay()</code> from <code>src/utils/async.ts</code></li> <li>Deep equality: <code>deepEqual()</code> from <code>src/utils/comparison.ts</code></li> <li>ID generation: <code>generateId()</code> from <code>src/utils/ids.ts</code></li> <li>Config sanitization: <code>sanitizeConfigWithEnv()</code> from <code>src/utils/agentUtils.ts</code></li> <li>ANSI colors: <code>src/utils/colors.ts</code></li> </ul>"},{"location":"CONTRIBUTING/#making-a-pr","title":"Making a PR","text":""},{"location":"CONTRIBUTING/#branch-naming","title":"Branch naming","text":"<pre><code>fix/issue-N-short-description\nrefactor/what-is-changing\nfeat/new-feature-name\ndocs/what-is-documented\nchore/housekeeping-task\n</code></pre>"},{"location":"CONTRIBUTING/#commit-message-format","title":"Commit message format","text":"<p>Use the imperative mood and reference the issue number:</p> <pre><code>fix: remove stub from TUIAgent.executeStep (#117)\nrefactor: split SystemAgent into four sub-modules (#28)\nfeat: add CircuitBreaker to retry utilities (#31)\ndocs: add CONTRIBUTING guide\n</code></pre>"},{"location":"CONTRIBUTING/#pr-description-template","title":"PR description template","text":"<pre><code>## What this changes\n&lt;!-- One paragraph: what problem does this solve? --&gt;\n\n## How it works\n&lt;!-- Brief explanation of the approach --&gt;\n\n## Testing\n&lt;!-- How did you verify this? --&gt;\n\n## Checklist\n- [ ] All existing tests pass (`npm test`)\n- [ ] New code has tests\n- [ ] No module exceeds 300 lines\n- [ ] No stubs or placeholder code\n- [ ] CI passes on Node 20.x and 22.x\n</code></pre>"},{"location":"CONTRIBUTING/#ci-requirements","title":"CI requirements","text":"<p>Both Node 20.x and Node 22.x matrix jobs must pass. Do not merge if either is red. The CI runs <code>npm test</code> and <code>npm run build</code>.</p>"},{"location":"CONTRIBUTING/#security","title":"Security","text":"<p>Never commit credentials. The <code>.env</code> file is git-ignored. Verify with <code>git status</code> before committing.</p> <p>If you discover a security vulnerability, create a GitHub issue and label it <code>security</code>. Do not include exploit details in the public issue \u2014 link to a private disclosure if needed.</p>"},{"location":"GETTING_STARTED/","title":"Getting Started with Gadugi Agentic Test","text":"<p>Gadugi (\u13a6\u13da\u13a9) - Cherokee word meaning \"cooperative spirit\" - perfectly embodies this framework where intelligent agents work together to test complex applications.</p> <p>Welcome to Gadugi Agentic Test! This guide will walk you through setting up and running your first intelligent test scenarios. Whether you're testing Electron applications, CLI tools, or complex web interfaces, our multi-agent system will revolutionize your testing approach.</p>"},{"location":"GETTING_STARTED/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Quick Start (5 minutes)</li> <li>Installation</li> <li>First Test Scenario</li> <li>Understanding Agents</li> <li>YAML Test Scenarios</li> <li>Running Tests</li> <li>Next Steps</li> </ol>"},{"location":"GETTING_STARTED/#quick-start-5-minutes","title":"Quick Start (5 minutes)","text":"<p>Get up and running with a simple test in under 5 minutes:</p> <pre><code># 1. Clone and setup\ngit clone https://github.com/rysweet/gadugi-agentic-test.git\ncd gadugi-agentic-test\nnpm install\n\n# 2. Set environment variables\nexport ELECTRON_APP_PATH=\"/path/to/your/electron/app\"\nexport GITHUB_TOKEN=\"your_github_token_optional\"\n\n# 3. Run a sample test\nnpm run build\nnpm start -- run scenarios/sample-ui-workflow.yaml\n</code></pre> <p>That's it! Your first intelligent test is running. Watch as multiple AI agents coordinate to test your application.</p>"},{"location":"GETTING_STARTED/#installation","title":"Installation","text":""},{"location":"GETTING_STARTED/#prerequisites","title":"Prerequisites","text":"<p>Before installing Gadugi, ensure you have:</p> <ul> <li>Node.js 18+ - Download here</li> <li>Python 3.11+ - For orchestration components</li> <li>Git CLI - For issue reporting features</li> <li>An Electron application - To test (or use our demo app)</li> </ul>"},{"location":"GETTING_STARTED/#step-1-install-gadugi","title":"Step 1: Install Gadugi","text":""},{"location":"GETTING_STARTED/#option-a-from-source-recommended","title":"Option A: From Source (Recommended)","text":"<pre><code># Clone the repository\ngit clone https://github.com/rysweet/gadugi-agentic-test.git\ncd gadugi-agentic-test\n\n# Install dependencies\nnpm install\n\n# Build the framework\nnpm run build\n\n# Verify installation\nnpm test\n</code></pre>"},{"location":"GETTING_STARTED/#option-b-global-installation-coming-soon","title":"Option B: Global Installation (Coming Soon)","text":"<pre><code># NPM package publishing planned for v1.1.0\nnpm install -g @gadugi/agentic-test\n</code></pre>"},{"location":"GETTING_STARTED/#step-2-install-playwright-browsers","title":"Step 2: Install Playwright Browsers","text":"<p>Gadugi uses Playwright for Electron testing:</p> <pre><code># Install browser dependencies\nnpx playwright install\n</code></pre>"},{"location":"GETTING_STARTED/#step-3-environment-setup","title":"Step 3: Environment Setup","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># Required\nELECTRON_APP_PATH=/path/to/your/electron/app.exe\n\n# Optional - Enhanced Features\nGITHUB_TOKEN=ghp_your_github_token_here\nAZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/\nAZURE_OPENAI_KEY=your_azure_openai_key\nOPENAI_API_KEY=your_openai_key_alternative\n\n# Optional - Configuration\nGADUGI_LOG_LEVEL=info\nGADUGI_HEADLESS=false\nGADUGI_TIMEOUT_MULTIPLIER=1.0\nGADUGI_PARALLEL_AGENTS=3\n</code></pre>"},{"location":"GETTING_STARTED/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<pre><code># Check that everything is working\nnpx gadugi-test --version\nnpx gadugi-test --help\n\n# Test with a sample scenario\nnpx gadugi-test run scenarios/sample-ui-workflow.yaml --dry-run\n</code></pre>"},{"location":"GETTING_STARTED/#first-test-scenario","title":"First Test Scenario","text":"<p>Let's create your first test scenario step by step.</p>"},{"location":"GETTING_STARTED/#step-1-create-a-simple-yaml-test","title":"Step 1: Create a Simple YAML Test","text":"<p>Create a file called <code>my-first-test.yaml</code>:</p> <pre><code>name: \"My First Gadugi Test\"\ndescription: \"A simple test to verify the application launches\"\nversion: \"1.0.0\"\n\n# Define the agents we'll use\nagents:\n  - name: \"ui-agent\"\n    type: \"ui\"\n    config:\n      executablePath: \"${ELECTRON_APP_PATH}\"\n      headless: false\n      screenshotConfig:\n        mode: \"only-on-failure\"\n        directory: \"./screenshots\"\n\n# Test steps\nsteps:\n  - name: \"Launch Application\"\n    agent: \"ui-agent\"\n    action: \"launch_electron\"\n    timeout: 20000\n\n  - name: \"Take Initial Screenshot\"\n    agent: \"ui-agent\"\n    action: \"screenshot\"\n    params:\n      name: \"app_launched\"\n\n  - name: \"Wait and Verify App is Responsive\"\n    agent: \"ui-agent\"\n    action: \"wait\"\n    params:\n      duration: 2000\n\n# Clean up\ncleanup:\n  - name: \"Close Application\"\n    agent: \"ui-agent\"\n    action: \"close_app\"\n\n# Test metadata\nmetadata:\n  tags: [\"smoke\", \"basic\", \"launch\"]\n  priority: \"high\"\n</code></pre>"},{"location":"GETTING_STARTED/#step-2-run-your-first-test","title":"Step 2: Run Your First Test","text":"<pre><code># Run the test\nnpx gadugi-test run my-first-test.yaml\n\n# Run with verbose logging\nnpx gadugi-test run my-first-test.yaml --log-level debug\n\n# Run and generate detailed reports\nnpx gadugi-test run my-first-test.yaml --reports ./test-reports/\n</code></pre>"},{"location":"GETTING_STARTED/#step-3-view-results","title":"Step 3: View Results","text":"<p>After the test runs, you'll see:</p> <pre><code>\ud83d\ude80 Gadugi Agentic Test v1.0.0\n\ud83d\udccb Session ID: abc123-def456-ghi789\n\nPhase 1: Discovery \u2705\n  \u2514\u2500\u2500 Loaded 1 test scenario\n\nPhase 2: Execution \u2705\n  \u2514\u2500\u2500 My First Gadugi Test: PASSED (5.2s)\n\nPhase 3: Analysis \u2705\n  \u2514\u2500\u2500 No failures to analyze\n\nPhase 4: Reporting \u2705\n  \u2514\u2500\u2500 No issues to report\n\n\ud83d\udcca Session Summary:\n  \u2705 Total: 1 | \u2705 Passed: 1 | \u274c Failed: 0 | \u23ed\ufe0f Skipped: 0\n  \u23f1\ufe0f Duration: 5.2 seconds\n  \ud83d\udcf8 Screenshots: 1 captured\n  \ud83d\udcc1 Reports: ./test-reports/session_abc123.json\n</code></pre>"},{"location":"GETTING_STARTED/#understanding-agents","title":"Understanding Agents","text":"<p>Gadugi uses specialized AI agents that work together. Think of them as expert team members, each with unique skills:</p>"},{"location":"GETTING_STARTED/#electronuiagent","title":"\ud83e\udd16 ElectronUIAgent","text":"<p>What it does: Controls your Electron application like a human user would Capabilities: - Clicks buttons, fills forms, navigates UI - Takes screenshots and monitors performance - Handles dialogs and multi-window scenarios - Real-time WebSocket monitoring</p> <p>Example: <pre><code>- name: \"Click Login Button\"\n  agent: \"ui-agent\"\n  action: \"click\"\n  params:\n    selector: \"[data-testid='login-btn']\"\n</code></pre></p>"},{"location":"GETTING_STARTED/#cliagent","title":"\u2328\ufe0f CLIAgent","text":"<p>What it does: Executes and monitors command-line operations Capabilities: - Runs shell commands and scripts - Monitors process output and exit codes - Handles interactive CLI sessions - Environment variable management</p> <p>Example: <pre><code>- name: \"Run Build Command\"\n  agent: \"cli-agent\"\n  action: \"execute\"\n  params:\n    command: \"npm run build\"\n    timeout: 60000\n</code></pre></p>"},{"location":"GETTING_STARTED/#comprehensionagent","title":"\ud83e\udde0 ComprehensionAgent","text":"<p>What it does: Uses AI to understand and generate tests Capabilities: - Analyzes application documentation - Generates test scenarios automatically - Identifies edge cases and potential issues - Natural language test generation</p>"},{"location":"GETTING_STARTED/#issuereporter","title":"\ud83d\udc1b IssueReporter","text":"<p>What it does: Automatically creates GitHub issues for failures Capabilities: - Detects duplicate issues - Rich formatting with screenshots - Automatic labeling and assignment - Context-aware issue descriptions</p>"},{"location":"GETTING_STARTED/#priorityagent","title":"\ud83d\udcca PriorityAgent","text":"<p>What it does: Intelligently prioritizes test failures Capabilities: - Impact assessment based on historical data - Machine learning-based severity scoring - Custom priority rules - Trend analysis</p>"},{"location":"GETTING_STARTED/#yaml-test-scenarios","title":"YAML Test Scenarios","text":"<p>YAML scenarios are the heart of Gadugi. They're human-readable, version-controllable, and powerful.</p>"},{"location":"GETTING_STARTED/#basic-structure","title":"Basic Structure","text":"<pre><code>name: \"Test Name\"\ndescription: \"What this test does\"\nversion: \"1.0.0\"\n\n# Configuration\nconfig:\n  timeout: 60000      # Global timeout\n  retries: 2          # Retry failed steps\n  parallel: false     # Run steps in sequence\n\n# Environment setup\nenvironment:\n  requires:           # Required env vars\n    - ELECTRON_APP_PATH\n  optional:           # Optional env vars\n    - GITHUB_TOKEN\n\n# Agents to use\nagents:\n  - name: \"agent-name\"\n    type: \"ui\"         # or \"cli\", \"websocket\", etc.\n    config:\n      # Agent-specific config\n\n# Test steps\nsteps:\n  - name: \"Step Name\"\n    agent: \"agent-name\"\n    action: \"action_type\"\n    params:\n      # Action parameters\n    timeout: 30000     # Step timeout\n\n# Cleanup actions\ncleanup:\n  - name: \"Cleanup Action\"\n    agent: \"agent-name\"\n    action: \"close_app\"\n\n# Test metadata\nmetadata:\n  tags: [\"tag1\", \"tag2\"]\n  priority: \"high\"\n</code></pre>"},{"location":"GETTING_STARTED/#advanced-features","title":"Advanced Features","text":""},{"location":"GETTING_STARTED/#conditional-steps","title":"Conditional Steps","text":"<pre><code>- name: \"Check Login State\"\n  agent: \"ui-agent\"\n  action: \"wait_for_element\"\n  params:\n    selector: \"[data-testid='user-menu']\"\n    state: \"visible\"\n  on_failure: \"continue\"  # Don't fail the whole test\n\n- name: \"Login if Needed\"\n  agent: \"ui-agent\"\n  action: \"click\"\n  params:\n    selector: \"[data-testid='login-btn']\"\n  condition:\n    when: \"previous_step_failed\"\n</code></pre>"},{"location":"GETTING_STARTED/#multi-agent-coordination","title":"Multi-Agent Coordination","text":"<pre><code>- name: \"Start Background Process\"\n  agent: \"cli-agent\"\n  action: \"execute\"\n  params:\n    command: \"npm run server\"\n    background: true\n\n- name: \"Test UI While Server Runs\"\n  agent: \"ui-agent\"\n  action: \"navigate\"\n  params:\n    url: \"http://localhost:3000\"\n  depends_on: \"Start Background Process\"\n</code></pre>"},{"location":"GETTING_STARTED/#data-driven-tests","title":"Data-Driven Tests","text":"<pre><code>- name: \"Test Multiple Users\"\n  agent: \"ui-agent\"\n  action: \"loop\"\n  params:\n    data:\n      - username: \"admin\"\n        password: \"admin123\"\n      - username: \"user1\"\n        password: \"user123\"\n    steps:\n      - action: \"fill\"\n        params:\n          selector: \"[data-testid='username']\"\n          value: \"${item.username}\"\n      - action: \"fill\"\n        params:\n          selector: \"[data-testid='password']\"\n          value: \"${item.password}\"\n      - action: \"click\"\n        params:\n          selector: \"[data-testid='login']\"\n</code></pre>"},{"location":"GETTING_STARTED/#running-tests","title":"Running Tests","text":"<p>Gadugi provides flexible ways to run your tests:</p>"},{"location":"GETTING_STARTED/#basic-execution","title":"Basic Execution","text":"<pre><code># Run a single test file\nnpx gadugi-test run my-test.yaml\n\n# Run all tests in a directory\nnpx gadugi-test run ./tests/\n\n# Run tests matching a pattern\nnpx gadugi-test run \"./tests/**/*smoke*.yaml\"\n</code></pre>"},{"location":"GETTING_STARTED/#test-suites","title":"Test Suites","text":"<pre><code># Run predefined test suites\nnpx gadugi-test run --suite smoke      # Quick smoke tests\nnpx gadugi-test run --suite regression # Full regression suite\nnpx gadugi-test run --suite full       # All tests\n\n# Custom suites\nnpx gadugi-test run --suite my-suite --config gadugi.config.js\n</code></pre>"},{"location":"GETTING_STARTED/#advanced-options","title":"Advanced Options","text":"<pre><code># Parallel execution\nnpx gadugi-test run --parallel 5 ./tests/\n\n# Retry failed tests\nnpx gadugi-test run --retries 3 ./tests/\n\n# Headless mode\nnpx gadugi-test run --headless ./tests/\n\n# Custom timeout multiplier\nnpx gadugi-test run --timeout-multiplier 2.0 ./tests/\n\n# Generate comprehensive reports\nnpx gadugi-test run --reports ./reports/ --format json,html ./tests/\n\n# CI/CD mode (optimized for CI environments)\nnpx gadugi-test run --ci --artifacts ./artifacts/ ./tests/\n</code></pre>"},{"location":"GETTING_STARTED/#configuration-files","title":"Configuration Files","text":"<p>Create <code>gadugi.config.js</code> for project-wide settings:</p> <pre><code>export default {\n  // Execution settings\n  maxConcurrentAgents: 3,\n  retryAttempts: 2,\n  timeoutMultiplier: 1.0,\n\n  // Logging\n  logLevel: 'info',\n  logFile: './logs/gadugi.log',\n\n  // Artifacts\n  artifactDirectory: './artifacts',\n  screenshotDirectory: './screenshots',\n  retainArtifacts: 7, // days\n\n  // AI Integration\n  llmProvider: 'azure-openai',\n  llmDeployment: 'gpt-4',\n\n  // GitHub Integration\n  createIssues: true,\n  repository: 'your-org/your-repo',\n\n  // Test Suites\n  suites: {\n    'my-suite': ['smoke:', 'critical:'],\n    'api-tests': ['api:*'],\n    'ui-tests': ['ui:*']\n  }\n};\n</code></pre>"},{"location":"GETTING_STARTED/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"GETTING_STARTED/#github-actions","title":"GitHub Actions","text":"<pre><code>name: Gadugi Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: npm install\n\n      - name: Install Playwright\n        run: npx playwright install\n\n      - name: Run Gadugi Tests\n        run: npx gadugi-test run --ci --suite smoke ./tests/\n        env:\n          ELECTRON_APP_PATH: ./dist/app.exe\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Upload test reports\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: gadugi-reports\n          path: ./reports/\n</code></pre>"},{"location":"GETTING_STARTED/#docker-support","title":"Docker Support","text":"<pre><code>FROM node:18-alpine\n\n# Install system dependencies\nRUN apk add --no-cache \\\n    chromium \\\n    nss \\\n    freetype \\\n    freetype-dev \\\n    harfbuzz \\\n    ca-certificates \\\n    ttf-freefont\n\n# Install your app\nCOPY . /app\nWORKDIR /app\nRUN npm install &amp;&amp; npm run build\n\n# Install Gadugi\nRUN npm install -g @gadugi/agentic-test\nRUN npx playwright install\n\n# Run tests\nCMD [\"gadugi-test\", \"run\", \"--ci\", \"./tests/\"]\n</code></pre>"},{"location":"GETTING_STARTED/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've set up Gadugi and run your first intelligent test. Here's what to explore next:</p>"},{"location":"GETTING_STARTED/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Troubleshooting - Common issues and solutions</li> <li>Example Scenarios - Ready-to-use test scenarios</li> </ul>"},{"location":"GETTING_STARTED/#advanced-features_1","title":"\ud83d\udd27 Advanced Features","text":"<ol> <li>Custom Agents - Create specialized agents for your domain</li> <li>AI Test Generation - Let ComprehensionAgent generate tests from docs</li> <li>Visual Regression - Advanced screenshot comparison</li> <li>Performance Monitoring - Real-time performance tracking</li> <li>WebSocket Testing - Real-time event validation</li> </ol>"},{"location":"GETTING_STARTED/#best-practices","title":"\ud83d\ude80 Best Practices","text":"<ol> <li>Start Small - Begin with simple smoke tests</li> <li>Use Tags - Organize tests with meaningful tags</li> <li>Environment Isolation - Use separate environments for testing</li> <li>Monitor Trends - Track test results over time</li> <li>Collaborate - Share scenarios with your team</li> </ol>"},{"location":"GETTING_STARTED/#get-help","title":"\ud83e\udd1d Get Help","text":"<ul> <li>GitHub Issues - Report bugs or request features</li> <li>Discussions - Ask questions and share tips</li> <li>Documentation - Full documentation</li> </ul>"},{"location":"GETTING_STARTED/#pro-tips","title":"\ud83d\udca1 Pro Tips","text":"<ol> <li> <p>Use Data-Testid Attributes <pre><code>&lt;!-- Good: Stable selector --&gt;\n&lt;button data-testid=\"login-btn\"&gt;Login&lt;/button&gt;\n\n&lt;!-- Avoid: Fragile selectors --&gt;\n&lt;button class=\"btn btn-primary\"&gt;Login&lt;/button&gt;\n</code></pre></p> </li> <li> <p>Leverage Environment Variables <pre><code>params:\n  value: \"${USER_EMAIL}\" # Use env vars for test data\n</code></pre></p> </li> <li> <p>Screenshot Everything Important <pre><code>- name: \"Document Success State\"\n  agent: \"ui-agent\"\n  action: \"screenshot\"\n  params:\n    name: \"success_${timestamp}\"\n</code></pre></p> </li> <li> <p>Use Meaningful Test Names <pre><code># Good\nname: \"User can log in with valid credentials and access dashboard\"\n\n# Avoid\nname: \"Test 1\"\n</code></pre></p> </li> <li> <p>Tag for Organization <pre><code>metadata:\n  tags: [\"auth\", \"smoke\", \"critical\", \"api-v2\"]\n</code></pre></p> </li> </ol>"},{"location":"GETTING_STARTED/#ready-to-test-intelligently","title":"Ready to Test Intelligently?","text":"<p>You now have everything you need to start testing with Gadugi's intelligent agents. The framework will learn and adapt as you use it, becoming more effective over time.</p> <p>What makes Gadugi special: - \u2728 Intelligent Agents that understand your application - \ud83d\udd04 Self-Healing Tests that adapt to UI changes - \ud83d\udcca Smart Prioritization of failures - \ud83e\udd16 Automated Issue Creation with full context - \ud83d\udd0d Advanced Visual Comparison with multiple algorithms</p> <p>Happy testing! \ud83c\udf89</p> <p>Built with \u2764\ufe0f by the Gadugi team. Ready to revolutionize your testing workflow with intelligent agents working in harmony.</p>"},{"location":"ResourceOptimizer/","title":"ResourceOptimizer - Memory Issue Resolution","text":"<p>The ResourceOptimizer class addresses the critical memory issues identified in PR #4 feedback, where 2.3GB of memory was consumed for just 50 tests, indicating linear memory growth without proper cleanup.</p>"},{"location":"ResourceOptimizer/#problem-statement","title":"Problem Statement","text":"<p>Original Issue: Tests were consuming excessive memory (2.3GB for 50 tests) due to: - No connection pooling - each test created new terminal connections - No resource cleanup - terminals and buffers accumulated without being released - Linear memory growth - memory usage increased proportionally with test count - Missing garbage collection triggers - no automatic memory management</p>"},{"location":"ResourceOptimizer/#solution-architecture","title":"Solution Architecture","text":""},{"location":"ResourceOptimizer/#1-connection-pooling","title":"1. Connection Pooling","text":"<pre><code>const optimizer = new ResourceOptimizer({\n  pool: {\n    maxSize: 10,        // Limit concurrent terminals\n    minSize: 2,         // Maintain minimal pool\n    idleTimeout: 300000, // 5 minutes idle timeout\n    maxAge: 1800000,    // 30 minutes max age\n  }\n});\n\n// Reuse existing terminals instead of creating new ones\nconst terminal = await optimizer.acquireTerminal(config);\n// ... use terminal ...\nawait optimizer.releaseTerminal(terminal); // Return to pool for reuse\n</code></pre>"},{"location":"ResourceOptimizer/#2-memory-monitoring-automatic-cleanup","title":"2. Memory Monitoring &amp; Automatic Cleanup","text":"<pre><code>const optimizer = new ResourceOptimizer({\n  memory: {\n    maxHeapUsed: 512 * 1024 * 1024,  // 512MB heap limit\n    gcThreshold: 70,                  // GC at 70% of limit\n    monitorInterval: 10000            // Monitor every 10 seconds\n  }\n});\n\n// Automatic cleanup when memory pressure is detected\noptimizer.on('memoryWarning', () =&gt; {\n  // Triggers automatic resource cleanup and garbage collection\n});\n</code></pre>"},{"location":"ResourceOptimizer/#3-buffer-management-compression","title":"3. Buffer Management &amp; Compression","text":"<pre><code>// Automatic buffer rotation and compression\nconst bufferId = optimizer.createBuffer(largeOutput, true); // Enable compression\nconst data = optimizer.getBuffer(bufferId);\noptimizer.destroyBuffer(bufferId); // Explicit cleanup\n</code></pre>"},{"location":"ResourceOptimizer/#4-resource-lifecycle-management","title":"4. Resource Lifecycle Management","text":"<pre><code>// Proper integration with ProcessLifecycleManager\nconst processManager = new ProcessLifecycleManager();\nconst optimizer = new ResourceOptimizer(config, processManager);\n\n// Automatic cleanup on shutdown\nprocess.on('exit', async () =&gt; {\n  await optimizer.destroy();\n  await processManager.shutdown();\n});\n</code></pre>"},{"location":"ResourceOptimizer/#key-features","title":"Key Features","text":""},{"location":"ResourceOptimizer/#resource-pooling","title":"Resource Pooling","text":"<ul> <li>Terminal Connection Pooling: Reuses terminals instead of creating new ones</li> <li>Configuration-based Pooling: Terminals with same config are pooled together</li> <li>Lazy Initialization: Resources created only when needed</li> <li>Automatic Pool Management: Idle and aged resources are automatically cleaned up</li> </ul>"},{"location":"ResourceOptimizer/#memory-management","title":"Memory Management","text":"<ul> <li>Real-time Monitoring: Tracks heap usage, RSS, and external memory</li> <li>Automatic Garbage Collection: Triggers GC when memory thresholds are reached</li> <li>Memory Pressure Response: Aggressive cleanup during high memory usage</li> <li>Leak Detection: Monitors for continuous memory growth patterns</li> </ul>"},{"location":"ResourceOptimizer/#buffer-optimization","title":"Buffer Optimization","text":"<ul> <li>Automatic Compression: Compresses buffers above configurable threshold</li> <li>Buffer Rotation: Automatically removes old, unused buffers</li> <li>Size Limits: Enforces maximum buffer count and size limits</li> <li>Access Tracking: Tracks buffer usage for intelligent cleanup</li> </ul>"},{"location":"ResourceOptimizer/#metrics-monitoring","title":"Metrics &amp; Monitoring","text":"<ul> <li>Comprehensive Metrics: Pool, memory, and buffer statistics</li> <li>Performance Tracking: Acquisition times, GC frequency, compression ratios</li> <li>Event-driven Monitoring: Real-time notifications of resource events</li> <li>Health Monitoring: Automatic detection of resource leaks and issues</li> </ul>"},{"location":"ResourceOptimizer/#usage-examples","title":"Usage Examples","text":""},{"location":"ResourceOptimizer/#basic-usage-fixes-memory-issue","title":"Basic Usage (Fixes Memory Issue)","text":"<pre><code>import { ResourceOptimizer } from 'gadugi-agentic-test';\n\nconst optimizer = new ResourceOptimizer({\n  pool: { maxSize: 10 },\n  memory: { maxHeapUsed: 512 * 1024 * 1024 }\n});\n\n// Instead of creating new terminals for each test\nasync function runTest() {\n  const terminal = await optimizer.acquireTerminal({ shell: '/bin/bash' });\n  try {\n    // Run test...\n    const output = await terminal.executeCommand('echo \"test\"');\n    const bufferId = optimizer.createBuffer(output, true);\n\n    // Process results...\n\n  } finally {\n    await optimizer.releaseTerminal(terminal); // Critical: return to pool\n  }\n}\n\n// Run many tests without memory growth\nfor (let i = 0; i &lt; 50; i++) {\n  await runTest();\n}\n</code></pre>"},{"location":"ResourceOptimizer/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>const optimizer = new ResourceOptimizer({\n  // Connection pooling\n  pool: {\n    maxSize: 15,          // Allow up to 15 concurrent terminals\n    minSize: 3,           // Keep 3 terminals warm\n    idleTimeout: 600000,  // 10 minutes idle timeout\n    maxAge: 3600000,      // 1 hour max age\n    acquisitionTimeout: 30000\n  },\n\n  // Memory management\n  memory: {\n    maxHeapUsed: 1024 * 1024 * 1024,  // 1GB heap limit\n    maxRSS: 2048 * 1024 * 1024,       // 2GB RSS limit\n    gcThreshold: 75,                   // GC at 75% of limit\n    monitorInterval: 5000              // Monitor every 5 seconds\n  },\n\n  // Buffer management\n  buffer: {\n    maxBufferSize: 2 * 1024 * 1024,    // 2MB per buffer\n    maxTotalBuffers: 100,              // Max 100 buffers\n    compressionThreshold: 128 * 1024,  // Compress &gt; 128KB\n    rotationInterval: 120000           // Rotate every 2 minutes\n  },\n\n  enableMetrics: true,\n  enableGarbageCollection: true\n});\n</code></pre>"},{"location":"ResourceOptimizer/#event-monitoring","title":"Event Monitoring","text":"<pre><code>// Monitor resource optimization events\noptimizer.on('memoryWarning', (usage) =&gt; {\n  console.log(`Memory warning: ${usage.heapUsed / 1024 / 1024}MB`);\n});\n\noptimizer.on('resourceCreated', (type, id) =&gt; {\n  console.log(`Created ${type}: ${id}`);\n});\n\noptimizer.on('bufferRotated', (count) =&gt; {\n  console.log(`Cleaned up ${count} old buffers`);\n});\n\noptimizer.on('gcTriggered', (reason) =&gt; {\n  console.log(`Garbage collection triggered: ${reason}`);\n});\n</code></pre>"},{"location":"ResourceOptimizer/#performance-comparison","title":"Performance Comparison","text":""},{"location":"ResourceOptimizer/#before-resourceoptimizer","title":"Before ResourceOptimizer","text":"<ul> <li>Memory Usage: 2.3GB for 50 tests (linear growth)</li> <li>Resource Creation: 50+ terminal instances created</li> <li>Cleanup: Manual cleanup required, often incomplete</li> <li>Performance: Degrading performance as memory pressure increased</li> </ul>"},{"location":"ResourceOptimizer/#after-resourceoptimizer","title":"After ResourceOptimizer","text":"<ul> <li>Memory Usage: &lt;100MB for 50 tests (constant usage)</li> <li>Resource Creation: 5-10 terminal instances reused</li> <li>Cleanup: Automatic cleanup with guaranteed resource deallocation</li> <li>Performance: Consistent performance with resource reuse benefits</li> </ul>"},{"location":"ResourceOptimizer/#integration-guide","title":"Integration Guide","text":""},{"location":"ResourceOptimizer/#with-existing-tuiagent-code","title":"With Existing TUIAgent Code","text":"<pre><code>// OLD: Direct TUIAgent usage\nconst agent = new TUIAgent(config);\nawait agent.start();\n// ... use agent ...\nawait agent.destroy(); // Often forgotten!\n\n// NEW: ResourceOptimizer managed\nconst terminal = await optimizer.acquireTerminal(config);\n// ... use terminal ...\nawait optimizer.releaseTerminal(terminal); // Automatic pooling\n</code></pre>"},{"location":"ResourceOptimizer/#with-test-frameworks","title":"With Test Frameworks","text":"<pre><code>describe('Terminal Tests', () =&gt; {\n  let optimizer: ResourceOptimizer;\n\n  beforeAll(() =&gt; {\n    optimizer = new ResourceOptimizer(config);\n  });\n\n  afterAll(async () =&gt; {\n    await optimizer.destroy();\n  });\n\n  it('should run test efficiently', async () =&gt; {\n    const terminal = await optimizer.acquireTerminal(testConfig);\n    try {\n      // Test implementation\n    } finally {\n      await optimizer.releaseTerminal(terminal);\n    }\n  });\n});\n</code></pre>"},{"location":"ResourceOptimizer/#best-practices","title":"Best Practices","text":""},{"location":"ResourceOptimizer/#1-always-release-resources","title":"1. Always Release Resources","text":"<pre><code>// \u2705 Good: Always release terminals\nconst terminal = await optimizer.acquireTerminal(config);\ntry {\n  // Use terminal\n} finally {\n  await optimizer.releaseTerminal(terminal);\n}\n\n// \u274c Bad: Forgetting to release\nconst terminal = await optimizer.acquireTerminal(config);\n// Use terminal but never release\n</code></pre>"},{"location":"ResourceOptimizer/#2-configure-appropriate-limits","title":"2. Configure Appropriate Limits","text":"<pre><code>// \u2705 Good: Set realistic limits based on your environment\nconst optimizer = new ResourceOptimizer({\n  pool: { maxSize: Math.min(os.cpus().length, 10) },\n  memory: { maxHeapUsed: process.env.NODE_ENV === 'test' ? 256*1024*1024 : 512*1024*1024 }\n});\n</code></pre>"},{"location":"ResourceOptimizer/#3-monitor-resource-usage","title":"3. Monitor Resource Usage","text":"<pre><code>// \u2705 Good: Regular metrics monitoring\nsetInterval(() =&gt; {\n  const metrics = optimizer.getMetrics();\n  if (metrics.memory.heapUsed &gt; THRESHOLD) {\n    console.warn('High memory usage detected');\n  }\n}, 30000);\n</code></pre>"},{"location":"ResourceOptimizer/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>// \u2705 Good: Proper error handling\ntry {\n  const terminal = await optimizer.acquireTerminal(config);\n  // Use terminal\n} catch (error) {\n  if (error.message.includes('acquisition timeout')) {\n    // Handle pool exhaustion\n  } else if (error.message.includes('memory')) {\n    // Handle memory pressure\n  }\n}\n</code></pre>"},{"location":"ResourceOptimizer/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ResourceOptimizer/#high-memory-usage","title":"High Memory Usage","text":"<ol> <li>Check pool configuration - ensure maxSize is appropriate</li> <li>Verify all terminals are being released back to the pool</li> <li>Monitor buffer usage - enable automatic rotation</li> <li>Enable garbage collection triggers</li> </ol>"},{"location":"ResourceOptimizer/#pool-exhaustion","title":"Pool Exhaustion","text":"<ol> <li>Increase pool maxSize if needed</li> <li>Check for leaked terminal acquisitions (not released)</li> <li>Reduce acquisitionTimeout if tests are hanging</li> <li>Monitor acquisition time metrics</li> </ol>"},{"location":"ResourceOptimizer/#performance-issues","title":"Performance Issues","text":"<ol> <li>Enable metrics to identify bottlenecks</li> <li>Adjust pool minSize for better warm-up</li> <li>Consider buffer compression for large outputs</li> <li>Monitor GC frequency and timing</li> </ol>"},{"location":"ResourceOptimizer/#migration-checklist","title":"Migration Checklist","text":"<ul> <li>[ ] Replace direct TUIAgent instantiation with ResourceOptimizer.acquireTerminal()</li> <li>[ ] Add proper terminal release calls in finally blocks</li> <li>[ ] Configure appropriate pool and memory limits</li> <li>[ ] Add resource monitoring and event handlers</li> <li>[ ] Update test cleanup to use ResourceOptimizer.destroy()</li> <li>[ ] Verify memory usage improvements in testing</li> <li>[ ] Update documentation and examples</li> </ul>"},{"location":"ResourceOptimizer/#conclusion","title":"Conclusion","text":"<p>The ResourceOptimizer successfully addresses the memory issues by implementing:</p> <ol> <li>Resource Pooling: Eliminates the linear growth of terminal instances</li> <li>Memory Monitoring: Provides real-time feedback and automatic cleanup</li> <li>Buffer Management: Prevents accumulation of test output data</li> <li>Lifecycle Management: Ensures proper resource cleanup and garbage collection</li> </ol> <p>With these improvements, the memory usage for 50 tests drops from 2.3GB to under 100MB, providing a 95%+ reduction in memory consumption while maintaining full functionality.</p>"},{"location":"TROUBLESHOOTING/","title":"Troubleshooting Guide","text":"<p>This guide covers common issues you might encounter when using Gadugi Agentic Test and their solutions. The troubleshooting sections are organized by category with practical solutions and prevention tips.</p>"},{"location":"TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Quick Diagnostics</li> <li>Installation Issues</li> <li>Configuration Problems</li> <li>Agent-Specific Issues</li> <li>Test Execution Problems</li> <li>Performance Issues</li> <li>Integration Issues</li> <li>Environment-Specific Problems</li> <li>Advanced Debugging</li> <li>Getting Help</li> </ol>"},{"location":"TROUBLESHOOTING/#quick-diagnostics","title":"Quick Diagnostics","text":"<p>Before diving into specific issues, run these quick diagnostic commands:</p>"},{"location":"TROUBLESHOOTING/#system-check","title":"System Check","text":"<pre><code># Check Node.js version (requires 18+)\nnode --version\n\n# Check npm version\nnpm --version\n\n# Verify Gadugi installation\nnpx gadugi-test --version\n\n# Environment validation\nnpx gadugi-test --check-env\n</code></pre>"},{"location":"TROUBLESHOOTING/#health-check","title":"Health Check","text":"<pre><code># Run basic health check\nnpx gadugi-test health-check\n\n# Validate configuration\nnpx gadugi-test validate-config ./gadugi.config.js\n\n# Test agent connectivity\nnpx gadugi-test test-agents --dry-run\n</code></pre>"},{"location":"TROUBLESHOOTING/#log-analysis","title":"Log Analysis","text":"<pre><code># Check recent logs\ntail -f ./logs/gadugi.log\n\n# View specific session logs\nnpx gadugi-test logs --session &lt;session-id&gt;\n\n# Debug mode execution\nnpx gadugi-test run --log-level debug ./tests/simple.yaml\n</code></pre>"},{"location":"TROUBLESHOOTING/#installation-issues","title":"Installation Issues","text":""},{"location":"TROUBLESHOOTING/#issue-npm-install-fails","title":"Issue: NPM Install Fails","text":"<p>Symptoms: - Permission errors during <code>npm install</code> - Missing dependencies - Node-gyp compilation failures</p> <p>Solutions:</p> <pre><code># Fix permission issues (Unix/Mac)\nsudo chown -R $(whoami) ~/.npm\nsudo chown -R $(whoami) /usr/local/lib/node_modules\n\n# Clear npm cache\nnpm cache clean --force\n\n# Install with legacy peer deps\nnpm install --legacy-peer-deps\n\n# Use yarn as alternative\nyarn install\n</code></pre> <p>Prevention: - Use Node Version Manager (nvm/fnm) - Avoid global npm installations with sudo - Keep npm updated: <code>npm install -g npm@latest</code></p>"},{"location":"TROUBLESHOOTING/#issue-playwright-browser-installation-fails","title":"Issue: Playwright Browser Installation Fails","text":"<p>Symptoms: - Browser download timeouts - \"Executable doesn't exist\" errors - Headless browser crashes</p> <p>Solutions:</p> <pre><code># Manual browser installation\nnpx playwright install\n\n# Install specific browsers only\nnpx playwright install chromium\n\n# Force reinstall\nnpx playwright install --force\n\n# Check browser status\nnpx playwright install --dry-run\n\n# Alternative: Use system browsers\nexport PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1\nnpx playwright install-deps\n</code></pre> <p>For Corporate Networks: <pre><code># Set proxy for downloads\nexport HTTPS_PROXY=http://your-proxy:port\nexport HTTP_PROXY=http://your-proxy:port\nnpx playwright install\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#issue-python-dependencies-missing","title":"Issue: Python Dependencies Missing","text":"<p>Symptoms: - \"Python 3.11+ required\" errors - pexpect import failures - CLI agent initialization errors</p> <p>Solutions:</p> <pre><code># Install Python dependencies\npip install pexpect psutil\n\n# For virtual environments\npython -m venv gadugi-env\nsource gadugi-env/bin/activate  # Unix/Mac\n# gadugi-env\\Scripts\\activate   # Windows\npip install -r requirements.txt\n\n# Verify Python path\nwhich python3\npython3 --version\n</code></pre>"},{"location":"TROUBLESHOOTING/#configuration-problems","title":"Configuration Problems","text":""},{"location":"TROUBLESHOOTING/#issue-environment-variables-not-found","title":"Issue: Environment Variables Not Found","text":"<p>Symptoms: - \"ELECTRON_APP_PATH not set\" errors - Missing configuration values - Agent initialization failures</p> <p>Solutions:</p> <ol> <li> <p>Check .env file location: <pre><code># Ensure .env is in project root\nls -la .env\n\n# Check .env content\ncat .env\n</code></pre></p> </li> <li> <p>Verify environment loading: <pre><code># Test environment\nnode -e \"require('dotenv').config(); console.log(process.env.ELECTRON_APP_PATH)\"\n\n# Check all Gadugi env vars\nenv | grep GADUGI\n</code></pre></p> </li> <li> <p>Common .env template: <pre><code># Required\nELECTRON_APP_PATH=/path/to/your/app.exe\n\n# Optional but recommended\nGITHUB_TOKEN=your_token_here\nGADUGI_LOG_LEVEL=info\nGADUGI_HEADLESS=false\n\n# AI Integration (optional)\nAZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/\nAZURE_OPENAI_KEY=your_key_here\n</code></pre></p> </li> </ol> <p>Windows-specific paths: <pre><code># Use forward slashes or double backslashes\nELECTRON_APP_PATH=C:/Program Files/YourApp/app.exe\n# OR\nELECTRON_APP_PATH=C:\\\\Program Files\\\\YourApp\\\\app.exe\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#issue-invalid-configuration-file","title":"Issue: Invalid Configuration File","text":"<p>Symptoms: - \"Configuration validation failed\" errors - Type errors in gadugi.config.js - Unknown configuration options</p> <p>Solutions:</p> <ol> <li> <p>Validate configuration syntax: <pre><code>// gadugi.config.js - Valid example\nexport default {\n  execution: {\n    maxConcurrentAgents: 3,\n    retryAttempts: 2,\n    timeoutMultiplier: 1.0\n  },\n\n  // Avoid common mistakes:\n  // \u274c maxParallel: \"3\"        (string instead of number)\n  // \u274c undefined: values       (undefined properties)\n  // \u274c typos: 'maxParralel'    (typos in property names)\n\n  logLevel: 'info', // \u2705 Valid: 'error', 'warn', 'info', 'debug'\n\n  ui: {\n    executablePath: process.env.ELECTRON_APP_PATH, // \u2705 Dynamic values OK\n    headless: process.env.CI === 'true'\n  }\n};\n</code></pre></p> </li> <li> <p>Test configuration: <pre><code># Validate config file\nnpx gadugi-test validate-config\n\n# Show resolved configuration\nnpx gadugi-test show-config\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-path-resolution-problems","title":"Issue: Path Resolution Problems","text":"<p>Symptoms: - \"File not found\" errors - Scenario loading failures - Screenshot directory creation errors</p> <p>Solutions:</p> <pre><code># Use absolute paths in configuration\nexport ELECTRON_APP_PATH=\"$(pwd)/dist/app.exe\"\n\n# Verify file exists\nls -la \"$ELECTRON_APP_PATH\"\n\n# Check directory permissions\nls -ld ./scenarios/\nchmod 755 ./scenarios/\n\n# Create missing directories\nmkdir -p ./screenshots ./logs ./reports\n</code></pre>"},{"location":"TROUBLESHOOTING/#agent-specific-issues","title":"Agent-Specific Issues","text":""},{"location":"TROUBLESHOOTING/#electronuiagent-issues","title":"ElectronUIAgent Issues","text":""},{"location":"TROUBLESHOOTING/#issue-electron-app-wont-launch","title":"Issue: Electron App Won't Launch","text":"<p>Symptoms: - Timeout during app launch - \"Failed to launch Electron application\" errors - Process starts but no UI appears</p> <p>Solutions:</p> <ol> <li> <p>Check executable path: <pre><code># Verify file exists and is executable\nls -la \"/path/to/your/app.exe\"\nfile \"/path/to/your/app.exe\"\n\n# Test manual launch\n\"/path/to/your/app.exe\" --no-sandbox --disable-dev-shm-usage\n</code></pre></p> </li> <li> <p>Common launch arguments: <pre><code># In your scenario YAML\nagents:\n  - name: \"ui-agent\"\n    type: \"ui\"\n    config:\n      executablePath: \"${ELECTRON_APP_PATH}\"\n      args:\n        - \"--no-sandbox\"\n        - \"--disable-dev-shm-usage\"\n        - \"--disable-gpu\"\n        - \"--disable-web-security\"  # Only for testing\n      launchTimeout: 30000\n</code></pre></p> </li> <li> <p>Debug launch issues: <pre><code>// Enable Playwright debug logs\nprocess.env.DEBUG = 'pw:*';\n\n// Capture launch errors\nconst agent = new ElectronUIAgent({\n  executablePath: process.env.ELECTRON_APP_PATH,\n  args: ['--enable-logging', '--log-level=1']\n});\n\ntry {\n  await agent.launch();\n} catch (error) {\n  console.error('Launch failed:', error);\n  // Check error.message for specific failure reasons\n}\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-element-selectors-not-working","title":"Issue: Element Selectors Not Working","text":"<p>Symptoms: - \"Element not found\" errors - Selectors work manually but fail in tests - Intermittent selector failures</p> <p>Solutions:</p> <ol> <li>Use multiple selector strategies: <pre><code># Instead of relying on one selector:\n# \u274c selector: \"#submit-btn\"\n\n# Use data-testid (recommended):\n# \u2705 selector: \"[data-testid='submit-btn']\"\n\n# Or use text-based selectors:\n# \u2705 selector: \"button:has-text('Submit')\"\n\n# Or use multiple fallback strategies in code:\n</code></pre></li> </ol> <pre><code>async function robustClick(page, selectors) {\n  for (const selector of selectors) {\n    try {\n      await page.click(selector, { timeout: 2000 });\n      return; // Success\n    } catch (error) {\n      continue; // Try next selector\n    }\n  }\n  throw new Error(`None of the selectors worked: ${selectors.join(', ')}`);\n}\n\n// Usage\nawait robustClick(page, [\n  '[data-testid=\"submit-btn\"]',\n  '#submit-btn',\n  'button:has-text(\"Submit\")',\n  '.submit-button'\n]);\n</code></pre> <ol> <li> <p>Add explicit waits: <pre><code>- name: \"Wait for Element to Load\"\n  agent: \"ui-agent\"\n  action: \"wait_for_element\"\n  params:\n    selector: \"[data-testid='submit-btn']\"\n    state: \"visible\"\n    timeout: 10000\n\n- name: \"Click Submit\"\n  agent: \"ui-agent\"\n  action: \"click\"\n  params:\n    selector: \"[data-testid='submit-btn']\"\n</code></pre></p> </li> <li> <p>Debug selectors: <pre><code>// Add to your test scenarios\n- name: \"Debug Available Elements\"\n  agent: \"ui-agent\"\n  action: \"evaluate\"\n  params:\n    expression: |\n      Array.from(document.querySelectorAll('button')).map(btn =&gt; ({\n        text: btn.textContent,\n        id: btn.id,\n        classes: btn.className,\n        testId: btn.getAttribute('data-testid')\n      }))\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-screenshot-capture-failures","title":"Issue: Screenshot Capture Failures","text":"<p>Symptoms: - Screenshot files not created - Empty or corrupted screenshots - Permission errors writing screenshots</p> <p>Solutions:</p> <ol> <li> <p>Check directory permissions: <pre><code>mkdir -p ./screenshots\nchmod 755 ./screenshots\n\n# Check disk space\ndf -h .\n</code></pre></p> </li> <li> <p>Configure screenshot settings: <pre><code>agents:\n  - name: \"ui-agent\"\n    type: \"ui\"\n    config:\n      screenshotConfig:\n        mode: \"on\"  # or \"only-on-failure\", \"off\"\n        directory: \"./screenshots\"\n        fullPage: true\n</code></pre></p> </li> <li> <p>Debug screenshot capture: <pre><code>try {\n  const screenshot = await agent.screenshot('debug-capture');\n  console.log('Screenshot saved:', screenshot.filePath);\n\n  // Verify file exists\n  const fs = require('fs');\n  const stats = fs.statSync(screenshot.filePath);\n  console.log('File size:', stats.size, 'bytes');\n} catch (error) {\n  console.error('Screenshot failed:', error);\n}\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#cliagent-issues","title":"CLIAgent Issues","text":""},{"location":"TROUBLESHOOTING/#issue-command-execution-timeouts","title":"Issue: Command Execution Timeouts","text":"<p>Symptoms: - Commands hang indefinitely - Timeout errors on long-running processes - Interactive prompts not handled</p> <p>Solutions:</p> <ol> <li> <p>Adjust timeouts: <pre><code>- name: \"Long Running Command\"\n  agent: \"cli-agent\"\n  action: \"execute\"\n  params:\n    command: \"npm run build\"\n    timeout: 300000  # 5 minutes\n</code></pre></p> </li> <li> <p>Handle interactive prompts: <pre><code>// For interactive commands\nconst session = await cliAgent.startInteractiveSession('npm init');\nawait session.expect('package name:');\nawait session.send('my-package');\nawait session.expect('version:');\nawait session.send('1.0.0');\nawait session.close();\n</code></pre></p> </li> <li> <p>Use non-interactive modes: <pre><code># Add non-interactive flags\nnpm install --silent\ngit clone --quiet\nkubectl apply --wait=false\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-environment-variable-problems","title":"Issue: Environment Variable Problems","text":"<p>Symptoms: - Commands work manually but fail in tests - PATH not found errors - Permission denied errors</p> <p>Solutions:</p> <ol> <li> <p>Explicit environment setup: <pre><code>- name: \"Command with Environment\"\n  agent: \"cli-agent\"\n  action: \"execute\"\n  params:\n    command: \"node --version\"\n    environment:\n      PATH: \"${PATH}:/usr/local/bin\"\n      NODE_ENV: \"test\"\n    workingDirectory: \"./my-project\"\n</code></pre></p> </li> <li> <p>Debug environment: <pre><code># Check current environment\nnpx gadugi-test run --log-level debug\n\n# Compare with manual execution\necho $PATH\nwhich node\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#test-execution-problems","title":"Test Execution Problems","text":""},{"location":"TROUBLESHOOTING/#issue-tests-pass-locally-but-fail-in-ci","title":"Issue: Tests Pass Locally but Fail in CI","text":"<p>Symptoms: - Green tests locally, red in CI - Timing-related failures - Resource availability issues</p> <p>Solutions:</p> <ol> <li> <p>CI-specific configuration: <pre><code># .github/workflows/test.yml\nenv:\n  GADUGI_HEADLESS: \"true\"\n  GADUGI_TIMEOUT_MULTIPLIER: \"2.0\"\n  GADUGI_PARALLEL_AGENTS: \"2\"  # Reduce for CI\n</code></pre></p> </li> <li> <p>Robust wait strategies: <pre><code># Instead of fixed waits:\n# \u274c action: \"wait\"\n#    params: { duration: 1000 }\n\n# Use condition-based waits:\n# \u2705 action: \"wait_for_element\"\n#    params:\n#      selector: \"[data-testid='loaded']\"\n#      timeout: 30000\n</code></pre></p> </li> <li> <p>CI-specific timeouts: <pre><code>// gadugi.config.js\nexport default {\n  timeoutMultiplier: process.env.CI ? 2.0 : 1.0,\n  execution: {\n    maxParallel: process.env.CI ? 2 : 4\n  }\n};\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-flaky-tests","title":"Issue: Flaky Tests","text":"<p>Symptoms: - Tests sometimes pass, sometimes fail - Timing-dependent failures - Race conditions</p> <p>Solutions:</p> <ol> <li> <p>Add stability checks: <pre><code>- name: \"Wait for Stability\"\n  agent: \"ui-agent\"\n  action: \"wait_for_element\"\n  params:\n    selector: \"[data-testid='content']\"\n    state: \"visible\"\n\n- name: \"Verify Content Loaded\"\n  agent: \"ui-agent\"\n  action: \"wait_for_function\"\n  params:\n    expression: \"document.querySelectorAll('[data-loading]').length === 0\"\n    timeout: 10000\n</code></pre></p> </li> <li> <p>Retry failed steps: <pre><code>steps:\n  - name: \"Flaky Operation\"\n    agent: \"ui-agent\"\n    action: \"click\"\n    params:\n      selector: \"[data-testid='submit']\"\n    retries: 3\n    continueOnFailure: false\n</code></pre></p> </li> <li> <p>Debug flaky tests: <pre><code># Run test multiple times\nfor i in {1..10}; do\n  echo \"Run $i\"\n  npx gadugi-test run flaky-test.yaml\ndone\n\n# Capture more screenshots\n# Set mode to \"on\" for flaky tests\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-memory-leaks-during-long-test-runs","title":"Issue: Memory Leaks During Long Test Runs","text":"<p>Symptoms: - Memory usage keeps growing - Tests slow down over time - Out of memory errors</p> <p>Solutions:</p> <ol> <li> <p>Enable cleanup: <pre><code>cleanup:\n  - name: \"Close Application\"\n    agent: \"ui-agent\"\n    action: \"close_app\"\n\n  - name: \"Clear Cache\"\n    agent: \"ui-agent\"\n    action: \"evaluate\"\n    params:\n      expression: \"window.gc &amp;&amp; window.gc()\"\n</code></pre></p> </li> <li> <p>Limit concurrent agents: <pre><code>// gadugi.config.js\nexport default {\n  execution: {\n    maxConcurrentAgents: 2, // Reduce if memory constrained\n  }\n};\n</code></pre></p> </li> <li> <p>Monitor memory usage: <pre><code># Monitor during test execution\nwatch -n 1 'ps aux | grep gadugi'\n\n# Or use built-in monitoring\nnpx gadugi-test run --monitor-memory ./tests/\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#performance-issues","title":"Performance Issues","text":""},{"location":"TROUBLESHOOTING/#issue-slow-test-execution","title":"Issue: Slow Test Execution","text":"<p>Symptoms: - Tests take much longer than expected - UI operations are sluggish - High CPU usage</p> <p>Solutions:</p> <ol> <li> <p>Optimize selectors: <pre><code># Fast selectors (use these):\nselector: \"[data-testid='element']\"    # \u2705 Fast\nselector: \"#unique-id\"                 # \u2705 Fast\n\n# Slow selectors (avoid these):\nselector: \"div &gt; span:nth-child(3)\"    # \u274c Slow\nselector: \"//div[contains(@class,'x')]\" # \u274c Very slow XPath\n</code></pre></p> </li> <li> <p>Reduce screenshot frequency: <pre><code>screenshotConfig:\n  mode: \"only-on-failure\"  # Instead of \"on\"\n</code></pre></p> </li> <li> <p>Optimize wait strategies: <pre><code># Don't use fixed delays\n# \u274c action: \"wait\"\n#    params: { duration: 5000 }\n\n# Use smart waits\n# \u2705 action: \"wait_for_element\"\n#    params:\n#      selector: \"[data-loaded='true']\"\n#      timeout: 5000\n</code></pre></p> </li> <li> <p>Parallel execution: <pre><code># Run independent tests in parallel\nnpx gadugi-test run --parallel 4 ./tests/independent/\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-high-memory-usage","title":"Issue: High Memory Usage","text":"<p>Symptoms: - System becomes unresponsive - Out of memory errors - Swap usage increases</p> <p>Solutions:</p> <ol> <li> <p>Limit browser instances: <pre><code>// gadugi.config.js\nexport default {\n  ui: {\n    maxInstances: 2, // Limit concurrent browsers\n  },\n  execution: {\n    maxConcurrentAgents: 2\n  }\n};\n</code></pre></p> </li> <li> <p>Enable headless mode: <pre><code>export GADUGI_HEADLESS=true\nnpx gadugi-test run ./tests/\n</code></pre></p> </li> <li> <p>Clear artifacts regularly: <pre><code># Clean old screenshots and logs\nfind ./screenshots -mtime +7 -delete\nfind ./logs -mtime +3 -delete\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#integration-issues","title":"Integration Issues","text":""},{"location":"TROUBLESHOOTING/#issue-github-integration-not-working","title":"Issue: GitHub Integration Not Working","text":"<p>Symptoms: - Issues not created automatically - Authentication errors - API rate limiting</p> <p>Solutions:</p> <ol> <li> <p>Verify token permissions: <pre><code># Test GitHub token\ncurl -H \"Authorization: token $GITHUB_TOKEN\" \\\n     https://api.github.com/user\n\n# Check required scopes: repo, issues\n</code></pre></p> </li> <li> <p>Configure properly: <pre><code>// gadugi.config.js\nexport default {\n  github: {\n    repository: 'owner/repo',  // \u2705 Correct format\n    // repository: 'https://github.com/owner/repo', // \u274c Wrong\n    createIssues: true,\n    token: process.env.GITHUB_TOKEN\n  }\n};\n</code></pre></p> </li> <li> <p>Handle rate limiting: <pre><code>// Reduce issue creation frequency\ngithub: {\n  createIssues: process.env.NODE_ENV === 'production',\n  rateLimit: {\n    requestsPerHour: 100\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#issue-websocket-connection-problems","title":"Issue: WebSocket Connection Problems","text":"<p>Symptoms: - WebSocket timeouts - Connection refused errors - Events not received</p> <p>Solutions:</p> <ol> <li> <p>Verify WebSocket server: <pre><code># Test WebSocket manually\nnpx wscat -c ws://localhost:3001\n\n# Check if server is running\nnetstat -an | grep 3001\n</code></pre></p> </li> <li> <p>Configure connection properly: <pre><code>agents:\n  - name: \"websocket-agent\"\n    type: \"websocket\"\n    config:\n      url: \"ws://localhost:3001\"\n      reconnectAttempts: 5\n      reconnectDelay: 2000\n      timeout: 10000\n</code></pre></p> </li> <li> <p>Debug connection issues: <pre><code>// Enable WebSocket debugging\nprocess.env.DEBUG = 'socket.io-client:*';\n\n// Test connection programmatically\nconst io = require('socket.io-client');\nconst socket = io('ws://localhost:3001');\n\nsocket.on('connect', () =&gt; console.log('Connected'));\nsocket.on('connect_error', (error) =&gt; console.error('Connection error:', error));\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#environment-specific-problems","title":"Environment-Specific Problems","text":""},{"location":"TROUBLESHOOTING/#windows-specific-issues","title":"Windows-Specific Issues","text":""},{"location":"TROUBLESHOOTING/#issue-path-separator-problems","title":"Issue: Path Separator Problems","text":"<p>Solutions: <pre><code>// Use path.join() for cross-platform paths\nconst path = require('path');\nconst configPath = path.join(__dirname, 'config', 'gadugi.config.js');\n\n// Or use forward slashes (works on Windows)\nELECTRON_APP_PATH=C:/Program Files/MyApp/app.exe\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#issue-powershell-execution-policy","title":"Issue: PowerShell Execution Policy","text":"<p>Solutions: <pre><code># Allow script execution\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n\n# Or run specific command\npowershell -ExecutionPolicy Bypass -File script.ps1\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#macos-specific-issues","title":"macOS-Specific Issues","text":""},{"location":"TROUBLESHOOTING/#issue-gatekeeper-blocking-electron-app","title":"Issue: Gatekeeper Blocking Electron App","text":"<p>Solutions: <pre><code># Allow unsigned app to run\nsudo spctl --master-disable\n\n# Or add specific exception\nsudo spctl --add /path/to/your/app.app\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#issue-permission-denied-errors","title":"Issue: Permission Denied Errors","text":"<p>Solutions: <pre><code># Fix permissions\nchmod +x /path/to/your/app\nsudo chown -R $(whoami) /path/to/project\n\n# Add to PATH if needed\nexport PATH=\"/usr/local/bin:$PATH\"\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#linux-specific-issues","title":"Linux-Specific Issues","text":""},{"location":"TROUBLESHOOTING/#issue-missing-display-server","title":"Issue: Missing Display Server","text":"<p>Solutions: <pre><code># Install Xvfb for headless\nsudo apt-get install xvfb\n\n# Run with virtual display\nxvfb-run -a npx gadugi-test run ./tests/\n\n# Or set headless mode\nexport GADUGI_HEADLESS=true\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#issue-browser-dependencies-missing","title":"Issue: Browser Dependencies Missing","text":"<p>Solutions: <pre><code># Install browser dependencies\nnpx playwright install-deps\n\n# For Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install -y \\\n  libnss3 \\\n  libatk-bridge2.0-0 \\\n  libdrm2 \\\n  libxcomposite1 \\\n  libxdamage1 \\\n  libxrandr2 \\\n  libgbm1 \\\n  libxss1 \\\n  libasound2\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#docker-specific-issues","title":"Docker-Specific Issues","text":""},{"location":"TROUBLESHOOTING/#issue-container-crashes","title":"Issue: Container Crashes","text":"<p>Solutions: <pre><code># Add necessary capabilities\nFROM node:18-alpine\n\n# Install browser dependencies\nRUN apk add --no-cache \\\n    chromium \\\n    nss \\\n    freetype \\\n    freetype-dev \\\n    harfbuzz \\\n    ca-certificates \\\n    ttf-freefont\n\n# Set Chrome path\nENV CHROME_BIN=\"/usr/bin/chromium-browser\"\nENV CHROME_PATH=\"/usr/bin/chromium-browser\"\n\n# Disable Chrome sandbox\nENV GADUGI_HEADLESS=true\nENV CHROME_ARGS=\"--no-sandbox --disable-dev-shm-usage\"\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#advanced-debugging","title":"Advanced Debugging","text":""},{"location":"TROUBLESHOOTING/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Maximum verbosity\nexport DEBUG=gadugi:*,pw:*\nexport GADUGI_LOG_LEVEL=debug\n\n# Run with debug output\nnpx gadugi-test run --log-level debug ./tests/\n</code></pre>"},{"location":"TROUBLESHOOTING/#capture-debug-information","title":"Capture Debug Information","text":"<pre><code># Generate debug report\nnpx gadugi-test debug-report --output ./debug-info.json\n\n# Include system information\nnpx gadugi-test debug-report --include-system --output ./debug-full.json\n</code></pre>"},{"location":"TROUBLESHOOTING/#manual-agent-testing","title":"Manual Agent Testing","text":"<pre><code>// test-agent.js - Manual agent testing\nconst { ElectronUIAgent } = require('@gadugi/agentic-test');\n\nasync function testAgent() {\n  const agent = new ElectronUIAgent({\n    executablePath: process.env.ELECTRON_APP_PATH,\n    headless: false\n  });\n\n  try {\n    console.log('Initializing agent...');\n    await agent.initialize();\n\n    console.log('Launching application...');\n    await agent.launch();\n\n    console.log('Taking screenshot...');\n    await agent.screenshot('manual-test');\n\n    console.log('Success!');\n\n  } catch (error) {\n    console.error('Agent test failed:', error);\n  } finally {\n    await agent.cleanup();\n  }\n}\n\ntestAgent();\n</code></pre>"},{"location":"TROUBLESHOOTING/#performance-profiling","title":"Performance Profiling","text":"<pre><code># Profile test execution\nnode --prof $(which gadugi-test) run ./tests/\n\n# Analyze profile\nnode --prof-process isolate-*.log &gt; profile.txt\n\n# Memory usage profiling\nnode --inspect $(which gadugi-test) run ./tests/\n</code></pre>"},{"location":"TROUBLESHOOTING/#network-debugging","title":"Network Debugging","text":"<pre><code># Capture network traffic\nexport DEBUG=axios:*\n\n# Monitor WebSocket connections\nnpx wscat -l 3001  # Listen mode\n</code></pre>"},{"location":"TROUBLESHOOTING/#getting-help","title":"Getting Help","text":""},{"location":"TROUBLESHOOTING/#self-help-resources","title":"Self-Help Resources","text":"<ol> <li>Documentation:</li> <li>Getting Started Guide</li> <li>API Reference</li> <li> <p>Example Scenarios</p> </li> <li> <p>Debug Tools: <pre><code># Built-in help\nnpx gadugi-test --help\nnpx gadugi-test run --help\n\n# Health check\nnpx gadugi-test health-check\n\n# Configuration validation\nnpx gadugi-test validate-config\n</code></pre></p> </li> <li> <p>Community Resources:</p> </li> <li>GitHub Discussions</li> <li>Issue Tracker</li> </ol>"},{"location":"TROUBLESHOOTING/#creating-effective-bug-reports","title":"Creating Effective Bug Reports","text":"<p>When creating an issue, include:</p> <ol> <li> <p>Environment Information: <pre><code>npx gadugi-test --version\nnode --version\nnpm --version\nuname -a  # Linux/Mac\n</code></pre></p> </li> <li> <p>Configuration: <pre><code># Share your configuration (remove sensitive data)\nnpx gadugi-test show-config --sanitized\n</code></pre></p> </li> <li> <p>Logs: <pre><code># Recent logs\ntail -n 100 ./logs/gadugi.log\n\n# Debug run\nnpx gadugi-test run --log-level debug ./failing-test.yaml\n</code></pre></p> </li> <li> <p>Minimal Reproduction:</p> </li> <li>Simplest scenario that reproduces the issue</li> <li>Steps to reproduce</li> <li>Expected vs actual behavior</li> </ol>"},{"location":"TROUBLESHOOTING/#template-bug-report","title":"Template Bug Report","text":"<pre><code>## Bug Description\nBrief description of the issue\n\n## Environment\n- Gadugi version: X.X.X\n- Node.js version: X.X.X\n- OS: [Windows/macOS/Linux]\n- Browser: [if UI testing]\n\n## Configuration\n```yaml\n# Your gadugi config (sanitized)\n</code></pre>"},{"location":"TROUBLESHOOTING/#steps-to-reproduce","title":"Steps to Reproduce","text":"<ol> <li>Step 1</li> <li>Step 2</li> <li>Step 3</li> </ol>"},{"location":"TROUBLESHOOTING/#expected-behavior","title":"Expected Behavior","text":"<p>What you expected to happen</p>"},{"location":"TROUBLESHOOTING/#actual-behavior","title":"Actual Behavior","text":"<p>What actually happened</p>"},{"location":"TROUBLESHOOTING/#logs","title":"Logs","text":"<pre><code>Relevant log output\n</code></pre>"},{"location":"TROUBLESHOOTING/#additional-context","title":"Additional Context","text":"<p>Any other relevant information ```</p>"},{"location":"TROUBLESHOOTING/#preventive-measures","title":"Preventive Measures","text":""},{"location":"TROUBLESHOOTING/#best-practices-for-stability","title":"Best Practices for Stability","text":"<ol> <li> <p>Use stable selectors: <code>html    &lt;button data-testid=\"submit-btn\"&gt;Submit&lt;/button&gt;</code></p> </li> <li> <p>Implement proper waits:    ```yaml</p> </li> <li> <p>action: \"wait_for_element\"      params:        selector: \"[data-loaded='true']\"    ```</p> </li> <li> <p>Add cleanup steps:    ```yaml    cleanup:</p> <ul> <li>action: \"close_app\"    ```</li> </ul> </li> <li> <p>Monitor resource usage: <code>bash    # Regular cleanup    find ./logs -mtime +7 -delete    find ./screenshots -mtime +14 -delete</code></p> </li> <li> <p>Version control configuration: <code>bash    # Track config changes    git add gadugi.config.js .env.example</code></p> </li> </ol> <p>This troubleshooting guide covers the most common issues encountered when using Gadugi Agentic Test. If you encounter an issue not covered here, please open an issue on GitHub with detailed information, and we'll help you resolve it and update this guide.</p> <p>Remember: Most issues are configuration-related and can be resolved quickly with the right diagnostics. When in doubt, start with the Quick Diagnostics section!</p>"},{"location":"quality-audit-2026-02/","title":"Quality Audit Report \u2014 February 2026","text":"<p>Note: This is a historical audit report from 2026-02-22. All issues identified have been resolved. See the CHANGELOG for details on each fix and the PRs that addressed them.</p> <p>Date: 2026-02-21 Scope: Full codebase (21,923 LOC, ~55 TypeScript source files) Method: 4 parallel review agents + direct analysis Master Issue: #31</p>"},{"location":"quality-audit-2026-02/#executive-summary","title":"Executive Summary","text":"<p>The audit identified 12 new GitHub issues across security, bugs, architecture, and quality categories. Seven issues were fixed immediately as part of this audit session. Five architectural and quality issues require more substantial refactoring work and are tracked as open GitHub issues.</p>"},{"location":"quality-audit-2026-02/#issues-fixed-during-audit","title":"Issues Fixed During Audit","text":"Fix File Issue <code>yaml.load()</code> uses <code>JSON_SCHEMA</code> \u2014 prevents <code>!!js/function</code> code execution <code>src/utils/yamlParser.ts:120,198</code> #20 \u2705 Path traversal guard in <code>processIncludes()</code> <code>src/utils/yamlParser.ts:187</code> #20 \u2705 Priority mapping corrected: medium\u2192MEDIUM, low\u2192LOW <code>src/adapters/scenarioAdapter.ts:99</code> #22 \u2705 <code>getSafeEnvironment()</code> replaces <code>process.env</code> in issue templates <code>src/agents/IssueReporter.ts:675</code> #19 \u2705 <code>setEnvironmentVariable()</code> no longer mutates <code>process.env</code> <code>src/agents/TUIAgent.ts:1195</code>, <code>src/agents/CLIAgent.ts:828</code> #30 \u2705 Removed <code>strict: false</code> override from Jest ts-jest config <code>jest.config.js:15</code> \u2014 \u2705 Added coverage thresholds (15% floor) to jest.config.js <code>jest.config.js</code> #27 \u2705"},{"location":"quality-audit-2026-02/#open-issues-by-priority","title":"Open Issues by Priority","text":""},{"location":"quality-audit-2026-02/#critical-security-fixed","title":"\u2705 Critical Security (Fixed)","text":"Issue File Description #19 \u2705 <code>IssueReporter.ts:675</code> Full <code>process.env</code> in issue bodies \u2014 fixed: replaced with <code>getSafeEnvironment()</code> allowlist #30 \u2705 <code>TUIAgent.ts:1195</code>, <code>CLIAgent.ts:828</code> <code>process.env</code> mutation \u2014 fixed: variables stored in local config only <p>Additional security findings not yet tracked as issues: - <code>IssueReporter.ts:451</code> \u2014 Screenshots uploaded to public GitHub Gists - <code>IssueReporter.ts:648</code> \u2014 MD5 used for fingerprint hashing (use SHA-256) - <code>ComprehensionAgent.ts:847</code> \u2014 OpenAI API key silently defaults to empty string - <code>config.ts:186</code> \u2014 <code>GITHUB_TOKEN</code> written to disk via <code>exportToFile()</code> - <code>SystemAgent.ts:714</code> \u2014 Shell injection via Docker container IDs</p>"},{"location":"quality-audit-2026-02/#high-priority-bugs-fixed","title":"\u2705 High Priority Bugs (Fixed)","text":"Issue File Description #21 \u2705 <code>cli.ts:361</code> Watch command \u2014 fixed: uses real <code>TestOrchestrator.runWithScenarios()</code> #23 \u2705 <code>TestOrchestrator.ts:507</code> Concurrency limiter \u2014 fixed: semaphore counter enforces <code>maxParallel</code> #24 \u2705 <code>logger.ts:440</code> setupLogger \u2014 fixed: swaps <code>_activeLogger</code> reference, no mutation #14 Multiple Duplicate incompatible type systems (pre-existing, open) <p>Additional bugs not yet tracked as issues: - <code>ElectronUIAgent.ts:793</code> \u2014 All dialogs auto-accepted, suppresses real error dialogs - <code>ComprehensionAgent.ts:427</code> \u2014 LLM failures silently return fake \"Unknown Feature\" specs - <code>SmartUITestRunner.ts:427</code> \u2014 Hard-coded <code>waitForTimeout(1000)</code> (the exact anti-pattern this project fixes) - <code>runners/index.ts:52</code> \u2014 Uses <code>require()</code> despite ES imports already at top of file - <code>cli.ts:629</code> \u2014 List command hardcodes <code>disabled: 0</code> - <code>orchestrator/index.ts:17</code> \u2014 Re-exports <code>TestScenario</code> type that doesn't exist in <code>TestModels.ts</code> - <code>scenarioAdapter.ts:32</code> \u2014 <code>adaptScenarioToComplex()</code> always generates new UUID, losing original scenario ID - <code>scenarios/index.ts:45</code> \u2014 <code>convertLegacyFormat()</code> silently drops all scenarios after the first - <code>IssueReporter.ts:854</code> \u2014 Rate limit wait blocks entire agent for up to 1 hour</p>"},{"location":"quality-audit-2026-02/#architecture-issues","title":"\ud83d\udfe0 Architecture Issues","text":"Issue Files Description #25 <code>core/TUIAgent.ts</code>, <code>agents/TUIAgent.ts</code> Two incompatible <code>TUIAgent</code> classes with the same name #26 <code>cli.ts</code>, <code>main.ts</code> Dual CLI entry points with divergent defaults; <code>main.ts</code> parses argv on import #29 Multiple <code>IssueReporter.execute()</code> always throws; 5 other stub methods silently return empty <p>Additional architecture findings: - <code>ElectronUIAgent.ts:21</code> \u2014 Duplicates entire Socket.IO client (should delegate to WebSocketAgent) - <code>ComprehensiveUITestRunner.ts</code> \u2014 Near-duplicate of SmartUITestRunner, needs <code>BaseUITestRunner</code> - <code>utils/index.ts:13</code> \u2014 <code>LegacyConfigManager</code> and <code>legacyLogger</code> are dead duplicates that expose secrets at import time - <code>scenarios/index.ts:87</code> \u2014 <code>TestScenario</code> defined twice with incompatible shapes (see also #14) - <code>src/index.ts</code> \u2014 Public library entry point missing agent/orchestrator exports entirely - <code>TestOrchestrator.ts:725</code> \u2014 <code>reportFailures()</code> is a no-op stub</p>"},{"location":"quality-audit-2026-02/#quality-coverage-issues","title":"\ud83d\udfe1 Quality &amp; Coverage Issues","text":"Issue Files Description #27 Multiple Zero test coverage for 9 major modules (orchestrator, 7 agents, 2 runners) #28 <code>src/agents/</code> All 9 agent files exceed 300 LOC (894\u20131325 LOC); <code>deepEqual</code> and <code>delay</code> duplicated 3\u20134\u00d7"},{"location":"quality-audit-2026-02/#metrics","title":"Metrics","text":"Category Count Files audited ~55 Total LOC 21,923 Issues created 12 Issues fixed during audit 5 Critical security findings 7 High severity bugs 10 Architecture issues 10 Quality / coverage issues 5 Untested production LOC (approx.) ~9,455 (43%)"},{"location":"quality-audit-2026-02/#fix-status","title":"Fix Status","text":"<p>Completed during audit (10 fixes, CI passing): - \u2705 #19 \u2014 <code>getSafeEnvironment()</code> allowlist prevents secrets in issue bodies - \u2705 #20 \u2014 <code>yaml.load()</code> safe schema + path traversal guard - \u2705 #21 \u2014 Watch command now uses real <code>TestOrchestrator.runWithScenarios()</code> - \u2705 #22 \u2014 Priority mapping corrected (medium\u2192MEDIUM, low\u2192LOW) - \u2705 #23 \u2014 <code>executeParallel()</code> semaphore enforces <code>maxParallel</code> - \u2705 #24 \u2014 <code>setupLogger()</code> swaps reference instead of mutating instance - \u2705 #30 \u2014 <code>process.env</code> mutation removed from TUIAgent and CLIAgent - \u2705 Jest strict mode re-enabled; coverage thresholds added</p> <p>Open \u2014 Architecture (tracked as GitHub issues): - #25 \u2014 Rename one TUIAgent to eliminate naming collision - #26 \u2014 Consolidate to single CLI entry point - #14 \u2014 Resolve duplicate type systems - #29 \u2014 Remove/implement stub methods</p> <p>Open \u2014 Quality (tracked as GitHub issues): - #27 \u2014 Add tests for <code>TestOrchestrator</code>, <code>ScenarioLoader</code>, <code>CLIAgent</code> - #28 \u2014 Split oversized agent files; extract shared <code>delay()</code> and <code>deepEqual()</code></p> <p>Resolved \u2014 WS-D Quality Wave (2026-02-23, #129): - D1 \u2014 <code>ids.ts</code>: <code>.substr()</code> replaced with <code>.slice()</code> (deprecated API regression) - D2 \u2014 <code>utils/index.ts</code>: Removed dead exports (<code>LegacyConfigManager</code>, <code>TimeUtils</code>, <code>legacyLogger</code>, <code>createLegacyLogger</code>, <code>StringUtils</code>) - D3 \u2014 All 9 <code>@deprecated</code> annotations updated with <code>Will be removed in v2.0.</code> removal timeline - D4 \u2014 <code>ConfigValidator.ts</code>: Added 4 missing validations (github.token, maxRetries bounds, tui.shell type, reporting.formats allowlist) - D5 \u2014 <code>SystemAgent.ts</code>: <code>baselineCaptureInterval</code> stored on instance; cleared in <code>cleanup()</code></p>"},{"location":"scenarios-README/","title":"Test Scenarios","text":"<p>This directory contains YAML-based test scenarios for the TypeScript Agentic Testing System. Each scenario defines comprehensive test workflows that can be executed by autonomous testing agents.</p>"},{"location":"scenarios-README/#overview","title":"Overview","text":"<p>Test scenarios are defined in YAML format and describe complex testing workflows that involve multiple agents working together. Use these scenarios with the <code>@gadugi/agentic-test</code> framework (<code>gadugi-test</code> CLI) to orchestrate agents that test Electron apps, CLI tools, and TUI applications.</p>"},{"location":"scenarios-README/#scenario-files","title":"Scenario Files","text":""},{"location":"scenarios-README/#core-test-scenarios","title":"Core Test Scenarios","text":"<ol> <li>cli-tests.yaml - CLI Command Testing</li> <li>Tests all core CLI commands (<code>atg --version</code>, <code>atg --help</code>, <code>atg build</code>, etc.)</li> <li>Validates error handling for missing parameters</li> <li> <p>Tests command validation and help systems</p> </li> <li> <p>ui-navigation.yaml - UI Navigation Testing</p> </li> <li>Tests navigation through all application tabs</li> <li>Verifies UI components load correctly</li> <li> <p>Tests tab switching and state management</p> </li> <li> <p>ui-workflows.yaml - Complete UI Workflows</p> </li> <li>End-to-end workflow testing for all major operations</li> <li>Tests Build, Generate Spec, Generate IaC, Configuration workflows</li> <li> <p>Includes WebSocket communication testing</p> </li> <li> <p>error-handling.yaml - Error Scenario Testing</p> </li> <li>Tests application behavior under various error conditions</li> <li>Validates error messages and recovery mechanisms</li> <li> <p>Tests network failures, invalid inputs, and timeout scenarios</p> </li> <li> <p>integration-tests.yaml - Integration Testing</p> </li> <li>Tests CLI-UI synchronization</li> <li>WebSocket communication validation</li> <li>Neo4j database integration testing</li> <li>Azure API interaction testing</li> </ol>"},{"location":"scenarios-README/#scenario-file-structure","title":"Scenario File Structure","text":"<p>Each YAML scenario file follows this standard structure:</p> <pre><code># Scenario metadata\nname: \"Descriptive Scenario Name\"\ndescription: \"Detailed description of what this scenario tests\"\nversion: \"1.0.0\"\n\n# Test configuration\nconfig:\n  timeout: 120000      # Maximum time for entire scenario (ms)\n  retries: 2           # Number of retries on failure\n  parallel: false      # Whether steps can run in parallel\n\n# Environment requirements\nenvironment:\n  requires:            # Required environment variables\n    - REQUIRED_VAR_1\n    - REQUIRED_VAR_2\n  optional:            # Optional environment variables\n    - OPTIONAL_VAR_1\n\n# Agent definitions\nagents:\n  - name: \"agent-name\"\n    type: \"agent-type\"  # ui, system, websocket, database, api, network\n    config:\n      # Agent-specific configuration\n\n# Test execution steps\nsteps:\n  - name: \"Step Description\"\n    agent: \"agent-name\"\n    action: \"action-name\"\n    params:\n      # Action parameters\n    expect:\n      # Expected outcomes\n    timeout: 30000\n    wait_for:\n      # Conditions to wait for\n\n# Validation assertions\nassertions:\n  - name: \"Assertion Description\"\n    type: \"assertion-type\"\n    agent: \"agent-name\"\n    params:\n      # Assertion parameters\n\n# Cleanup actions\ncleanup:\n  - name: \"Cleanup Description\"\n    agent: \"agent-name\"\n    action: \"cleanup-action\"\n\n# Metadata\nmetadata:\n  tags: [\"tag1\", \"tag2\"]\n  priority: \"high\"\n  author: \"author-name\"\n  created: \"ISO-date\"\n  updated: \"ISO-date\"\n</code></pre>"},{"location":"scenarios-README/#agent-types","title":"Agent Types","text":""},{"location":"scenarios-README/#ui-agent-type-ui","title":"UI Agent (<code>type: \"ui\"</code>)","text":"<p>Handles Electron application interactions via Playwright.</p> <p>Configuration: <pre><code>config:\n  browser: \"chromium\"     # Browser engine\n  headless: false         # Run with or without UI\n  viewport:\n    width: 1280\n    height: 720\n  timeout: 30000\n  slowMo: 500            # Slow down actions for stability\n</code></pre></p> <p>Common Actions: - <code>launch_electron</code> - Launch Electron application - <code>click</code> - Click on elements - <code>fill</code> - Fill form inputs - <code>wait_for_element</code> - Wait for element states - <code>multi_action</code> - Execute multiple actions sequentially - <code>execute_script</code> - Run JavaScript in the browser context - <code>close_app</code> - Close the application</p>"},{"location":"scenarios-README/#system-agent-type-system","title":"System Agent (<code>type: \"system\"</code>)","text":"<p>Executes command-line operations and system interactions.</p> <p>Configuration: <pre><code>config:\n  shell: \"bash\"           # Shell to use\n  cwd: \"/path/to/directory\"\n  timeout: 60000\n  capture_output: true    # Capture stdout/stderr\n</code></pre></p> <p>Common Actions: - <code>execute_command</code> - Execute shell commands - <code>check_process</code> - Check if processes are running - <code>file_operations</code> - File system operations</p>"},{"location":"scenarios-README/#websocket-agent-type-websocket","title":"WebSocket Agent (<code>type: \"websocket\"</code>)","text":"<p>Manages WebSocket connections and real-time communication.</p> <p>Configuration: <pre><code>config:\n  url: \"ws://localhost:3001\"\n  reconnect: true\n  timeout: 10000\n</code></pre></p> <p>Common Actions: - <code>connect</code> - Establish WebSocket connection - <code>listen</code> - Listen for specific events - <code>send_message</code> - Send messages - <code>disconnect</code> - Close connections</p>"},{"location":"scenarios-README/#database-agent-type-database","title":"Database Agent (<code>type: \"database\"</code>)","text":"<p>Handles database operations and testing.</p> <p>Configuration: <pre><code>config:\n  type: \"neo4j\"\n  host: \"localhost\"\n  port: \"7687\"\n  auth:\n    username: \"neo4j\"\n    password: \"${NEO4J_PASSWORD}\"\n  timeout: 15000\n</code></pre></p> <p>Common Actions: - <code>connect</code> - Connect to database - <code>execute_query</code> - Run database queries - <code>stress_test</code> - Performance testing - <code>disconnect</code> - Close connections</p>"},{"location":"scenarios-README/#api-agent-type-api","title":"API Agent (<code>type: \"api\"</code>)","text":"<p>Tests REST API endpoints and external service integrations.</p> <p>Configuration: <pre><code>config:\n  timeout: 30000\n  retry_count: 3\n</code></pre></p> <p>Common Actions: - <code>authenticate_azure</code> - Azure authentication - <code>call_api</code> - HTTP API calls - <code>test_endpoints</code> - Endpoint validation</p>"},{"location":"scenarios-README/#network-agent-type-network","title":"Network Agent (<code>type: \"network\"</code>)","text":"<p>Simulates network conditions and failures.</p> <p>Configuration: <pre><code>config:\n  can_simulate_failures: true\n  timeout: 10000\n</code></pre></p> <p>Common Actions: - <code>block_port</code> - Block network ports - <code>unblock_port</code> - Restore network access - <code>simulate_latency</code> - Add network delays</p>"},{"location":"scenarios-README/#writing-new-scenarios","title":"Writing New Scenarios","text":""},{"location":"scenarios-README/#1-define-the-scenario-purpose","title":"1. Define the Scenario Purpose","text":"<p>Start by clearly defining what your scenario will test: - What functionality or workflow? - What success criteria? - What failure modes to test?</p>"},{"location":"scenarios-README/#2-choose-appropriate-agents","title":"2. Choose Appropriate Agents","text":"<p>Select the agents needed for your test: - UI testing: <code>ui-agent</code> - CLI operations: <code>system-agent</code> - Real-time updates: <code>websocket-agent</code> - Database operations: <code>database-agent</code> - API testing: <code>api-agent</code> - Network conditions: <code>network-agent</code></p>"},{"location":"scenarios-README/#3-plan-the-test-steps","title":"3. Plan the Test Steps","text":"<p>Break down your test into logical steps: 1. Setup/initialization 2. Main test actions 3. Verification/validation 4. Cleanup</p>"},{"location":"scenarios-README/#4-define-environment-requirements","title":"4. Define Environment Requirements","text":"<p>List all environment variables needed: - Required: Variables that must be present - Optional: Variables that enhance testing but aren't mandatory</p>"},{"location":"scenarios-README/#5-write-comprehensive-assertions","title":"5. Write Comprehensive Assertions","text":"<p>Include assertions that validate: - Expected outcomes occurred - No unexpected errors happened - System remains in valid state - Performance criteria met</p>"},{"location":"scenarios-README/#6-include-proper-cleanup","title":"6. Include Proper Cleanup","text":"<p>Always include cleanup steps to: - Close applications and connections - Remove test data - Restore system state - Clean up temporary files</p>"},{"location":"scenarios-README/#best-practices","title":"Best Practices","text":""},{"location":"scenarios-README/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Scenario files: <code>kebab-case.yaml</code></li> <li>Step names: \"Descriptive Action Description\"</li> <li>Agent names: \"purpose-agent\" (e.g., \"ui-agent\", \"cli-agent\")</li> </ul>"},{"location":"scenarios-README/#timeout-management","title":"Timeout Management","text":"<ul> <li>Set appropriate timeouts for each step</li> <li>Consider network latency and system performance</li> <li>Use longer timeouts for integration tests</li> <li>Use shorter timeouts for unit-style tests</li> </ul>"},{"location":"scenarios-README/#error-handling","title":"Error Handling","text":"<ul> <li>Include <code>expect_failure: true</code> for negative tests</li> <li>Use <code>optional: true</code> for steps that may not apply</li> <li>Include <code>ignore_errors: true</code> in cleanup steps</li> <li>Test both success and failure scenarios</li> </ul>"},{"location":"scenarios-README/#environment-variables","title":"Environment Variables","text":"<ul> <li>Use <code>${VAR_NAME}</code> syntax for variable substitution</li> <li>Provide defaults where appropriate: <code>${VAR_NAME:-default_value}</code></li> <li>Document all required variables in the environment section</li> </ul>"},{"location":"scenarios-README/#test-data-management","title":"Test Data Management","text":"<ul> <li>Use unique identifiers: <code>test-${TIMESTAMP}</code></li> <li>Clean up test data in cleanup section</li> <li>Don't rely on persistent state between tests</li> </ul>"},{"location":"scenarios-README/#documentation","title":"Documentation","text":"<ul> <li>Use descriptive names and descriptions</li> <li>Include comments for complex steps</li> <li>Tag scenarios appropriately for filtering</li> <li>Update metadata when modifying scenarios</li> </ul>"},{"location":"scenarios-README/#example-minimal-scenario","title":"Example Minimal Scenario","text":"<pre><code>name: \"Simple UI Test\"\ndescription: \"Basic UI interaction test\"\nversion: \"1.0.0\"\n\nconfig:\n  timeout: 60000\n  retries: 1\n  parallel: false\n\nenvironment:\n  requires:\n    - ELECTRON_APP_PATH\n\nagents:\n  - name: \"ui-agent\"\n    type: \"ui\"\n    config:\n      browser: \"chromium\"\n      headless: false\n      timeout: 30000\n\nsteps:\n  - name: \"Launch App\"\n    agent: \"ui-agent\"\n    action: \"launch_electron\"\n    params:\n      executablePath: \"${ELECTRON_APP_PATH}\"\n    timeout: 20000\n\n  - name: \"Click Button\"\n    agent: \"ui-agent\"\n    action: \"click\"\n    params:\n      selector: \"[data-testid='test-button']\"\n    wait_for:\n      selector: \"[data-testid='result']\"\n      state: \"visible\"\n\nassertions:\n  - name: \"Result Displayed\"\n    type: \"element_visible\"\n    agent: \"ui-agent\"\n    params:\n      selector: \"[data-testid='result']\"\n\ncleanup:\n  - name: \"Close App\"\n    agent: \"ui-agent\"\n    action: \"close_app\"\n\nmetadata:\n  tags: [\"ui\", \"simple\"]\n  priority: \"medium\"\n  author: \"developer\"\n  created: \"2024-09-03T00:00:00Z\"\n</code></pre>"},{"location":"scenarios-README/#running-scenarios","title":"Running Scenarios","text":"<p>Scenarios are executed by the TypeScript Agentic Testing System orchestrator. The system will:</p> <ol> <li>Parse the YAML scenario</li> <li>Validate environment requirements</li> <li>Initialize specified agents</li> <li>Execute steps in sequence</li> <li>Run assertions to validate outcomes</li> <li>Execute cleanup procedures</li> <li>Generate comprehensive reports</li> </ol> <p>For more information on running scenarios, see the Getting Started guide.</p>"},{"location":"scenarios-README/#schema-notes","title":"Schema Notes","text":""},{"location":"scenarios-README/#stable-scenario-ids","title":"Stable Scenario IDs","text":"<p>The <code>id</code> field in a scenario definition is now a deterministic slug derived from the scenario <code>name</code>. You do not need to set <code>id</code> manually \u2014 the framework generates a stable identifier from the name, so scenario IDs remain consistent across runs and across team members:</p> <pre><code>name: \"CLI Smoke Test\"\n# id is automatically: \"cli-smoke-test\"\n</code></pre> <p>Previously, each load generated a new UUID, which made cross-run comparisons unreliable.</p>"},{"location":"scenarios-README/#agents-array-validation","title":"Agents Array Validation","text":"<p>The <code>agents</code> array is now validated on load. A scenario with an empty or missing <code>agents</code> field is rejected with a clear error message:</p> <pre><code># Valid \u2014 at least one agent required\nagents:\n  - name: \"cli-agent\"\n    type: \"system\"\n    config:\n      shell: \"bash\"\n</code></pre> <p>Running a scenario with no agents defined will produce an error like:</p> <pre><code>ScenarioValidationError: scenario \"My Test\" must define at least one agent\n</code></pre>"},{"location":"scenarios-README/#package-name","title":"Package Name","text":"<p>All programmatic usage should import from <code>@gadugi/agentic-test</code>:</p> <pre><code>import { runScenario, loadScenarios } from \"@gadugi/agentic-test\";\n\nconst scenarios = await loadScenarios(\"./scenarios\");\nawait runScenario(scenarios[0]);\n</code></pre> <p>The CLI binary is <code>gadugi-test</code>:</p> <pre><code>gadugi-test run scenarios/my-test.yaml\n</code></pre>"},{"location":"scenarios-README/#contributing","title":"Contributing","text":"<p>When adding new scenarios:</p> <ol> <li>Follow the established naming conventions</li> <li>Include comprehensive test coverage</li> <li>Add appropriate metadata and tags</li> <li>Test your scenario thoroughly</li> <li>Update this README if introducing new patterns</li> <li>Consider both positive and negative test cases</li> </ol>"},{"location":"scenarios-README/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues when writing scenarios:</p> <ul> <li>Timeouts: Increase timeout values for slow operations</li> <li>Element selectors: Use <code>data-testid</code> attributes for reliable selection</li> <li>Environment variables: Ensure all required variables are documented</li> <li>Agent configuration: Verify agent types and configurations are valid</li> <li>Step dependencies: Ensure steps execute in logical order</li> <li>Cleanup failures: Use <code>ignore_errors: true</code> for non-critical cleanup steps</li> </ul>"},{"location":"screenshot-diff-guide/","title":"Screenshot Diff Visualization Guide","text":"<p>This guide explains how to use the advanced screenshot diff functionality implemented in the agentic testing system.</p>"},{"location":"screenshot-diff-guide/#overview","title":"Overview","text":"<p>The screenshot diff system provides comprehensive image comparison capabilities with: - Multiple diff algorithms (pixel-by-pixel, perceptual, structural) - Customizable color coding for visual differences - Support for different image sizes - Batch processing capabilities - Detailed similarity scoring - Advanced reporting features</p>"},{"location":"screenshot-diff-guide/#quick-start","title":"Quick Start","text":"<pre><code>import { createScreenshotManager } from './src/utils/screenshot';\n\nconst screenshotManager = createScreenshotManager({\n  baseDir: './screenshots',\n  strategy: 'by-scenario'\n});\n\n// Basic comparison\nconst result = await screenshotManager.compareScreenshots(\n  './baseline.png',\n  './actual.png'\n);\n\nconsole.log(`Similarity: ${result.similarityPercentage}%`);\nconsole.log(`Match: ${result.matches}`);\n</code></pre>"},{"location":"screenshot-diff-guide/#diff-algorithms","title":"Diff Algorithms","text":""},{"location":"screenshot-diff-guide/#1-pixel-by-pixel-pixel-by-pixel","title":"1. Pixel-by-Pixel (<code>pixel-by-pixel</code>)","text":"<ul> <li>Best for: Exact pixel-level comparisons</li> <li>Use case: UI regression testing, pixel-perfect layouts</li> <li>Features: High precision, antialiasing detection</li> </ul> <pre><code>const result = await screenshotManager.compareScreenshots(\n  baseline,\n  actual,\n  {\n    algorithm: 'pixel-by-pixel',\n    threshold: 0.05, // 5% difference threshold\n    includeAA: true  // Include antialiasing detection\n  }\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#2-perceptual-perceptual","title":"2. Perceptual (<code>perceptual</code>)","text":"<ul> <li>Best for: Human-visible differences</li> <li>Use case: Content validation, visual quality assessment</li> <li>Features: Luminance-based comparison, color perception</li> </ul> <pre><code>const result = await screenshotManager.compareScreenshots(\n  baseline,\n  actual,\n  {\n    algorithm: 'perceptual',\n    threshold: 0.1\n  }\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#3-structural-structural","title":"3. Structural (<code>structural</code>)","text":"<ul> <li>Best for: Layout and shape changes</li> <li>Use case: Component structure validation, edge detection</li> <li>Features: Edge detection, shape analysis</li> </ul> <pre><code>const result = await screenshotManager.compareScreenshots(\n  baseline,\n  actual,\n  {\n    algorithm: 'structural',\n    threshold: 0.15\n  }\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#color-coding-options","title":"Color Coding Options","text":"<p>Customize the visual diff colors to match your needs:</p> <pre><code>const result = await screenshotManager.compareScreenshots(\n  baseline,\n  actual,\n  {\n    colorOptions: {\n      removedColor: [255, 0, 0],    // Red for removed pixels\n      addedColor: [0, 255, 0],      // Green for added pixels  \n      changedColor: [255, 255, 0],  // Yellow for changed pixels\n      alpha: 200                    // Transparency (0-255)\n    }\n  }\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#advanced-diff-images","title":"Advanced Diff Images","text":"<p>Create enhanced diff visualizations:</p> <pre><code>// Create side-by-side comparison\nconst diffPath = await screenshotManager.createDiff(\n  baseline,\n  actual,\n  './output/diff.png',\n  {\n    algorithm: 'pixel-by-pixel',\n    showSideBySide: true,  // Shows baseline | actual | diff\n    colorOptions: {\n      removedColor: [220, 20, 60],   // Crimson\n      addedColor: [34, 139, 34],     // Forest green\n      changedColor: [255, 165, 0]    // Orange\n    }\n  }\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#batch-processing","title":"Batch Processing","text":"<p>Process multiple screenshot comparisons:</p> <pre><code>const results = await screenshotManager.batchCompareScreenshots([\n  {\n    name: 'Homepage',\n    baseline: './screenshots/home_baseline.png',\n    actual: './screenshots/home_actual.png',\n    options: { algorithm: 'perceptual', threshold: 0.05 }\n  },\n  {\n    name: 'Login',\n    baseline: './screenshots/login_baseline.png', \n    actual: './screenshots/login_actual.png',\n    options: { algorithm: 'pixel-by-pixel', threshold: 0.02 }\n  }\n]);\n\n// Generate report\nconst reportPath = await screenshotManager.generateComparisonReport(\n  results,\n  './reports/comparison_report.json'\n);\n</code></pre>"},{"location":"screenshot-diff-guide/#multi-algorithm-scoring","title":"Multi-Algorithm Scoring","text":"<p>Get comprehensive similarity scores using multiple algorithms:</p> <pre><code>const score = await screenshotManager.calculateSimilarityScore(\n  baseline,\n  actual,\n  {\n    weights: { \n      pixel: 0.4,      // 40% weight for pixel comparison\n      perceptual: 0.4, // 40% weight for perceptual comparison  \n      structural: 0.2  // 20% weight for structural comparison\n    }\n  }\n);\n\nconsole.log(`Overall Similarity: ${score.overall}%`);\nconsole.log(`Breakdown - Pixel: ${score.pixel}%, Perceptual: ${score.perceptual}%, Structural: ${score.structural}%`);\n</code></pre>"},{"location":"screenshot-diff-guide/#handling-different-image-sizes","title":"Handling Different Image Sizes","text":"<p>The system automatically handles images of different sizes:</p> <ul> <li>Images are resized to match the larger dimensions</li> <li>Aspect ratios are preserved</li> <li>The <code>resized</code> flag indicates if resizing occurred</li> </ul> <pre><code>const result = await screenshotManager.compareScreenshots(baseline, actual);\n\nif (result.metadata.resized) {\n  console.log('Images were resized for comparison');\n  console.log('Baseline:', result.metadata.baselineSize);\n  console.log('Actual:', result.metadata.actualSize);\n}\n</code></pre>"},{"location":"screenshot-diff-guide/#integration-with-playwright","title":"Integration with Playwright","text":"<p>Use with Playwright test scenarios:</p> <pre><code>import { test, expect } from '@playwright/test';\nimport { createScreenshotManager } from './utils/screenshot';\n\ntest('visual regression test', async ({ page }) =&gt; {\n  const screenshotManager = createScreenshotManager();\n\n  await page.goto('/dashboard');\n\n  // Capture current screenshot\n  const current = await screenshotManager.capturePageScreenshot(page, {\n    scenarioId: 'dashboard-test'\n  });\n\n  // Compare with baseline\n  const result = await screenshotManager.compareScreenshots(\n    './baselines/dashboard.png',\n    current.filePath,\n    {\n      algorithm: 'perceptual',\n      threshold: 0.05\n    }\n  );\n\n  expect(result.matches).toBeTruthy();\n});\n</code></pre>"},{"location":"screenshot-diff-guide/#configuration-options","title":"Configuration Options","text":""},{"location":"screenshot-diff-guide/#comparison-options","title":"Comparison Options","text":"<pre><code>interface ComparisonOptions {\n  threshold?: number;        // Similarity threshold (0-1)\n  algorithm?: DiffAlgorithm; // 'pixel-by-pixel' | 'perceptual' | 'structural'\n  includeAA?: boolean;       // Include antialiasing detection\n  colorOptions?: DiffColorOptions;\n  createDiffImage?: boolean; // Generate diff image\n}\n</code></pre>"},{"location":"screenshot-diff-guide/#color-options","title":"Color Options","text":"<pre><code>interface DiffColorOptions {\n  removedColor?: [number, number, number]; // RGB for removed pixels\n  addedColor?: [number, number, number];   // RGB for added pixels\n  changedColor?: [number, number, number]; // RGB for changed pixels\n  alpha?: number;                          // Alpha value (0-255)\n}\n</code></pre>"},{"location":"screenshot-diff-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Choose the right algorithm:</li> <li>Use <code>pixel-by-pixel</code> for exact UI regression testing</li> <li>Use <code>perceptual</code> for content and visual quality validation</li> <li> <p>Use <code>structural</code> for layout and component structure testing</p> </li> <li> <p>Set appropriate thresholds:</p> </li> <li>Lower thresholds (0.01-0.05) for strict comparisons</li> <li> <p>Higher thresholds (0.1-0.2) for more flexible comparisons</p> </li> <li> <p>Use batch processing for efficiency:</p> </li> <li>Process multiple screenshots in a single operation</li> <li> <p>Generate comprehensive reports</p> </li> <li> <p>Leverage side-by-side diffs:</p> </li> <li>Enable <code>showSideBySide</code> for detailed visual analysis</li> <li> <p>Useful for debugging and manual review</p> </li> <li> <p>Customize colors for clarity:</p> </li> <li>Use high-contrast colors for better visibility</li> <li>Adjust alpha values for overlay transparency</li> </ol>"},{"location":"screenshot-diff-guide/#troubleshooting","title":"Troubleshooting","text":"<p>Images not loading: - Ensure image paths are correct and accessible - Check file permissions and formats (PNG/JPEG supported)</p> <p>High false positives: - Increase threshold values - Use <code>perceptual</code> algorithm instead of <code>pixel-by-pixel</code> - Enable antialiasing detection with <code>includeAA: true</code></p> <p>Performance issues: - Disable diff image creation for batch operations: <code>createDiffImage: false</code> - Use appropriate algorithms (structural is fastest, pixel-by-pixel is slowest) - Process images asynchronously in batches</p>"},{"location":"screenshot-diff-guide/#report-format","title":"Report Format","text":"<p>Generated reports include:</p> <pre><code>{\n  \"runId\": \"run_2025-01-01T12-00-00_abc123\",\n  \"timestamp\": \"2025-01-01T12:00:00.000Z\",\n  \"summary\": {\n    \"totalComparisons\": 3,\n    \"passed\": 2,\n    \"failed\": 1,\n    \"averageSimilarity\": 87.5\n  },\n  \"results\": [\n    {\n      \"name\": \"Homepage\",\n      \"matches\": true,\n      \"similarity\": 95.2,\n      \"difference\": 4.8,\n      \"algorithm\": \"perceptual\",\n      \"diffImagePath\": \"/path/to/diff.png\",\n      \"resized\": false,\n      \"pixelCount\": 1920000,\n      \"differentPixels\": 92160\n    }\n  ]\n}\n</code></pre> <p>This comprehensive screenshot diff system provides all the tools needed for robust visual testing and comparison in your Playwright-based test automation.</p>"}]}